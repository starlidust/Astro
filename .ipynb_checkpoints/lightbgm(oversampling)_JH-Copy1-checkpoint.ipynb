{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# out_fiberID\n",
    "* 기존변수 + u-g,g-r,r-i,i-z만 추가변수로 사용\n",
    "* fiber_ID를 제외하고 진행해봄\n",
    "* 제출결과 : 0.3793087274 \n",
    "-> fiberID를 제외해서 0.02상승"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-18T12:14:17.018506Z",
     "start_time": "2020-02-18T12:14:15.183560Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import log_loss\n",
    "import lightgbm as lgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-18T12:14:17.022506Z",
     "start_time": "2020-02-18T12:14:17.019506Z"
    }
   },
   "outputs": [],
   "source": [
    "# from google.colab import drive\n",
    "# drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-18T12:14:17.051505Z",
     "start_time": "2020-02-18T12:14:17.023506Z"
    }
   },
   "outputs": [],
   "source": [
    "# #colab용\n",
    "# import os\n",
    "# os.chdir('/content/drive/My Drive/Colab Notebooks/Dacon/천체관측/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-18T12:14:18.681639Z",
     "start_time": "2020-02-18T12:14:17.052505Z"
    }
   },
   "outputs": [],
   "source": [
    "# path = \"/content/drive/My Drive/Colab Notebooks/Dacon/천체관측/data/\" #colab\n",
    "path = \"./data/\" #local\n",
    "train_df = pd.read_csv(path+'train.csv',index_col=0)\n",
    "test_df = pd.read_csv(path+'test.csv',index_col=0)\n",
    "sample_submission_df = pd.read_csv(path+'sample_submission.csv',index_col=0)\n",
    "pd.options.display.max_columns = 30"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### oversampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-18T12:14:22.057044Z",
     "start_time": "2020-02-18T12:14:18.682639Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "C:\\Users\\starl\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:493: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "C:\\Users\\starl\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:494: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "C:\\Users\\starl\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:495: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "C:\\Users\\starl\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:496: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "C:\\Users\\starl\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:497: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "C:\\Users\\starl\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:502: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(199991, 22)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "sm = SMOTE(random_state=42)\n",
    "\n",
    "y = train_df.type\n",
    "X = train_df.drop('type',axis = 1)\n",
    "\n",
    "train_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-18T12:14:33.919779Z",
     "start_time": "2020-02-18T12:14:22.059045Z"
    }
   },
   "outputs": [],
   "source": [
    "resample_X, resample_y = sm.fit_resample(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-18T12:14:33.925780Z",
     "start_time": "2020-02-18T12:14:33.920779Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(943920, 21)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resample_X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-18T12:23:46.642902Z",
     "start_time": "2020-02-18T12:23:46.348911Z"
    }
   },
   "outputs": [],
   "source": [
    "new_train = pd.concat([resample_X,resample_y],axis = 1)\n",
    "new_train = new_train[train_df.columns]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DATA Setting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-18T12:23:50.361788Z",
     "start_time": "2020-02-18T12:23:49.761807Z"
    }
   },
   "outputs": [],
   "source": [
    "column_number = {}\n",
    "number_columns = {}\n",
    "for i, column in enumerate(sample_submission_df.columns):\n",
    "    column_number[column] = i\n",
    "    number_columns[i] = column\n",
    "    \n",
    "    \n",
    "def to_number(x, dic):\n",
    "    return dic[x]\n",
    "\n",
    "new_train['type_num'] = new_train['type'].apply(lambda x: to_number(x, column_number))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-18T12:23:54.278669Z",
     "start_time": "2020-02-18T12:23:54.274669Z"
    }
   },
   "outputs": [],
   "source": [
    "def add_minus_feature_all(data,test = False):\n",
    "    '''\n",
    "    combination으로 모든 변수들의 조합에 대해서 컬럼생성 \n",
    "    각 mag에서 가장 높은값의 filter를 받아오는 \"~~mag_MAX\"생성\n",
    "    결과 64개로 증가\n",
    "    '''\n",
    "    from itertools import combinations\n",
    "    n = 0\n",
    "    for count in range(5,21,5):\n",
    "        s = 2\n",
    "        if test == True :\n",
    "            s = 1\n",
    "        selected = data.columns[s:].values[n:count]\n",
    "        mag = str.split(selected[0],'_')[0]\n",
    "#         data[mag+\"_MAX\"] = data[selected].apply(lambda x : str.split(np.argmax(x),'_')[1],axis = 1)\n",
    "        for combi in list(combinations(selected,2)):\n",
    "            name_1st = str.split(combi[0],'_')[1]\n",
    "            name_2nd = str.split(combi[1],'_')[1]\n",
    "            data[mag+\"_\"+name_1st+\"-\"+name_2nd] = data[combi[0]]-data[combi[1]]\n",
    "        n=count\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-18T12:23:55.289637Z",
     "start_time": "2020-02-18T12:23:55.280637Z"
    }
   },
   "outputs": [],
   "source": [
    "def add_minus_feature(data,test = False):\n",
    "    '''\n",
    "    근접변수에 대해서만 컬럼생성 ex) 'fiberMag_u-g', 'fiberMag_g-r', 'fiberMag_r-i', 'fiberMag_i-z'\n",
    "    각 mag에서 가장 높은값의 filter를 받아오는 \"~~mag_MAX\"생성\n",
    "    결과 38개로 증가 \n",
    "    '''\n",
    "    from itertools import combinations\n",
    "    n = 0\n",
    "    m = 0\n",
    "    for count in range(5,21,5):\n",
    "        s = 2\n",
    "        if test == True :\n",
    "            s = 1\n",
    "        selected = data.columns[s:].values[n:count]\n",
    "        mag = str.split(selected[0],'_')[0]\n",
    "#         data[mag+\"_MAX\"] = data[selected].apply(lambda x : str.split(np.argmax(x),'_')[1],axis = 1)\n",
    "        for i in range(0,len(selected)):        \n",
    "            if i>0: \n",
    "                name_1st = str.split(m,'_')[1]\n",
    "                name_2nd = str.split(selected[i],'_')[1]\n",
    "                data[mag+\"_\"+name_1st+\"-\"+name_2nd] = data[m]-data[selected[i]]\n",
    "            m = selected[i]    \n",
    "        n=count\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-18T12:23:56.649595Z",
     "start_time": "2020-02-18T12:23:56.252608Z"
    }
   },
   "outputs": [],
   "source": [
    "train_df = add_minus_feature_all(new_train)\n",
    "test_df = add_minus_feature_all(test_df,True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-18T12:24:07.384279Z",
     "start_time": "2020-02-18T12:24:07.378267Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((943920, 63), (10009, 61))"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.shape,test_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-18T12:24:16.589986Z",
     "start_time": "2020-02-18T12:24:16.585985Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['type', 'fiberID', 'psfMag_u', 'psfMag_g', 'psfMag_r', 'psfMag_i',\n",
       "       'psfMag_z', 'fiberMag_u', 'fiberMag_g', 'fiberMag_r', 'fiberMag_i',\n",
       "       'fiberMag_z', 'petroMag_u', 'petroMag_g', 'petroMag_r', 'petroMag_i',\n",
       "       'petroMag_z', 'modelMag_u', 'modelMag_g', 'modelMag_r', 'modelMag_i',\n",
       "       'modelMag_z', 'type_num', 'psfMag_u-g', 'psfMag_u-r', 'psfMag_u-i',\n",
       "       'psfMag_u-z', 'psfMag_g-r', 'psfMag_g-i', 'psfMag_g-z', 'psfMag_r-i',\n",
       "       'psfMag_r-z', 'psfMag_i-z', 'fiberMag_u-g', 'fiberMag_u-r',\n",
       "       'fiberMag_u-i', 'fiberMag_u-z', 'fiberMag_g-r', 'fiberMag_g-i',\n",
       "       'fiberMag_g-z', 'fiberMag_r-i', 'fiberMag_r-z', 'fiberMag_i-z',\n",
       "       'petroMag_u-g', 'petroMag_u-r', 'petroMag_u-i', 'petroMag_u-z',\n",
       "       'petroMag_g-r', 'petroMag_g-i', 'petroMag_g-z', 'petroMag_r-i',\n",
       "       'petroMag_r-z', 'petroMag_i-z', 'modelMag_u-g', 'modelMag_u-r',\n",
       "       'modelMag_u-i', 'modelMag_u-z', 'modelMag_g-r', 'modelMag_g-i',\n",
       "       'modelMag_g-z', 'modelMag_r-i', 'modelMag_r-z', 'modelMag_i-z'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-18T12:24:26.777673Z",
     "start_time": "2020-02-18T12:24:26.774673Z"
    }
   },
   "outputs": [],
   "source": [
    "def label_encode(data):\n",
    "    '''\n",
    "    각 mag에서 가장 높은값의 filter를 labelencoding \n",
    "    '''\n",
    "    from sklearn.preprocessing import LabelEncoder\n",
    "    le = LabelEncoder()\n",
    "    taget_cols = ['psfMag_MAX','fiberMag_MAX','petroMag_MAX','modelMag_MAX']\n",
    "    for col in taget_cols:\n",
    "        data[col] = le.fit_transform(data[col])\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-18T12:24:36.108387Z",
     "start_time": "2020-02-18T12:24:35.990391Z"
    }
   },
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'psfMag_MAX'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexes\\base.py\u001b[0m in \u001b[0;36mget_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   3062\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3063\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3064\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'psfMag_MAX'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-36-d858fba2423c>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mtrain_df\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlabel_encode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_df\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mtest_df\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlabel_encode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest_df\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-35-e8e72b170bc5>\u001b[0m in \u001b[0;36mlabel_encode\u001b[1;34m(data)\u001b[0m\n\u001b[0;32m      7\u001b[0m     \u001b[0mtaget_cols\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;34m'psfMag_MAX'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'fiberMag_MAX'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'petroMag_MAX'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'modelMag_MAX'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mcol\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtaget_cols\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m         \u001b[0mdata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mcol\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mle\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mcol\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     10\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   2683\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_getitem_multilevel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2684\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2685\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_getitem_column\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2686\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2687\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_getitem_column\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m_getitem_column\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   2690\u001b[0m         \u001b[1;31m# get column\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2691\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_unique\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2692\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_item_cache\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2693\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2694\u001b[0m         \u001b[1;31m# duplicate columns & possible reduce dimensionality\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36m_get_item_cache\u001b[1;34m(self, item)\u001b[0m\n\u001b[0;32m   2484\u001b[0m         \u001b[0mres\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcache\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2485\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mres\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2486\u001b[1;33m             \u001b[0mvalues\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_data\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2487\u001b[0m             \u001b[0mres\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_box_item_values\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalues\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2488\u001b[0m             \u001b[0mcache\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mres\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\core\\internals.py\u001b[0m in \u001b[0;36mget\u001b[1;34m(self, item, fastpath)\u001b[0m\n\u001b[0;32m   4113\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4114\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0misna\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 4115\u001b[1;33m                 \u001b[0mloc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   4116\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4117\u001b[0m                 \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0misna\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexes\\base.py\u001b[0m in \u001b[0;36mget_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   3063\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3064\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3065\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_maybe_cast_indexer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3066\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3067\u001b[0m         \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_indexer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmethod\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtolerance\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtolerance\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'psfMag_MAX'"
     ]
    }
   ],
   "source": [
    "train_df = label_encode(train_df)\n",
    "test_df = label_encode(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-18T13:20:01.602548Z",
     "start_time": "2020-02-18T13:20:00.687577Z"
    }
   },
   "outputs": [],
   "source": [
    "train_X = train_df.drop(columns=['type', 'type_num','fiberID'], axis=1)\n",
    "train_y = train_df['type_num']\n",
    "test_X = test_df.drop(columns = ['fiberID'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-18T13:20:03.124502Z",
     "start_time": "2020-02-18T13:20:01.603549Z"
    }
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(train_X, train_y, test_size=0.3, random_state=42,stratify = train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-18T13:20:03.128502Z",
     "start_time": "2020-02-18T13:20:03.125502Z"
    }
   },
   "outputs": [],
   "source": [
    "train_ds = lgb.Dataset(X_train, label = y_train)\n",
    "test_ds = lgb.Dataset(X_test, label = y_test) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-18T13:20:03.164501Z",
     "start_time": "2020-02-18T13:20:03.129502Z"
    }
   },
   "outputs": [],
   "source": [
    "params = {\n",
    "    'boosting_type': 'gbdt',\n",
    "    'objective': 'multiclass',\n",
    "    'num_class': train_y.nunique(),\n",
    "    'metric': {'multi_logloss','multi_logloss'},\n",
    "    'num_leaves': 25,\n",
    "    'learning_rate': 0.05,\n",
    "    'max_depth' : 12,\n",
    "    'random_state' : 42\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-02-18T23:40:17.780Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tTrain's multi_logloss: 1.56127\tTest's multi_logloss: 1.56527\n",
      "[200]\tTrain's multi_logloss: 1.08623\tTest's multi_logloss: 1.09179\n",
      "[300]\tTrain's multi_logloss: 0.824488\tTest's multi_logloss: 0.831149\n",
      "[400]\tTrain's multi_logloss: 0.665378\tTest's multi_logloss: 0.672952\n",
      "[500]\tTrain's multi_logloss: 0.562548\tTest's multi_logloss: 0.571119\n",
      "[600]\tTrain's multi_logloss: 0.494138\tTest's multi_logloss: 0.503624\n",
      "[700]\tTrain's multi_logloss: 0.447143\tTest's multi_logloss: 0.457444\n"
     ]
    }
   ],
   "source": [
    "evaluation_results = {}\n",
    "lgmb_model = lgb.train(params, train_ds,num_boost_round= 5000, \n",
    "                       valid_sets = [train_ds,test_ds], valid_names=['Train', 'Test'],\n",
    "                       evals_result=evaluation_results,\n",
    "                       verbose_eval=100, early_stopping_rounds=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-02-18T23:40:24.693Z"
    }
   },
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(1, 2, figsize=[15, 4])\n",
    "\n",
    "# Plot the log loss during training\n",
    "axs[0].plot(evaluation_results['Train']['multi_logloss'], label='Train')\n",
    "axs[0].plot(evaluation_results['Test']['multi_logloss'], label='Test')\n",
    "axs[0].set_ylabel('Log loss')\n",
    "axs[0].set_xlabel('Boosting round')\n",
    "axs[0].set_title('Training performance')\n",
    "axs[0].legend()\n",
    "\n",
    "# Plot feature importance\n",
    "importances = pd.DataFrame({'features': lgmb_model.feature_name(), \n",
    "                            'importance': lgmb_model.feature_importance()}).sort_values('importance', ascending=False).head(10)\n",
    "axs[1].bar(x=np.arange(len(importances)), height=importances['importance'])\n",
    "axs[1].set_xticks(np.arange(len(importances)))\n",
    "axs[1].set_xticklabels(importances['features'])\n",
    "axs[1].set_ylabel('Feature importance (# times used to split)')\n",
    "axs[1].set_title('Feature importance')\n",
    "plt.xticks(rotation=45)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-02-18T23:40:24.695Z"
    }
   },
   "outputs": [],
   "source": [
    "train_y_pred = lgmb_model.predict(X_test)\n",
    "real_y_pred = lgmb_model.predict(test_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-02-18T23:40:24.697Z"
    }
   },
   "outputs": [],
   "source": [
    "train_y_pred.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-02-18T23:40:24.699Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#log_loss\n",
    "log_loss(y_test,train_y_pred,labels= list(set(y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-02-18T23:40:24.701Z"
    }
   },
   "outputs": [],
   "source": [
    "lgmb_model.feature_importance()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### feature_importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-02-18T23:40:24.703Z"
    }
   },
   "outputs": [],
   "source": [
    "pi_df = pd.DataFrame(lgmb_model.feature_importance(), index= train_X.columns,columns= ['importance']).sort_values('importance',ascending = False)\n",
    "pi_df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 예측결과에 대해\n",
    "* 12번이 모두 6번으로 몰림\n",
    "중간예측 : 0(STAR_WHITE_DWARF-2160),2(STAR_BROWN_DWARF-500),7(SERENDIPITY_DISTANT-4654),11(ROSAT_D-6580)\n",
    "망한예측 : 12(STAR_PN-13),17(SERENDIPITY_MANUAL-61)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-02-18T23:40:24.705Z"
    }
   },
   "outputs": [],
   "source": [
    "cm_result = pd.DataFrame(confusion_matrix(y_test,np.argmax(train_y_pred,axis = 1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-02-18T23:40:24.707Z"
    }
   },
   "outputs": [],
   "source": [
    "number_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-02-18T23:40:24.709Z"
    }
   },
   "outputs": [],
   "source": [
    "train_df.type.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-02-18T23:40:24.712Z"
    }
   },
   "outputs": [],
   "source": [
    "cm_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-02-18T23:40:24.714Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize =(15,15))\n",
    "sns.heatmap(cm_result/np.sum(cm_result),annot = True, cmap ='RdYlGn',fmt='.1%')\n",
    "plt.ylabel(\"real\",fontsize=20)\n",
    "plt.xlabel(\"predict\",fontsize=20)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# REAL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-02-18T23:40:24.726Z"
    }
   },
   "outputs": [],
   "source": [
    "train_ds = lgb.Dataset(train_X, label = train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-02-18T23:40:24.728Z"
    }
   },
   "outputs": [],
   "source": [
    "lgmb_model = lgb.train(params, train_ds,num_boost_round= 2000, verbose_eval=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-02-18T23:40:24.730Z"
    }
   },
   "outputs": [],
   "source": [
    "y_pred = lgmb_model.predict(test_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-02-18T23:40:24.732Z"
    }
   },
   "outputs": [],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-02-18T23:40:24.736Z"
    }
   },
   "outputs": [],
   "source": [
    "submission = pd.DataFrame(data=y_pred, columns=sample_submission_df.columns, index=sample_submission_df.index)\n",
    "submission.to_csv('./submisson/submission.csv', index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
