{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "0227_keras(update_plotly_learningrate)_jae.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.4"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/starlidust/Astro/blob/master/0227_keras(update_plotly_learningrate)_jae.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "FAnG9WAJIdG3",
        "outputId": "e78a74a7-de51-4ffa-c148-9d7d4db0443e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 63
        }
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import lightgbm as lgb\n",
        "import tensorflow as tf\n",
        "import chart_studio.plotly as py\n",
        "\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.metrics import log_loss\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "from tensorflow import keras"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "ratlOsTrIqkA",
        "outputId": "d06a840b-ec93-4130-83fd-3d64b09d7483",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 125
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "MjaMyZkkI36o",
        "colab": {}
      },
      "source": [
        "import os\n",
        "os.chdir('/content/drive/My Drive/data_con/')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "9TJVuvADIdHA",
        "colab": {}
      },
      "source": [
        "path = \"./data/\" \n",
        "train_df = pd.read_csv(path+'train.csv',index_col=0)\n",
        "test_df = pd.read_csv(path+'test.csv',index_col=0)\n",
        "sample_submission_df = pd.read_csv(path+'sample_submission.csv',index_col=0)\n",
        "pd.options.display.max_columns = 30"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Vhfz2BXRIdHG",
        "colab": {}
      },
      "source": [
        "##conda install keras-gpu 하면 gpu도 괴롭힐 수 있음"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "quYDTIuSXfjd",
        "colab": {}
      },
      "source": [
        "## 원핫 인코딩 함수\n",
        "def prepare_inputs(X_train, X_test):\n",
        "    ohe =  OneHotEncoder()\n",
        "    ohe.fit(X_train)\n",
        "    x_train_enc = ohe.transform(X_train)\n",
        "    X_test_enc = ohe.transform(X_test)\n",
        "    return X_train_enc, X_test_enc"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "sZsLrP8DIdHL"
      },
      "source": [
        "## 전처리\n",
        " - 이상치 확인 및 처리"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "VdNREsVMIdHN",
        "outputId": "af01093b-ead7-425f-ed52-7df5fc3fcf09",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "train_df.shape"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(199991, 22)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "T6PAAhPuIdHS",
        "outputId": "d8ed7a2e-26e1-4bfa-ce10-ec9377c59540",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 304
        }
      },
      "source": [
        "train_df.describe()"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>fiberID</th>\n",
              "      <th>psfMag_u</th>\n",
              "      <th>psfMag_g</th>\n",
              "      <th>psfMag_r</th>\n",
              "      <th>psfMag_i</th>\n",
              "      <th>psfMag_z</th>\n",
              "      <th>fiberMag_u</th>\n",
              "      <th>fiberMag_g</th>\n",
              "      <th>fiberMag_r</th>\n",
              "      <th>fiberMag_i</th>\n",
              "      <th>fiberMag_z</th>\n",
              "      <th>petroMag_u</th>\n",
              "      <th>petroMag_g</th>\n",
              "      <th>petroMag_r</th>\n",
              "      <th>petroMag_i</th>\n",
              "      <th>petroMag_z</th>\n",
              "      <th>modelMag_u</th>\n",
              "      <th>modelMag_g</th>\n",
              "      <th>modelMag_r</th>\n",
              "      <th>modelMag_i</th>\n",
              "      <th>modelMag_z</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>199991.000000</td>\n",
              "      <td>1.999910e+05</td>\n",
              "      <td>199991.000000</td>\n",
              "      <td>199991.000000</td>\n",
              "      <td>199991.000000</td>\n",
              "      <td>199991.000000</td>\n",
              "      <td>1.999910e+05</td>\n",
              "      <td>199991.000000</td>\n",
              "      <td>199991.000000</td>\n",
              "      <td>199991.000000</td>\n",
              "      <td>199991.000000</td>\n",
              "      <td>199991.000000</td>\n",
              "      <td>199991.000000</td>\n",
              "      <td>199991.000000</td>\n",
              "      <td>199991.000000</td>\n",
              "      <td>199991.000000</td>\n",
              "      <td>199991.000000</td>\n",
              "      <td>199991.000000</td>\n",
              "      <td>199991.000000</td>\n",
              "      <td>199991.000000</td>\n",
              "      <td>199991.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>360.830152</td>\n",
              "      <td>-6.750146e+00</td>\n",
              "      <td>18.675373</td>\n",
              "      <td>18.401235</td>\n",
              "      <td>18.043495</td>\n",
              "      <td>17.663526</td>\n",
              "      <td>1.084986e+01</td>\n",
              "      <td>19.072693</td>\n",
              "      <td>19.134483</td>\n",
              "      <td>18.183331</td>\n",
              "      <td>18.000882</td>\n",
              "      <td>21.837903</td>\n",
              "      <td>18.454136</td>\n",
              "      <td>18.481525</td>\n",
              "      <td>17.686617</td>\n",
              "      <td>17.699207</td>\n",
              "      <td>20.110991</td>\n",
              "      <td>18.544375</td>\n",
              "      <td>18.181544</td>\n",
              "      <td>17.692395</td>\n",
              "      <td>17.189281</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>225.305890</td>\n",
              "      <td>1.187678e+04</td>\n",
              "      <td>155.423024</td>\n",
              "      <td>127.128078</td>\n",
              "      <td>116.622194</td>\n",
              "      <td>123.735298</td>\n",
              "      <td>4.172116e+03</td>\n",
              "      <td>749.256162</td>\n",
              "      <td>90.049058</td>\n",
              "      <td>122.378972</td>\n",
              "      <td>145.862346</td>\n",
              "      <td>789.472333</td>\n",
              "      <td>154.376277</td>\n",
              "      <td>97.240448</td>\n",
              "      <td>145.730872</td>\n",
              "      <td>142.691880</td>\n",
              "      <td>122.299062</td>\n",
              "      <td>161.728183</td>\n",
              "      <td>133.984475</td>\n",
              "      <td>131.183416</td>\n",
              "      <td>133.685138</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>1.000000</td>\n",
              "      <td>-5.310802e+06</td>\n",
              "      <td>-40022.466071</td>\n",
              "      <td>-27184.795793</td>\n",
              "      <td>-26566.310827</td>\n",
              "      <td>-24878.828280</td>\n",
              "      <td>-1.864766e+06</td>\n",
              "      <td>-215882.917191</td>\n",
              "      <td>-21802.656144</td>\n",
              "      <td>-20208.516262</td>\n",
              "      <td>-26505.602101</td>\n",
              "      <td>-24463.431833</td>\n",
              "      <td>-25958.752324</td>\n",
              "      <td>-23948.588523</td>\n",
              "      <td>-40438.184078</td>\n",
              "      <td>-30070.729379</td>\n",
              "      <td>-26236.578659</td>\n",
              "      <td>-36902.402336</td>\n",
              "      <td>-36439.638493</td>\n",
              "      <td>-38969.416822</td>\n",
              "      <td>-26050.710196</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>174.000000</td>\n",
              "      <td>1.965259e+01</td>\n",
              "      <td>18.701180</td>\n",
              "      <td>18.048572</td>\n",
              "      <td>17.747663</td>\n",
              "      <td>17.425523</td>\n",
              "      <td>1.994040e+01</td>\n",
              "      <td>18.902851</td>\n",
              "      <td>18.259352</td>\n",
              "      <td>17.903615</td>\n",
              "      <td>17.606148</td>\n",
              "      <td>19.247795</td>\n",
              "      <td>18.113933</td>\n",
              "      <td>17.479794</td>\n",
              "      <td>17.050294</td>\n",
              "      <td>16.804705</td>\n",
              "      <td>19.266214</td>\n",
              "      <td>18.076120</td>\n",
              "      <td>17.423425</td>\n",
              "      <td>16.977671</td>\n",
              "      <td>16.705774</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>349.000000</td>\n",
              "      <td>2.087136e+01</td>\n",
              "      <td>19.904235</td>\n",
              "      <td>19.454492</td>\n",
              "      <td>19.043895</td>\n",
              "      <td>18.611799</td>\n",
              "      <td>2.104910e+01</td>\n",
              "      <td>20.069038</td>\n",
              "      <td>19.631419</td>\n",
              "      <td>19.188763</td>\n",
              "      <td>18.710967</td>\n",
              "      <td>20.366848</td>\n",
              "      <td>19.586559</td>\n",
              "      <td>19.182789</td>\n",
              "      <td>18.693370</td>\n",
              "      <td>18.174592</td>\n",
              "      <td>20.406840</td>\n",
              "      <td>19.547674</td>\n",
              "      <td>19.143156</td>\n",
              "      <td>18.641756</td>\n",
              "      <td>18.100997</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>526.000000</td>\n",
              "      <td>2.216043e+01</td>\n",
              "      <td>21.150297</td>\n",
              "      <td>20.515936</td>\n",
              "      <td>20.073528</td>\n",
              "      <td>19.883760</td>\n",
              "      <td>2.233754e+01</td>\n",
              "      <td>21.385830</td>\n",
              "      <td>20.773911</td>\n",
              "      <td>20.331419</td>\n",
              "      <td>20.133179</td>\n",
              "      <td>21.797480</td>\n",
              "      <td>21.004397</td>\n",
              "      <td>20.457491</td>\n",
              "      <td>20.019112</td>\n",
              "      <td>19.807652</td>\n",
              "      <td>21.992898</td>\n",
              "      <td>20.962386</td>\n",
              "      <td>20.408140</td>\n",
              "      <td>19.968846</td>\n",
              "      <td>19.819554</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>1000.000000</td>\n",
              "      <td>1.877392e+04</td>\n",
              "      <td>3538.984910</td>\n",
              "      <td>3048.110913</td>\n",
              "      <td>4835.218639</td>\n",
              "      <td>9823.740407</td>\n",
              "      <td>4.870154e+03</td>\n",
              "      <td>248077.513380</td>\n",
              "      <td>12084.735440</td>\n",
              "      <td>8059.638535</td>\n",
              "      <td>18358.921741</td>\n",
              "      <td>298771.019041</td>\n",
              "      <td>12139.815877</td>\n",
              "      <td>7003.136546</td>\n",
              "      <td>9772.190537</td>\n",
              "      <td>17403.789263</td>\n",
              "      <td>14488.251976</td>\n",
              "      <td>10582.058590</td>\n",
              "      <td>12237.951703</td>\n",
              "      <td>4062.499371</td>\n",
              "      <td>7420.534172</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "             fiberID      psfMag_u       psfMag_g       psfMag_r  \\\n",
              "count  199991.000000  1.999910e+05  199991.000000  199991.000000   \n",
              "mean      360.830152 -6.750146e+00      18.675373      18.401235   \n",
              "std       225.305890  1.187678e+04     155.423024     127.128078   \n",
              "min         1.000000 -5.310802e+06  -40022.466071  -27184.795793   \n",
              "25%       174.000000  1.965259e+01      18.701180      18.048572   \n",
              "50%       349.000000  2.087136e+01      19.904235      19.454492   \n",
              "75%       526.000000  2.216043e+01      21.150297      20.515936   \n",
              "max      1000.000000  1.877392e+04    3538.984910    3048.110913   \n",
              "\n",
              "            psfMag_i       psfMag_z    fiberMag_u     fiberMag_g  \\\n",
              "count  199991.000000  199991.000000  1.999910e+05  199991.000000   \n",
              "mean       18.043495      17.663526  1.084986e+01      19.072693   \n",
              "std       116.622194     123.735298  4.172116e+03     749.256162   \n",
              "min    -26566.310827  -24878.828280 -1.864766e+06 -215882.917191   \n",
              "25%        17.747663      17.425523  1.994040e+01      18.902851   \n",
              "50%        19.043895      18.611799  2.104910e+01      20.069038   \n",
              "75%        20.073528      19.883760  2.233754e+01      21.385830   \n",
              "max      4835.218639    9823.740407  4.870154e+03  248077.513380   \n",
              "\n",
              "          fiberMag_r     fiberMag_i     fiberMag_z     petroMag_u  \\\n",
              "count  199991.000000  199991.000000  199991.000000  199991.000000   \n",
              "mean       19.134483      18.183331      18.000882      21.837903   \n",
              "std        90.049058     122.378972     145.862346     789.472333   \n",
              "min    -21802.656144  -20208.516262  -26505.602101  -24463.431833   \n",
              "25%        18.259352      17.903615      17.606148      19.247795   \n",
              "50%        19.631419      19.188763      18.710967      20.366848   \n",
              "75%        20.773911      20.331419      20.133179      21.797480   \n",
              "max     12084.735440    8059.638535   18358.921741  298771.019041   \n",
              "\n",
              "          petroMag_g     petroMag_r     petroMag_i     petroMag_z  \\\n",
              "count  199991.000000  199991.000000  199991.000000  199991.000000   \n",
              "mean       18.454136      18.481525      17.686617      17.699207   \n",
              "std       154.376277      97.240448     145.730872     142.691880   \n",
              "min    -25958.752324  -23948.588523  -40438.184078  -30070.729379   \n",
              "25%        18.113933      17.479794      17.050294      16.804705   \n",
              "50%        19.586559      19.182789      18.693370      18.174592   \n",
              "75%        21.004397      20.457491      20.019112      19.807652   \n",
              "max     12139.815877    7003.136546    9772.190537   17403.789263   \n",
              "\n",
              "          modelMag_u     modelMag_g     modelMag_r     modelMag_i  \\\n",
              "count  199991.000000  199991.000000  199991.000000  199991.000000   \n",
              "mean       20.110991      18.544375      18.181544      17.692395   \n",
              "std       122.299062     161.728183     133.984475     131.183416   \n",
              "min    -26236.578659  -36902.402336  -36439.638493  -38969.416822   \n",
              "25%        19.266214      18.076120      17.423425      16.977671   \n",
              "50%        20.406840      19.547674      19.143156      18.641756   \n",
              "75%        21.992898      20.962386      20.408140      19.968846   \n",
              "max     14488.251976   10582.058590   12237.951703    4062.499371   \n",
              "\n",
              "          modelMag_z  \n",
              "count  199991.000000  \n",
              "mean       17.189281  \n",
              "std       133.685138  \n",
              "min    -26050.710196  \n",
              "25%        16.705774  \n",
              "50%        18.100997  \n",
              "75%        19.819554  \n",
              "max      7420.534172  "
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "PQyieXjqIdHV",
        "colab": {}
      },
      "source": [
        "def del_outlier(data, min=0, max=60):\n",
        "    up_idx_t=()\n",
        "    dw_idx_t=()\n",
        "    train_light = data.iloc[:,2:]\n",
        "    for i in range(len(train_light.columns)):\n",
        "        col = train_light.columns[i]\n",
        "        up_idx_t+=tuple(data[data[col]>max].index)\n",
        "        dw_idx_t+=tuple(data[data[col]<min].index)\n",
        "    del_idx = set(up_idx_t+dw_idx_t)\n",
        "    \n",
        "    return data[~data.index.isin(del_idx)]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "nOW3yLvUIdHb",
        "colab": {}
      },
      "source": [
        "train_df = del_outlier(train_df, min=-20, max=60)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "h63rnOB9IdHg",
        "outputId": "5ba04dca-6f3e-4f7d-b8cc-428921b4ae46",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        }
      },
      "source": [
        "train_df.columns, train_df.shape"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(Index(['type', 'fiberID', 'psfMag_u', 'psfMag_g', 'psfMag_r', 'psfMag_i',\n",
              "        'psfMag_z', 'fiberMag_u', 'fiberMag_g', 'fiberMag_r', 'fiberMag_i',\n",
              "        'fiberMag_z', 'petroMag_u', 'petroMag_g', 'petroMag_r', 'petroMag_i',\n",
              "        'petroMag_z', 'modelMag_u', 'modelMag_g', 'modelMag_r', 'modelMag_i',\n",
              "        'modelMag_z'],\n",
              "       dtype='object'), (199770, 22))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "xEriLvN2IdHj"
      },
      "source": [
        "## DATA Setting"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "t5-DMEgwIdHl",
        "colab": {}
      },
      "source": [
        "column_number = {}\n",
        "number_columns = {}\n",
        "for i, column in enumerate(sample_submission_df.columns):\n",
        "    column_number[column] = i\n",
        "    number_columns[i] = column\n",
        "    \n",
        "    \n",
        "def to_number(x, dic):\n",
        "    return dic[x]\n",
        "\n",
        "train_df['type_num'] = train_df['type'].apply(lambda x: to_number(x, column_number))\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "fsjNmwYlIdHq",
        "colab": {}
      },
      "source": [
        "def add_minus_feature(data,test = False):\n",
        "    from itertools import combinations\n",
        "    n = 0\n",
        "    for count in range(5,21,5):\n",
        "        s = 2\n",
        "        if test == True :\n",
        "            s = 1\n",
        "        selected = data.columns[s:].values[n:count]\n",
        "        mag = str.split(selected[0],'_')[0]\n",
        "        for combi in list(combinations(selected,2)):\n",
        "            name_1st = str.split(combi[0],'_')[1]\n",
        "            name_2nd = str.split(combi[1],'_')[1]\n",
        "            data[mag+\"_\"+name_1st+\"-\"+name_2nd] = data[combi[0]]-data[combi[1]]\n",
        "        n=count\n",
        "    return data"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "hQK90dmoIdHw",
        "colab": {}
      },
      "source": [
        "train_df = add_minus_feature(train_df)\n",
        "test_df = add_minus_feature(test_df,True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "wNh3Nq8tIdH1",
        "colab": {}
      },
      "source": [
        "train_X = train_df.drop(columns=['type', 'type_num'], axis=1)\n",
        "train_y = train_df['type_num']\n",
        "test_X = test_df"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Ebv7h9icIdH6",
        "outputId": "b8bd5ca8-5f8f-4b49-963a-09db5ddd8bcb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 290
        }
      },
      "source": [
        "train_X.head()"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>fiberID</th>\n",
              "      <th>psfMag_u</th>\n",
              "      <th>psfMag_g</th>\n",
              "      <th>psfMag_r</th>\n",
              "      <th>psfMag_i</th>\n",
              "      <th>psfMag_z</th>\n",
              "      <th>fiberMag_u</th>\n",
              "      <th>fiberMag_g</th>\n",
              "      <th>fiberMag_r</th>\n",
              "      <th>fiberMag_i</th>\n",
              "      <th>fiberMag_z</th>\n",
              "      <th>petroMag_u</th>\n",
              "      <th>petroMag_g</th>\n",
              "      <th>petroMag_r</th>\n",
              "      <th>petroMag_i</th>\n",
              "      <th>...</th>\n",
              "      <th>petroMag_g-i</th>\n",
              "      <th>petroMag_g-z</th>\n",
              "      <th>petroMag_r-i</th>\n",
              "      <th>petroMag_r-z</th>\n",
              "      <th>petroMag_i-z</th>\n",
              "      <th>modelMag_u-g</th>\n",
              "      <th>modelMag_u-r</th>\n",
              "      <th>modelMag_u-i</th>\n",
              "      <th>modelMag_u-z</th>\n",
              "      <th>modelMag_g-r</th>\n",
              "      <th>modelMag_g-i</th>\n",
              "      <th>modelMag_g-z</th>\n",
              "      <th>modelMag_r-i</th>\n",
              "      <th>modelMag_r-z</th>\n",
              "      <th>modelMag_i-z</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>id</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>601</td>\n",
              "      <td>23.198224</td>\n",
              "      <td>21.431953</td>\n",
              "      <td>21.314148</td>\n",
              "      <td>21.176553</td>\n",
              "      <td>21.171444</td>\n",
              "      <td>22.581309</td>\n",
              "      <td>21.644453</td>\n",
              "      <td>21.657571</td>\n",
              "      <td>21.387653</td>\n",
              "      <td>21.572827</td>\n",
              "      <td>22.504317</td>\n",
              "      <td>21.431636</td>\n",
              "      <td>21.478312</td>\n",
              "      <td>21.145409</td>\n",
              "      <td>...</td>\n",
              "      <td>0.286226</td>\n",
              "      <td>1.009190</td>\n",
              "      <td>0.332902</td>\n",
              "      <td>1.055866</td>\n",
              "      <td>0.722964</td>\n",
              "      <td>1.283708</td>\n",
              "      <td>1.385054</td>\n",
              "      <td>1.728637</td>\n",
              "      <td>1.601901</td>\n",
              "      <td>0.101347</td>\n",
              "      <td>0.444929</td>\n",
              "      <td>0.318194</td>\n",
              "      <td>0.343582</td>\n",
              "      <td>0.216847</td>\n",
              "      <td>-0.126735</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>788</td>\n",
              "      <td>21.431355</td>\n",
              "      <td>20.708104</td>\n",
              "      <td>20.678850</td>\n",
              "      <td>20.703420</td>\n",
              "      <td>20.473229</td>\n",
              "      <td>21.868797</td>\n",
              "      <td>21.029773</td>\n",
              "      <td>20.967054</td>\n",
              "      <td>20.937731</td>\n",
              "      <td>21.063646</td>\n",
              "      <td>21.360701</td>\n",
              "      <td>20.778968</td>\n",
              "      <td>20.889705</td>\n",
              "      <td>20.639812</td>\n",
              "      <td>...</td>\n",
              "      <td>0.139156</td>\n",
              "      <td>0.132308</td>\n",
              "      <td>0.249893</td>\n",
              "      <td>0.243045</td>\n",
              "      <td>-0.006847</td>\n",
              "      <td>0.734428</td>\n",
              "      <td>0.739030</td>\n",
              "      <td>0.799566</td>\n",
              "      <td>0.980641</td>\n",
              "      <td>0.004602</td>\n",
              "      <td>0.065138</td>\n",
              "      <td>0.246213</td>\n",
              "      <td>0.060537</td>\n",
              "      <td>0.241611</td>\n",
              "      <td>0.181074</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>427</td>\n",
              "      <td>17.851451</td>\n",
              "      <td>16.727898</td>\n",
              "      <td>16.679677</td>\n",
              "      <td>16.694640</td>\n",
              "      <td>16.641788</td>\n",
              "      <td>18.171890</td>\n",
              "      <td>17.033098</td>\n",
              "      <td>16.999682</td>\n",
              "      <td>17.095999</td>\n",
              "      <td>17.076449</td>\n",
              "      <td>17.867253</td>\n",
              "      <td>16.738784</td>\n",
              "      <td>16.688874</td>\n",
              "      <td>16.744210</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.005426</td>\n",
              "      <td>-0.069222</td>\n",
              "      <td>-0.055336</td>\n",
              "      <td>-0.119132</td>\n",
              "      <td>-0.063796</td>\n",
              "      <td>1.120628</td>\n",
              "      <td>1.176814</td>\n",
              "      <td>1.157885</td>\n",
              "      <td>1.129134</td>\n",
              "      <td>0.056186</td>\n",
              "      <td>0.037257</td>\n",
              "      <td>0.008506</td>\n",
              "      <td>-0.018929</td>\n",
              "      <td>-0.047680</td>\n",
              "      <td>-0.028751</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>864</td>\n",
              "      <td>20.789900</td>\n",
              "      <td>20.040371</td>\n",
              "      <td>19.926909</td>\n",
              "      <td>19.843840</td>\n",
              "      <td>19.463270</td>\n",
              "      <td>21.039030</td>\n",
              "      <td>20.317165</td>\n",
              "      <td>20.217898</td>\n",
              "      <td>20.073852</td>\n",
              "      <td>19.794505</td>\n",
              "      <td>20.433907</td>\n",
              "      <td>19.993727</td>\n",
              "      <td>19.985531</td>\n",
              "      <td>19.750917</td>\n",
              "      <td>...</td>\n",
              "      <td>0.242810</td>\n",
              "      <td>0.538610</td>\n",
              "      <td>0.234614</td>\n",
              "      <td>0.530413</td>\n",
              "      <td>0.295800</td>\n",
              "      <td>0.769012</td>\n",
              "      <td>0.880913</td>\n",
              "      <td>1.012598</td>\n",
              "      <td>1.217856</td>\n",
              "      <td>0.111901</td>\n",
              "      <td>0.243586</td>\n",
              "      <td>0.448844</td>\n",
              "      <td>0.131685</td>\n",
              "      <td>0.336943</td>\n",
              "      <td>0.205258</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>612</td>\n",
              "      <td>26.454969</td>\n",
              "      <td>23.058767</td>\n",
              "      <td>21.471406</td>\n",
              "      <td>19.504961</td>\n",
              "      <td>18.389096</td>\n",
              "      <td>25.700632</td>\n",
              "      <td>23.629122</td>\n",
              "      <td>21.742750</td>\n",
              "      <td>19.861718</td>\n",
              "      <td>18.810375</td>\n",
              "      <td>25.859229</td>\n",
              "      <td>22.426929</td>\n",
              "      <td>21.673551</td>\n",
              "      <td>19.610012</td>\n",
              "      <td>...</td>\n",
              "      <td>2.816917</td>\n",
              "      <td>4.050788</td>\n",
              "      <td>2.063539</td>\n",
              "      <td>3.297411</td>\n",
              "      <td>1.233871</td>\n",
              "      <td>1.729059</td>\n",
              "      <td>3.401710</td>\n",
              "      <td>5.389723</td>\n",
              "      <td>6.501398</td>\n",
              "      <td>1.672651</td>\n",
              "      <td>3.660663</td>\n",
              "      <td>4.772338</td>\n",
              "      <td>1.988012</td>\n",
              "      <td>3.099688</td>\n",
              "      <td>1.111675</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 61 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "    fiberID   psfMag_u   psfMag_g   psfMag_r   psfMag_i   psfMag_z  \\\n",
              "id                                                                   \n",
              "0       601  23.198224  21.431953  21.314148  21.176553  21.171444   \n",
              "1       788  21.431355  20.708104  20.678850  20.703420  20.473229   \n",
              "2       427  17.851451  16.727898  16.679677  16.694640  16.641788   \n",
              "3       864  20.789900  20.040371  19.926909  19.843840  19.463270   \n",
              "4       612  26.454969  23.058767  21.471406  19.504961  18.389096   \n",
              "\n",
              "    fiberMag_u  fiberMag_g  fiberMag_r  fiberMag_i  fiberMag_z  petroMag_u  \\\n",
              "id                                                                           \n",
              "0    22.581309   21.644453   21.657571   21.387653   21.572827   22.504317   \n",
              "1    21.868797   21.029773   20.967054   20.937731   21.063646   21.360701   \n",
              "2    18.171890   17.033098   16.999682   17.095999   17.076449   17.867253   \n",
              "3    21.039030   20.317165   20.217898   20.073852   19.794505   20.433907   \n",
              "4    25.700632   23.629122   21.742750   19.861718   18.810375   25.859229   \n",
              "\n",
              "    petroMag_g  petroMag_r  petroMag_i  ...  petroMag_g-i  petroMag_g-z  \\\n",
              "id                                      ...                               \n",
              "0    21.431636   21.478312   21.145409  ...      0.286226      1.009190   \n",
              "1    20.778968   20.889705   20.639812  ...      0.139156      0.132308   \n",
              "2    16.738784   16.688874   16.744210  ...     -0.005426     -0.069222   \n",
              "3    19.993727   19.985531   19.750917  ...      0.242810      0.538610   \n",
              "4    22.426929   21.673551   19.610012  ...      2.816917      4.050788   \n",
              "\n",
              "    petroMag_r-i  petroMag_r-z  petroMag_i-z  modelMag_u-g  modelMag_u-r  \\\n",
              "id                                                                         \n",
              "0       0.332902      1.055866      0.722964      1.283708      1.385054   \n",
              "1       0.249893      0.243045     -0.006847      0.734428      0.739030   \n",
              "2      -0.055336     -0.119132     -0.063796      1.120628      1.176814   \n",
              "3       0.234614      0.530413      0.295800      0.769012      0.880913   \n",
              "4       2.063539      3.297411      1.233871      1.729059      3.401710   \n",
              "\n",
              "    modelMag_u-i  modelMag_u-z  modelMag_g-r  modelMag_g-i  modelMag_g-z  \\\n",
              "id                                                                         \n",
              "0       1.728637      1.601901      0.101347      0.444929      0.318194   \n",
              "1       0.799566      0.980641      0.004602      0.065138      0.246213   \n",
              "2       1.157885      1.129134      0.056186      0.037257      0.008506   \n",
              "3       1.012598      1.217856      0.111901      0.243586      0.448844   \n",
              "4       5.389723      6.501398      1.672651      3.660663      4.772338   \n",
              "\n",
              "    modelMag_r-i  modelMag_r-z  modelMag_i-z  \n",
              "id                                            \n",
              "0       0.343582      0.216847     -0.126735  \n",
              "1       0.060537      0.241611      0.181074  \n",
              "2      -0.018929     -0.047680     -0.028751  \n",
              "3       0.131685      0.336943      0.205258  \n",
              "4       1.988012      3.099688      1.111675  \n",
              "\n",
              "[5 rows x 61 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "BiMDAd9ZIdID",
        "outputId": "c78905c2-e932-4e71-939a-f121d08732f0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 281
        }
      },
      "source": [
        "train_X.columns"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['fiberID', 'psfMag_u', 'psfMag_g', 'psfMag_r', 'psfMag_i', 'psfMag_z',\n",
              "       'fiberMag_u', 'fiberMag_g', 'fiberMag_r', 'fiberMag_i', 'fiberMag_z',\n",
              "       'petroMag_u', 'petroMag_g', 'petroMag_r', 'petroMag_i', 'petroMag_z',\n",
              "       'modelMag_u', 'modelMag_g', 'modelMag_r', 'modelMag_i', 'modelMag_z',\n",
              "       'psfMag_u-g', 'psfMag_u-r', 'psfMag_u-i', 'psfMag_u-z', 'psfMag_g-r',\n",
              "       'psfMag_g-i', 'psfMag_g-z', 'psfMag_r-i', 'psfMag_r-z', 'psfMag_i-z',\n",
              "       'fiberMag_u-g', 'fiberMag_u-r', 'fiberMag_u-i', 'fiberMag_u-z',\n",
              "       'fiberMag_g-r', 'fiberMag_g-i', 'fiberMag_g-z', 'fiberMag_r-i',\n",
              "       'fiberMag_r-z', 'fiberMag_i-z', 'petroMag_u-g', 'petroMag_u-r',\n",
              "       'petroMag_u-i', 'petroMag_u-z', 'petroMag_g-r', 'petroMag_g-i',\n",
              "       'petroMag_g-z', 'petroMag_r-i', 'petroMag_r-z', 'petroMag_i-z',\n",
              "       'modelMag_u-g', 'modelMag_u-r', 'modelMag_u-i', 'modelMag_u-z',\n",
              "       'modelMag_g-r', 'modelMag_g-i', 'modelMag_g-z', 'modelMag_r-i',\n",
              "       'modelMag_r-z', 'modelMag_i-z'],\n",
              "      dtype='object')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "sax8LG7lIdIK",
        "colab": {}
      },
      "source": [
        "## u-g, g-r, r-i, i-z 만 남기는게 좋지 않을까????\n",
        "train_X.drop(['psfMag_u-r','psfMag_u-i','psfMag_u-z','psfMag_g-i','psfMag_g-z','psfMag_r-z',\n",
        "             'fiberMag_u-r','fiberMag_u-i','fiberMag_u-z','fiberMag_g-i','fiberMag_g-z','fiberMag_r-z',\n",
        "             'petroMag_u-r','petroMag_u-i','petroMag_u-z','petroMag_g-i','petroMag_g-z','petroMag_r-z',\n",
        "             'modelMag_u-r','modelMag_u-i','modelMag_u-z','modelMag_g-i','modelMag_g-z','modelMag_r-z'] ,axis=1, inplace=True)\n",
        "\n",
        "test_X.drop(['psfMag_u-r','psfMag_u-i','psfMag_u-z','psfMag_g-i','psfMag_g-z','psfMag_r-z',\n",
        "             'fiberMag_u-r','fiberMag_u-i','fiberMag_u-z','fiberMag_g-i','fiberMag_g-z','fiberMag_r-z',\n",
        "             'petroMag_u-r','petroMag_u-i','petroMag_u-z','petroMag_g-i','petroMag_g-z','petroMag_r-z',\n",
        "         'modelMag_u-r','modelMag_u-i','modelMag_u-z','modelMag_g-i','modelMag_g-z','modelMag_r-z'] ,axis=1, inplace=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Y6pvdT1rIdIP",
        "outputId": "37fd6067-353f-4933-e1c0-7b39786c1d28",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "train_X.shape, test_X.shape"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((199770, 37), (10009, 37))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "BUQNSQmmN5MR",
        "outputId": "6358d24d-19d8-48cb-8847-622e8a661be3",
        "scrolled": true,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 175
        }
      },
      "source": [
        "train_X.columns"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['fiberID', 'psfMag_u', 'psfMag_g', 'psfMag_r', 'psfMag_i', 'psfMag_z',\n",
              "       'fiberMag_u', 'fiberMag_g', 'fiberMag_r', 'fiberMag_i', 'fiberMag_z',\n",
              "       'petroMag_u', 'petroMag_g', 'petroMag_r', 'petroMag_i', 'petroMag_z',\n",
              "       'modelMag_u', 'modelMag_g', 'modelMag_r', 'modelMag_i', 'modelMag_z',\n",
              "       'psfMag_u-g', 'psfMag_g-r', 'psfMag_r-i', 'psfMag_i-z', 'fiberMag_u-g',\n",
              "       'fiberMag_g-r', 'fiberMag_r-i', 'fiberMag_i-z', 'petroMag_u-g',\n",
              "       'petroMag_g-r', 'petroMag_r-i', 'petroMag_i-z', 'modelMag_u-g',\n",
              "       'modelMag_g-r', 'modelMag_r-i', 'modelMag_i-z'],\n",
              "      dtype='object')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O0Ku8WNU2G-k",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# train_fi, test_fi = prepare_inputs(train_X.fiberID, test_X.fiberID)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "iwqJJUOxOPIx",
        "colab": {}
      },
      "source": [
        "## fiber 관련변수 전부 제거\n",
        "train_X.drop(['fiberID','fiberMag_u', 'fiberMag_g', 'fiberMag_r', 'fiberMag_i', 'fiberMag_z',\n",
        "              'fiberMag_u-g','fiberMag_g-r', 'fiberMag_r-i', 'fiberMag_i-z', ], axis=1, inplace=True)\n",
        "\n",
        "test_X.drop(['fiberID','fiberMag_u', 'fiberMag_g', 'fiberMag_r', 'fiberMag_i', 'fiberMag_z',\n",
        "              'fiberMag_u-g','fiberMag_g-r', 'fiberMag_r-i', 'fiberMag_i-z', ], axis=1, inplace=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "yZVRWqedIdIa",
        "outputId": "1119f0bf-109b-4df5-8327-735711bf74b4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "train_X.shape, test_X.shape"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((199770, 27), (10009, 27))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "3_Nds360IdIe",
        "colab": {}
      },
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(train_X, train_y, test_size=0.3, random_state=42,stratify = train_y)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "2fCs6Z2zIdIi",
        "colab": {}
      },
      "source": [
        "o_hot = OneHotEncoder()\n",
        "y_train= o_hot.fit_transform(y_train.values.reshape(-1,1))\n",
        "y_train = y_train.toarray()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "2mwvZZ0tIdIn",
        "scrolled": true,
        "colab": {}
      },
      "source": [
        "o2_hot = OneHotEncoder()\n",
        "y_test= o2_hot.fit_transform(y_test.values.reshape(-1,1))\n",
        "y_test = y_test.toarray()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "C8DaauwYIdIr",
        "outputId": "4c50f50d-d886-4573-9635-18524167fdaa",
        "scrolled": true,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "y_train.shape, y_test.shape"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((139839, 19), (59931, 19))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "pg79AzKhIdIu",
        "outputId": "58c80647-2acd-4e28-9fba-b2ebb079c592",
        "scrolled": true,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "X_train = X_train.values\n",
        "X_train.shape"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(139839, 27)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "n8eI0u2nIdI0",
        "outputId": "09d8418f-d3d8-40d5-d4ce-60888330bfa3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "X_test = X_test.values\n",
        "X_test.shape"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(59931, 27)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "cWbu6unjIdI5",
        "outputId": "ed05fe68-931d-444b-d408-0a7f0f610b09",
        "scrolled": true,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Flatten, Dropout\n",
        "from keras.layers import BatchNormalization\n",
        "from keras.layers import ELU\n",
        "\n",
        "elu_alpha=0.1\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Dense(256*4, input_dim=X_train.shape[1]))\n",
        "model.add(BatchNormalization())\n",
        "model.add(ELU(alpha=elu_alpha))\n",
        "model.add(Dropout(0.3))\n",
        "model.add(Dense(256*3))\n",
        "model.add(BatchNormalization())\n",
        "model.add(ELU(alpha=elu_alpha))\n",
        "model.add(Dropout(0.3))\n",
        "model.add(Dense(256*2))\n",
        "model.add(BatchNormalization())\n",
        "model.add(ELU(alpha=elu_alpha))\n",
        "model.add(Dropout(0.3))\n",
        "model.add(Dense(256*1))\n",
        "model.add(BatchNormalization())\n",
        "model.add(ELU(alpha=elu_alpha))\n",
        "model.add(Dropout(0.3))\n",
        "model.add(Dense(128))\n",
        "model.add(BatchNormalization())\n",
        "model.add(ELU(alpha=elu_alpha))\n",
        "model.add(Dropout(0.3))\n",
        "model.add(Dense(64, activation='elu'))\n",
        "model.add(Dense(32, activation='elu'))\n",
        "model.add(Dense(19, activation='softmax'))\n",
        "\n",
        "\n",
        "from keras.losses import categorical_crossentropy\n",
        "from keras.optimizers import Adam\n",
        "from keras.callbacks import EarlyStopping\n",
        "from keras.callbacks import ModelCheckpoint\n",
        "\n",
        "## 얼리스타핑\n",
        "es = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=100)\n",
        "\n",
        "##최적모델 기억\n",
        "mc = ModelCheckpoint('best_model.h5', monitor='val_loss', mode='min', save_best_only=True)\n",
        "epochs = 1000\n",
        "model.compile(loss='categorical_crossentropy',\n",
        "              optimizer=Adam(0.0001, decay=1e-2/epochs), metrics=['accuracy','categorical_crossentropy'])\n",
        "\n",
        "history=model.fit(X_train, y_train, validation_data=(X_test, y_test) ,batch_size=100, epochs=1000, verbose=1,\n",
        "                 callbacks=[es, mc])\n",
        "### validation_data를 쓰면 test 데이터가 따로있을때 직접 넣을 수 있다.\n",
        "model.evaluate(X_test, y_test)"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:793: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3576: The name tf.log is deprecated. Please use tf.math.log instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1033: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1020: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3005: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
            "\n",
            "Train on 139839 samples, validate on 59931 samples\n",
            "Epoch 1/1000\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:190: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:197: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:207: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:216: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:223: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n",
            "\n",
            "139839/139839 [==============================] - 38s 270us/step - loss: 0.9738 - acc: 0.7225 - categorical_crossentropy: 0.9738 - val_loss: 1.1519 - val_acc: 0.6386 - val_categorical_crossentropy: 1.1519\n",
            "Epoch 2/1000\n",
            "139839/139839 [==============================] - 27s 193us/step - loss: 0.6456 - acc: 0.7913 - categorical_crossentropy: 0.6456 - val_loss: 0.5282 - val_acc: 0.8239 - val_categorical_crossentropy: 0.5282\n",
            "Epoch 3/1000\n",
            "139839/139839 [==============================] - 27s 194us/step - loss: 0.5981 - acc: 0.8026 - categorical_crossentropy: 0.5981 - val_loss: 0.9987 - val_acc: 0.6766 - val_categorical_crossentropy: 0.9987\n",
            "Epoch 4/1000\n",
            "139839/139839 [==============================] - 27s 191us/step - loss: 0.5742 - acc: 0.8085 - categorical_crossentropy: 0.5742 - val_loss: 0.5654 - val_acc: 0.8121 - val_categorical_crossentropy: 0.5654\n",
            "Epoch 5/1000\n",
            "139839/139839 [==============================] - 26s 189us/step - loss: 0.5559 - acc: 0.8136 - categorical_crossentropy: 0.5559 - val_loss: 0.5416 - val_acc: 0.8160 - val_categorical_crossentropy: 0.5416\n",
            "Epoch 6/1000\n",
            "139839/139839 [==============================] - 26s 189us/step - loss: 0.5451 - acc: 0.8152 - categorical_crossentropy: 0.5451 - val_loss: 0.5392 - val_acc: 0.8110 - val_categorical_crossentropy: 0.5392\n",
            "Epoch 7/1000\n",
            "139839/139839 [==============================] - 27s 190us/step - loss: 0.5356 - acc: 0.8191 - categorical_crossentropy: 0.5356 - val_loss: 0.4790 - val_acc: 0.8347 - val_categorical_crossentropy: 0.4790\n",
            "Epoch 8/1000\n",
            "139839/139839 [==============================] - 25s 181us/step - loss: 0.5281 - acc: 0.8211 - categorical_crossentropy: 0.5281 - val_loss: 0.4747 - val_acc: 0.8380 - val_categorical_crossentropy: 0.4747\n",
            "Epoch 9/1000\n",
            "139839/139839 [==============================] - 25s 181us/step - loss: 0.5201 - acc: 0.8231 - categorical_crossentropy: 0.5201 - val_loss: 0.9284 - val_acc: 0.6982 - val_categorical_crossentropy: 0.9284\n",
            "Epoch 10/1000\n",
            "139839/139839 [==============================] - 25s 182us/step - loss: 0.5155 - acc: 0.8247 - categorical_crossentropy: 0.5155 - val_loss: 0.4729 - val_acc: 0.8352 - val_categorical_crossentropy: 0.4729\n",
            "Epoch 11/1000\n",
            "139839/139839 [==============================] - 25s 180us/step - loss: 0.5108 - acc: 0.8253 - categorical_crossentropy: 0.5108 - val_loss: 0.4814 - val_acc: 0.8337 - val_categorical_crossentropy: 0.4814\n",
            "Epoch 12/1000\n",
            "139839/139839 [==============================] - 25s 179us/step - loss: 0.5062 - acc: 0.8274 - categorical_crossentropy: 0.5062 - val_loss: 0.5568 - val_acc: 0.7919 - val_categorical_crossentropy: 0.5568\n",
            "Epoch 13/1000\n",
            "139839/139839 [==============================] - 26s 183us/step - loss: 0.5046 - acc: 0.8283 - categorical_crossentropy: 0.5046 - val_loss: 0.6345 - val_acc: 0.8037 - val_categorical_crossentropy: 0.6345\n",
            "Epoch 14/1000\n",
            "139839/139839 [==============================] - 25s 179us/step - loss: 0.5010 - acc: 0.8283 - categorical_crossentropy: 0.5010 - val_loss: 0.4838 - val_acc: 0.8322 - val_categorical_crossentropy: 0.4838\n",
            "Epoch 15/1000\n",
            "139839/139839 [==============================] - 26s 186us/step - loss: 0.4992 - acc: 0.8277 - categorical_crossentropy: 0.4992 - val_loss: 0.5105 - val_acc: 0.8191 - val_categorical_crossentropy: 0.5105\n",
            "Epoch 16/1000\n",
            "139839/139839 [==============================] - 26s 184us/step - loss: 0.4957 - acc: 0.8294 - categorical_crossentropy: 0.4957 - val_loss: 0.7129 - val_acc: 0.7675 - val_categorical_crossentropy: 0.7129\n",
            "Epoch 17/1000\n",
            "139839/139839 [==============================] - 27s 190us/step - loss: 0.4926 - acc: 0.8316 - categorical_crossentropy: 0.4926 - val_loss: 0.4479 - val_acc: 0.8482 - val_categorical_crossentropy: 0.4479\n",
            "Epoch 18/1000\n",
            "139839/139839 [==============================] - 26s 188us/step - loss: 0.4903 - acc: 0.8327 - categorical_crossentropy: 0.4903 - val_loss: 0.4907 - val_acc: 0.8286 - val_categorical_crossentropy: 0.4907\n",
            "Epoch 19/1000\n",
            "139839/139839 [==============================] - 26s 188us/step - loss: 0.4860 - acc: 0.8323 - categorical_crossentropy: 0.4860 - val_loss: 0.4515 - val_acc: 0.8465 - val_categorical_crossentropy: 0.4515\n",
            "Epoch 20/1000\n",
            "139839/139839 [==============================] - 26s 186us/step - loss: 0.4875 - acc: 0.8323 - categorical_crossentropy: 0.4875 - val_loss: 0.5266 - val_acc: 0.8265 - val_categorical_crossentropy: 0.5266\n",
            "Epoch 21/1000\n",
            "139839/139839 [==============================] - 27s 191us/step - loss: 0.4846 - acc: 0.8329 - categorical_crossentropy: 0.4846 - val_loss: 0.5884 - val_acc: 0.7770 - val_categorical_crossentropy: 0.5884\n",
            "Epoch 22/1000\n",
            "139839/139839 [==============================] - 26s 188us/step - loss: 0.4817 - acc: 0.8338 - categorical_crossentropy: 0.4817 - val_loss: 0.5258 - val_acc: 0.8066 - val_categorical_crossentropy: 0.5258\n",
            "Epoch 23/1000\n",
            "139839/139839 [==============================] - 26s 187us/step - loss: 0.4808 - acc: 0.8348 - categorical_crossentropy: 0.4808 - val_loss: 0.5307 - val_acc: 0.8115 - val_categorical_crossentropy: 0.5307\n",
            "Epoch 24/1000\n",
            "139839/139839 [==============================] - 26s 184us/step - loss: 0.4808 - acc: 0.8350 - categorical_crossentropy: 0.4808 - val_loss: 0.4749 - val_acc: 0.8375 - val_categorical_crossentropy: 0.4749\n",
            "Epoch 25/1000\n",
            "139839/139839 [==============================] - 26s 189us/step - loss: 0.4763 - acc: 0.8353 - categorical_crossentropy: 0.4763 - val_loss: 0.4751 - val_acc: 0.8357 - val_categorical_crossentropy: 0.4751\n",
            "Epoch 26/1000\n",
            "139839/139839 [==============================] - 26s 187us/step - loss: 0.4773 - acc: 0.8360 - categorical_crossentropy: 0.4773 - val_loss: 0.4664 - val_acc: 0.8356 - val_categorical_crossentropy: 0.4664\n",
            "Epoch 27/1000\n",
            "139839/139839 [==============================] - 26s 188us/step - loss: 0.4721 - acc: 0.8356 - categorical_crossentropy: 0.4721 - val_loss: 0.4408 - val_acc: 0.8457 - val_categorical_crossentropy: 0.4408\n",
            "Epoch 28/1000\n",
            "139839/139839 [==============================] - 26s 189us/step - loss: 0.4745 - acc: 0.8356 - categorical_crossentropy: 0.4745 - val_loss: 0.4714 - val_acc: 0.8347 - val_categorical_crossentropy: 0.4714\n",
            "Epoch 29/1000\n",
            "139839/139839 [==============================] - 26s 185us/step - loss: 0.4743 - acc: 0.8353 - categorical_crossentropy: 0.4743 - val_loss: 0.5070 - val_acc: 0.8174 - val_categorical_crossentropy: 0.5070\n",
            "Epoch 30/1000\n",
            "139839/139839 [==============================] - 26s 186us/step - loss: 0.4705 - acc: 0.8367 - categorical_crossentropy: 0.4705 - val_loss: 0.4473 - val_acc: 0.8447 - val_categorical_crossentropy: 0.4473\n",
            "Epoch 31/1000\n",
            "139839/139839 [==============================] - 26s 183us/step - loss: 0.4699 - acc: 0.8375 - categorical_crossentropy: 0.4699 - val_loss: 0.4375 - val_acc: 0.8475 - val_categorical_crossentropy: 0.4375\n",
            "Epoch 32/1000\n",
            "139839/139839 [==============================] - 26s 186us/step - loss: 0.4684 - acc: 0.8378 - categorical_crossentropy: 0.4684 - val_loss: 0.4706 - val_acc: 0.8363 - val_categorical_crossentropy: 0.4706\n",
            "Epoch 33/1000\n",
            "139839/139839 [==============================] - 26s 186us/step - loss: 0.4696 - acc: 0.8376 - categorical_crossentropy: 0.4696 - val_loss: 0.5628 - val_acc: 0.8085 - val_categorical_crossentropy: 0.5628\n",
            "Epoch 34/1000\n",
            "139839/139839 [==============================] - 26s 183us/step - loss: 0.4670 - acc: 0.8375 - categorical_crossentropy: 0.4670 - val_loss: 0.4182 - val_acc: 0.8549 - val_categorical_crossentropy: 0.4182\n",
            "Epoch 35/1000\n",
            "139839/139839 [==============================] - 25s 182us/step - loss: 0.4660 - acc: 0.8393 - categorical_crossentropy: 0.4660 - val_loss: 0.4713 - val_acc: 0.8272 - val_categorical_crossentropy: 0.4713\n",
            "Epoch 36/1000\n",
            "139839/139839 [==============================] - 26s 184us/step - loss: 0.4667 - acc: 0.8390 - categorical_crossentropy: 0.4667 - val_loss: 0.5243 - val_acc: 0.8149 - val_categorical_crossentropy: 0.5243\n",
            "Epoch 37/1000\n",
            "139839/139839 [==============================] - 26s 187us/step - loss: 0.4632 - acc: 0.8389 - categorical_crossentropy: 0.4632 - val_loss: 0.4311 - val_acc: 0.8460 - val_categorical_crossentropy: 0.4311\n",
            "Epoch 38/1000\n",
            "139839/139839 [==============================] - 26s 183us/step - loss: 0.4628 - acc: 0.8402 - categorical_crossentropy: 0.4628 - val_loss: 0.5623 - val_acc: 0.7987 - val_categorical_crossentropy: 0.5623\n",
            "Epoch 39/1000\n",
            "139839/139839 [==============================] - 25s 176us/step - loss: 0.4621 - acc: 0.8403 - categorical_crossentropy: 0.4621 - val_loss: 0.4232 - val_acc: 0.8526 - val_categorical_crossentropy: 0.4232\n",
            "Epoch 40/1000\n",
            "139839/139839 [==============================] - 25s 179us/step - loss: 0.4618 - acc: 0.8412 - categorical_crossentropy: 0.4618 - val_loss: 0.4514 - val_acc: 0.8407 - val_categorical_crossentropy: 0.4514\n",
            "Epoch 41/1000\n",
            "139839/139839 [==============================] - 25s 181us/step - loss: 0.4600 - acc: 0.8408 - categorical_crossentropy: 0.4600 - val_loss: 0.4353 - val_acc: 0.8462 - val_categorical_crossentropy: 0.4353\n",
            "Epoch 42/1000\n",
            "139839/139839 [==============================] - 26s 185us/step - loss: 0.4609 - acc: 0.8403 - categorical_crossentropy: 0.4609 - val_loss: 0.4546 - val_acc: 0.8388 - val_categorical_crossentropy: 0.4546\n",
            "Epoch 43/1000\n",
            "139839/139839 [==============================] - 25s 176us/step - loss: 0.4596 - acc: 0.8413 - categorical_crossentropy: 0.4596 - val_loss: 0.4294 - val_acc: 0.8509 - val_categorical_crossentropy: 0.4294\n",
            "Epoch 44/1000\n",
            "139839/139839 [==============================] - 25s 179us/step - loss: 0.4590 - acc: 0.8403 - categorical_crossentropy: 0.4590 - val_loss: 0.4566 - val_acc: 0.8339 - val_categorical_crossentropy: 0.4566\n",
            "Epoch 45/1000\n",
            "139839/139839 [==============================] - 25s 181us/step - loss: 0.4595 - acc: 0.8402 - categorical_crossentropy: 0.4595 - val_loss: 0.6386 - val_acc: 0.7670 - val_categorical_crossentropy: 0.6386\n",
            "Epoch 46/1000\n",
            "139839/139839 [==============================] - 25s 178us/step - loss: 0.4555 - acc: 0.8421 - categorical_crossentropy: 0.4555 - val_loss: 0.5053 - val_acc: 0.8238 - val_categorical_crossentropy: 0.5053\n",
            "Epoch 47/1000\n",
            "139839/139839 [==============================] - 25s 180us/step - loss: 0.4552 - acc: 0.8425 - categorical_crossentropy: 0.4552 - val_loss: 0.4495 - val_acc: 0.8464 - val_categorical_crossentropy: 0.4495\n",
            "Epoch 48/1000\n",
            "139839/139839 [==============================] - 25s 181us/step - loss: 0.4555 - acc: 0.8415 - categorical_crossentropy: 0.4555 - val_loss: 0.4638 - val_acc: 0.8403 - val_categorical_crossentropy: 0.4638\n",
            "Epoch 49/1000\n",
            "139839/139839 [==============================] - 25s 179us/step - loss: 0.4550 - acc: 0.8408 - categorical_crossentropy: 0.4550 - val_loss: 0.4340 - val_acc: 0.8460 - val_categorical_crossentropy: 0.4340\n",
            "Epoch 50/1000\n",
            "139839/139839 [==============================] - 25s 180us/step - loss: 0.4532 - acc: 0.8424 - categorical_crossentropy: 0.4532 - val_loss: 0.4202 - val_acc: 0.8510 - val_categorical_crossentropy: 0.4202\n",
            "Epoch 51/1000\n",
            "139839/139839 [==============================] - 24s 174us/step - loss: 0.4545 - acc: 0.8425 - categorical_crossentropy: 0.4545 - val_loss: 0.7752 - val_acc: 0.7318 - val_categorical_crossentropy: 0.7752\n",
            "Epoch 52/1000\n",
            "139839/139839 [==============================] - 25s 180us/step - loss: 0.4523 - acc: 0.8426 - categorical_crossentropy: 0.4523 - val_loss: 0.5074 - val_acc: 0.8148 - val_categorical_crossentropy: 0.5074\n",
            "Epoch 53/1000\n",
            "139839/139839 [==============================] - 25s 182us/step - loss: 0.4526 - acc: 0.8429 - categorical_crossentropy: 0.4526 - val_loss: 0.4177 - val_acc: 0.8564 - val_categorical_crossentropy: 0.4177\n",
            "Epoch 54/1000\n",
            "139839/139839 [==============================] - 26s 184us/step - loss: 0.4536 - acc: 0.8432 - categorical_crossentropy: 0.4536 - val_loss: 0.4899 - val_acc: 0.8226 - val_categorical_crossentropy: 0.4899\n",
            "Epoch 55/1000\n",
            "139839/139839 [==============================] - 26s 183us/step - loss: 0.4525 - acc: 0.8433 - categorical_crossentropy: 0.4525 - val_loss: 0.4480 - val_acc: 0.8461 - val_categorical_crossentropy: 0.4480\n",
            "Epoch 56/1000\n",
            "139839/139839 [==============================] - 25s 182us/step - loss: 0.4506 - acc: 0.8432 - categorical_crossentropy: 0.4506 - val_loss: 0.4384 - val_acc: 0.8463 - val_categorical_crossentropy: 0.4384\n",
            "Epoch 57/1000\n",
            "139839/139839 [==============================] - 26s 182us/step - loss: 0.4521 - acc: 0.8423 - categorical_crossentropy: 0.4521 - val_loss: 0.4160 - val_acc: 0.8525 - val_categorical_crossentropy: 0.4160\n",
            "Epoch 58/1000\n",
            "139839/139839 [==============================] - 26s 186us/step - loss: 0.4515 - acc: 0.8421 - categorical_crossentropy: 0.4515 - val_loss: 0.4965 - val_acc: 0.8296 - val_categorical_crossentropy: 0.4965\n",
            "Epoch 59/1000\n",
            "139839/139839 [==============================] - 25s 180us/step - loss: 0.4507 - acc: 0.8436 - categorical_crossentropy: 0.4507 - val_loss: 0.4706 - val_acc: 0.8350 - val_categorical_crossentropy: 0.4706\n",
            "Epoch 60/1000\n",
            "139839/139839 [==============================] - 25s 176us/step - loss: 0.4483 - acc: 0.8440 - categorical_crossentropy: 0.4483 - val_loss: 0.4685 - val_acc: 0.8380 - val_categorical_crossentropy: 0.4685\n",
            "Epoch 61/1000\n",
            "139839/139839 [==============================] - 25s 178us/step - loss: 0.4493 - acc: 0.8439 - categorical_crossentropy: 0.4493 - val_loss: 0.4450 - val_acc: 0.8545 - val_categorical_crossentropy: 0.4450\n",
            "Epoch 62/1000\n",
            "139839/139839 [==============================] - 24s 175us/step - loss: 0.4505 - acc: 0.8438 - categorical_crossentropy: 0.4505 - val_loss: 0.4257 - val_acc: 0.8507 - val_categorical_crossentropy: 0.4257\n",
            "Epoch 63/1000\n",
            "139839/139839 [==============================] - 24s 173us/step - loss: 0.4476 - acc: 0.8440 - categorical_crossentropy: 0.4476 - val_loss: 0.4388 - val_acc: 0.8447 - val_categorical_crossentropy: 0.4388\n",
            "Epoch 64/1000\n",
            "139839/139839 [==============================] - 25s 178us/step - loss: 0.4493 - acc: 0.8437 - categorical_crossentropy: 0.4493 - val_loss: 0.5712 - val_acc: 0.8077 - val_categorical_crossentropy: 0.5712\n",
            "Epoch 65/1000\n",
            "139839/139839 [==============================] - 25s 177us/step - loss: 0.4472 - acc: 0.8442 - categorical_crossentropy: 0.4472 - val_loss: 0.4423 - val_acc: 0.8470 - val_categorical_crossentropy: 0.4423\n",
            "Epoch 66/1000\n",
            "139839/139839 [==============================] - 24s 174us/step - loss: 0.4475 - acc: 0.8444 - categorical_crossentropy: 0.4475 - val_loss: 0.4496 - val_acc: 0.8376 - val_categorical_crossentropy: 0.4496\n",
            "Epoch 67/1000\n",
            "139839/139839 [==============================] - 25s 179us/step - loss: 0.4494 - acc: 0.8430 - categorical_crossentropy: 0.4494 - val_loss: 0.4325 - val_acc: 0.8506 - val_categorical_crossentropy: 0.4325\n",
            "Epoch 68/1000\n",
            "139839/139839 [==============================] - 25s 178us/step - loss: 0.4440 - acc: 0.8457 - categorical_crossentropy: 0.4440 - val_loss: 0.4658 - val_acc: 0.8426 - val_categorical_crossentropy: 0.4658\n",
            "Epoch 69/1000\n",
            "139839/139839 [==============================] - 24s 173us/step - loss: 0.4431 - acc: 0.8448 - categorical_crossentropy: 0.4431 - val_loss: 0.5423 - val_acc: 0.7927 - val_categorical_crossentropy: 0.5423\n",
            "Epoch 70/1000\n",
            "139839/139839 [==============================] - 25s 176us/step - loss: 0.4437 - acc: 0.8454 - categorical_crossentropy: 0.4437 - val_loss: 0.5348 - val_acc: 0.8139 - val_categorical_crossentropy: 0.5348\n",
            "Epoch 71/1000\n",
            "139839/139839 [==============================] - 25s 175us/step - loss: 0.4440 - acc: 0.8458 - categorical_crossentropy: 0.4440 - val_loss: 0.4149 - val_acc: 0.8537 - val_categorical_crossentropy: 0.4149\n",
            "Epoch 72/1000\n",
            "139839/139839 [==============================] - 25s 180us/step - loss: 0.4459 - acc: 0.8444 - categorical_crossentropy: 0.4459 - val_loss: 0.4268 - val_acc: 0.8486 - val_categorical_crossentropy: 0.4268\n",
            "Epoch 73/1000\n",
            "139839/139839 [==============================] - 25s 176us/step - loss: 0.4431 - acc: 0.8460 - categorical_crossentropy: 0.4431 - val_loss: 0.4096 - val_acc: 0.8571 - val_categorical_crossentropy: 0.4096\n",
            "Epoch 74/1000\n",
            "139839/139839 [==============================] - 25s 181us/step - loss: 0.4463 - acc: 0.8444 - categorical_crossentropy: 0.4463 - val_loss: 0.4345 - val_acc: 0.8476 - val_categorical_crossentropy: 0.4345\n",
            "Epoch 75/1000\n",
            "139839/139839 [==============================] - 25s 181us/step - loss: 0.4407 - acc: 0.8457 - categorical_crossentropy: 0.4407 - val_loss: 0.4096 - val_acc: 0.8583 - val_categorical_crossentropy: 0.4096\n",
            "Epoch 76/1000\n",
            "139839/139839 [==============================] - 25s 181us/step - loss: 0.4420 - acc: 0.8451 - categorical_crossentropy: 0.4420 - val_loss: 0.4583 - val_acc: 0.8368 - val_categorical_crossentropy: 0.4583\n",
            "Epoch 77/1000\n",
            "139839/139839 [==============================] - 25s 178us/step - loss: 0.4433 - acc: 0.8451 - categorical_crossentropy: 0.4433 - val_loss: 0.4036 - val_acc: 0.8590 - val_categorical_crossentropy: 0.4036\n",
            "Epoch 78/1000\n",
            "139839/139839 [==============================] - 25s 181us/step - loss: 0.4428 - acc: 0.8454 - categorical_crossentropy: 0.4428 - val_loss: 0.4306 - val_acc: 0.8523 - val_categorical_crossentropy: 0.4306\n",
            "Epoch 79/1000\n",
            "139839/139839 [==============================] - 26s 184us/step - loss: 0.4404 - acc: 0.8454 - categorical_crossentropy: 0.4404 - val_loss: 0.5627 - val_acc: 0.8022 - val_categorical_crossentropy: 0.5627\n",
            "Epoch 80/1000\n",
            "139839/139839 [==============================] - 25s 179us/step - loss: 0.4417 - acc: 0.8462 - categorical_crossentropy: 0.4417 - val_loss: 0.4361 - val_acc: 0.8510 - val_categorical_crossentropy: 0.4361\n",
            "Epoch 81/1000\n",
            "139839/139839 [==============================] - 26s 184us/step - loss: 0.4406 - acc: 0.8470 - categorical_crossentropy: 0.4406 - val_loss: 0.4047 - val_acc: 0.8580 - val_categorical_crossentropy: 0.4047\n",
            "Epoch 82/1000\n",
            "139839/139839 [==============================] - 25s 179us/step - loss: 0.4390 - acc: 0.8467 - categorical_crossentropy: 0.4390 - val_loss: 0.4138 - val_acc: 0.8559 - val_categorical_crossentropy: 0.4138\n",
            "Epoch 83/1000\n",
            "139839/139839 [==============================] - 25s 182us/step - loss: 0.4406 - acc: 0.8468 - categorical_crossentropy: 0.4406 - val_loss: 0.4481 - val_acc: 0.8474 - val_categorical_crossentropy: 0.4481\n",
            "Epoch 84/1000\n",
            "139839/139839 [==============================] - 25s 176us/step - loss: 0.4385 - acc: 0.8469 - categorical_crossentropy: 0.4385 - val_loss: 0.4330 - val_acc: 0.8465 - val_categorical_crossentropy: 0.4330\n",
            "Epoch 85/1000\n",
            "139839/139839 [==============================] - 25s 179us/step - loss: 0.4385 - acc: 0.8471 - categorical_crossentropy: 0.4385 - val_loss: 0.4221 - val_acc: 0.8553 - val_categorical_crossentropy: 0.4221\n",
            "Epoch 86/1000\n",
            "139839/139839 [==============================] - 26s 184us/step - loss: 0.4385 - acc: 0.8468 - categorical_crossentropy: 0.4385 - val_loss: 0.4359 - val_acc: 0.8486 - val_categorical_crossentropy: 0.4359\n",
            "Epoch 87/1000\n",
            "139839/139839 [==============================] - 26s 183us/step - loss: 0.4388 - acc: 0.8476 - categorical_crossentropy: 0.4388 - val_loss: 0.4145 - val_acc: 0.8558 - val_categorical_crossentropy: 0.4145\n",
            "Epoch 88/1000\n",
            "139839/139839 [==============================] - 25s 177us/step - loss: 0.4405 - acc: 0.8463 - categorical_crossentropy: 0.4405 - val_loss: 0.5361 - val_acc: 0.8341 - val_categorical_crossentropy: 0.5361\n",
            "Epoch 89/1000\n",
            "139839/139839 [==============================] - 25s 179us/step - loss: 0.4371 - acc: 0.8474 - categorical_crossentropy: 0.4371 - val_loss: 0.4147 - val_acc: 0.8576 - val_categorical_crossentropy: 0.4147\n",
            "Epoch 90/1000\n",
            "139839/139839 [==============================] - 25s 179us/step - loss: 0.4379 - acc: 0.8468 - categorical_crossentropy: 0.4379 - val_loss: 0.4828 - val_acc: 0.8210 - val_categorical_crossentropy: 0.4828\n",
            "Epoch 91/1000\n",
            "139839/139839 [==============================] - 25s 180us/step - loss: 0.4354 - acc: 0.8477 - categorical_crossentropy: 0.4354 - val_loss: 0.4322 - val_acc: 0.8484 - val_categorical_crossentropy: 0.4322\n",
            "Epoch 92/1000\n",
            "139839/139839 [==============================] - 25s 175us/step - loss: 0.4362 - acc: 0.8475 - categorical_crossentropy: 0.4362 - val_loss: 0.4454 - val_acc: 0.8466 - val_categorical_crossentropy: 0.4454\n",
            "Epoch 93/1000\n",
            "139839/139839 [==============================] - 25s 181us/step - loss: 0.4361 - acc: 0.8471 - categorical_crossentropy: 0.4361 - val_loss: 0.4055 - val_acc: 0.8567 - val_categorical_crossentropy: 0.4055\n",
            "Epoch 94/1000\n",
            "139839/139839 [==============================] - 25s 180us/step - loss: 0.4363 - acc: 0.8485 - categorical_crossentropy: 0.4363 - val_loss: 0.4688 - val_acc: 0.8408 - val_categorical_crossentropy: 0.4688\n",
            "Epoch 95/1000\n",
            "139839/139839 [==============================] - 26s 182us/step - loss: 0.4385 - acc: 0.8469 - categorical_crossentropy: 0.4385 - val_loss: 0.4347 - val_acc: 0.8462 - val_categorical_crossentropy: 0.4347\n",
            "Epoch 96/1000\n",
            "139839/139839 [==============================] - 25s 179us/step - loss: 0.4352 - acc: 0.8486 - categorical_crossentropy: 0.4352 - val_loss: 0.4326 - val_acc: 0.8467 - val_categorical_crossentropy: 0.4326\n",
            "Epoch 97/1000\n",
            "139839/139839 [==============================] - 25s 176us/step - loss: 0.4374 - acc: 0.8467 - categorical_crossentropy: 0.4374 - val_loss: 0.4180 - val_acc: 0.8517 - val_categorical_crossentropy: 0.4180\n",
            "Epoch 98/1000\n",
            "139839/139839 [==============================] - 24s 170us/step - loss: 0.4337 - acc: 0.8495 - categorical_crossentropy: 0.4337 - val_loss: 0.4282 - val_acc: 0.8502 - val_categorical_crossentropy: 0.4282\n",
            "Epoch 99/1000\n",
            "139839/139839 [==============================] - 24s 175us/step - loss: 0.4316 - acc: 0.8487 - categorical_crossentropy: 0.4316 - val_loss: 0.4451 - val_acc: 0.8452 - val_categorical_crossentropy: 0.4451\n",
            "Epoch 100/1000\n",
            "139839/139839 [==============================] - 24s 172us/step - loss: 0.4342 - acc: 0.8482 - categorical_crossentropy: 0.4342 - val_loss: 0.4191 - val_acc: 0.8569 - val_categorical_crossentropy: 0.4191\n",
            "Epoch 101/1000\n",
            "139839/139839 [==============================] - 24s 169us/step - loss: 0.4357 - acc: 0.8475 - categorical_crossentropy: 0.4357 - val_loss: 0.4136 - val_acc: 0.8574 - val_categorical_crossentropy: 0.4136\n",
            "Epoch 102/1000\n",
            "139839/139839 [==============================] - 24s 175us/step - loss: 0.4337 - acc: 0.8483 - categorical_crossentropy: 0.4337 - val_loss: 0.4325 - val_acc: 0.8437 - val_categorical_crossentropy: 0.4325\n",
            "Epoch 103/1000\n",
            "139839/139839 [==============================] - 25s 176us/step - loss: 0.4320 - acc: 0.8491 - categorical_crossentropy: 0.4320 - val_loss: 0.4168 - val_acc: 0.8557 - val_categorical_crossentropy: 0.4168\n",
            "Epoch 104/1000\n",
            "139839/139839 [==============================] - 24s 169us/step - loss: 0.4361 - acc: 0.8481 - categorical_crossentropy: 0.4361 - val_loss: 0.4247 - val_acc: 0.8506 - val_categorical_crossentropy: 0.4247\n",
            "Epoch 105/1000\n",
            "139839/139839 [==============================] - 24s 172us/step - loss: 0.4336 - acc: 0.8482 - categorical_crossentropy: 0.4336 - val_loss: 0.3889 - val_acc: 0.8640 - val_categorical_crossentropy: 0.3889\n",
            "Epoch 106/1000\n",
            "139839/139839 [==============================] - 24s 171us/step - loss: 0.4334 - acc: 0.8485 - categorical_crossentropy: 0.4334 - val_loss: 0.4095 - val_acc: 0.8566 - val_categorical_crossentropy: 0.4095\n",
            "Epoch 107/1000\n",
            "139839/139839 [==============================] - 24s 169us/step - loss: 0.4351 - acc: 0.8482 - categorical_crossentropy: 0.4351 - val_loss: 0.4328 - val_acc: 0.8499 - val_categorical_crossentropy: 0.4328\n",
            "Epoch 108/1000\n",
            "139839/139839 [==============================] - 24s 173us/step - loss: 0.4339 - acc: 0.8483 - categorical_crossentropy: 0.4339 - val_loss: 0.4022 - val_acc: 0.8603 - val_categorical_crossentropy: 0.4022\n",
            "Epoch 109/1000\n",
            "139839/139839 [==============================] - 24s 169us/step - loss: 0.4326 - acc: 0.8487 - categorical_crossentropy: 0.4326 - val_loss: 0.4786 - val_acc: 0.8443 - val_categorical_crossentropy: 0.4786\n",
            "Epoch 110/1000\n",
            "139839/139839 [==============================] - 24s 169us/step - loss: 0.4304 - acc: 0.8498 - categorical_crossentropy: 0.4304 - val_loss: 0.4136 - val_acc: 0.8556 - val_categorical_crossentropy: 0.4136\n",
            "Epoch 111/1000\n",
            "139839/139839 [==============================] - 25s 175us/step - loss: 0.4315 - acc: 0.8490 - categorical_crossentropy: 0.4315 - val_loss: 0.4246 - val_acc: 0.8510 - val_categorical_crossentropy: 0.4246\n",
            "Epoch 112/1000\n",
            "139839/139839 [==============================] - 24s 173us/step - loss: 0.4314 - acc: 0.8484 - categorical_crossentropy: 0.4314 - val_loss: 0.4319 - val_acc: 0.8521 - val_categorical_crossentropy: 0.4319\n",
            "Epoch 113/1000\n",
            "139839/139839 [==============================] - 24s 172us/step - loss: 0.4321 - acc: 0.8488 - categorical_crossentropy: 0.4321 - val_loss: 0.4195 - val_acc: 0.8514 - val_categorical_crossentropy: 0.4195\n",
            "Epoch 114/1000\n",
            "139839/139839 [==============================] - 23s 166us/step - loss: 0.4310 - acc: 0.8490 - categorical_crossentropy: 0.4310 - val_loss: 0.4051 - val_acc: 0.8595 - val_categorical_crossentropy: 0.4051\n",
            "Epoch 115/1000\n",
            "139839/139839 [==============================] - 24s 171us/step - loss: 0.4329 - acc: 0.8492 - categorical_crossentropy: 0.4329 - val_loss: 0.4297 - val_acc: 0.8471 - val_categorical_crossentropy: 0.4297\n",
            "Epoch 116/1000\n",
            "139839/139839 [==============================] - 24s 173us/step - loss: 0.4316 - acc: 0.8492 - categorical_crossentropy: 0.4316 - val_loss: 0.4262 - val_acc: 0.8521 - val_categorical_crossentropy: 0.4262\n",
            "Epoch 117/1000\n",
            "139839/139839 [==============================] - 24s 168us/step - loss: 0.4306 - acc: 0.8499 - categorical_crossentropy: 0.4306 - val_loss: 0.4070 - val_acc: 0.8597 - val_categorical_crossentropy: 0.4070\n",
            "Epoch 118/1000\n",
            "139839/139839 [==============================] - 24s 174us/step - loss: 0.4305 - acc: 0.8496 - categorical_crossentropy: 0.4305 - val_loss: 0.4010 - val_acc: 0.8605 - val_categorical_crossentropy: 0.4010\n",
            "Epoch 119/1000\n",
            "139839/139839 [==============================] - 23s 164us/step - loss: 0.4316 - acc: 0.8488 - categorical_crossentropy: 0.4316 - val_loss: 0.4348 - val_acc: 0.8465 - val_categorical_crossentropy: 0.4348\n",
            "Epoch 120/1000\n",
            "139839/139839 [==============================] - 24s 172us/step - loss: 0.4306 - acc: 0.8498 - categorical_crossentropy: 0.4306 - val_loss: 0.4430 - val_acc: 0.8395 - val_categorical_crossentropy: 0.4430\n",
            "Epoch 121/1000\n",
            "139839/139839 [==============================] - 24s 170us/step - loss: 0.4294 - acc: 0.8499 - categorical_crossentropy: 0.4294 - val_loss: 0.4202 - val_acc: 0.8509 - val_categorical_crossentropy: 0.4202\n",
            "Epoch 122/1000\n",
            "139839/139839 [==============================] - 23s 167us/step - loss: 0.4285 - acc: 0.8497 - categorical_crossentropy: 0.4285 - val_loss: 0.4396 - val_acc: 0.8429 - val_categorical_crossentropy: 0.4396\n",
            "Epoch 123/1000\n",
            "139839/139839 [==============================] - 24s 168us/step - loss: 0.4315 - acc: 0.8485 - categorical_crossentropy: 0.4315 - val_loss: 0.4322 - val_acc: 0.8472 - val_categorical_crossentropy: 0.4322\n",
            "Epoch 124/1000\n",
            "139839/139839 [==============================] - 24s 172us/step - loss: 0.4289 - acc: 0.8494 - categorical_crossentropy: 0.4289 - val_loss: 0.4211 - val_acc: 0.8555 - val_categorical_crossentropy: 0.4211\n",
            "Epoch 125/1000\n",
            "139839/139839 [==============================] - 25s 178us/step - loss: 0.4288 - acc: 0.8495 - categorical_crossentropy: 0.4288 - val_loss: 0.4616 - val_acc: 0.8354 - val_categorical_crossentropy: 0.4616\n",
            "Epoch 126/1000\n",
            "139839/139839 [==============================] - 24s 173us/step - loss: 0.4295 - acc: 0.8501 - categorical_crossentropy: 0.4295 - val_loss: 0.4127 - val_acc: 0.8592 - val_categorical_crossentropy: 0.4127\n",
            "Epoch 127/1000\n",
            "139839/139839 [==============================] - 25s 178us/step - loss: 0.4293 - acc: 0.8494 - categorical_crossentropy: 0.4293 - val_loss: 0.4020 - val_acc: 0.8596 - val_categorical_crossentropy: 0.4020\n",
            "Epoch 128/1000\n",
            "139839/139839 [==============================] - 25s 177us/step - loss: 0.4287 - acc: 0.8502 - categorical_crossentropy: 0.4287 - val_loss: 0.4390 - val_acc: 0.8464 - val_categorical_crossentropy: 0.4390\n",
            "Epoch 129/1000\n",
            "139839/139839 [==============================] - 24s 174us/step - loss: 0.4288 - acc: 0.8501 - categorical_crossentropy: 0.4288 - val_loss: 0.4296 - val_acc: 0.8541 - val_categorical_crossentropy: 0.4296\n",
            "Epoch 130/1000\n",
            "139839/139839 [==============================] - 24s 171us/step - loss: 0.4294 - acc: 0.8498 - categorical_crossentropy: 0.4294 - val_loss: 0.4473 - val_acc: 0.8408 - val_categorical_crossentropy: 0.4473\n",
            "Epoch 131/1000\n",
            "139839/139839 [==============================] - 24s 173us/step - loss: 0.4277 - acc: 0.8504 - categorical_crossentropy: 0.4277 - val_loss: 0.4060 - val_acc: 0.8592 - val_categorical_crossentropy: 0.4060\n",
            "Epoch 132/1000\n",
            "139839/139839 [==============================] - 23s 168us/step - loss: 0.4267 - acc: 0.8517 - categorical_crossentropy: 0.4267 - val_loss: 0.3967 - val_acc: 0.8620 - val_categorical_crossentropy: 0.3967\n",
            "Epoch 133/1000\n",
            "139839/139839 [==============================] - 24s 172us/step - loss: 0.4275 - acc: 0.8513 - categorical_crossentropy: 0.4275 - val_loss: 0.4533 - val_acc: 0.8385 - val_categorical_crossentropy: 0.4533\n",
            "Epoch 134/1000\n",
            "139839/139839 [==============================] - 23s 167us/step - loss: 0.4274 - acc: 0.8502 - categorical_crossentropy: 0.4274 - val_loss: 0.4053 - val_acc: 0.8593 - val_categorical_crossentropy: 0.4053\n",
            "Epoch 135/1000\n",
            "139839/139839 [==============================] - 24s 170us/step - loss: 0.4253 - acc: 0.8522 - categorical_crossentropy: 0.4253 - val_loss: 0.4077 - val_acc: 0.8582 - val_categorical_crossentropy: 0.4077\n",
            "Epoch 136/1000\n",
            "139839/139839 [==============================] - 24s 170us/step - loss: 0.4275 - acc: 0.8497 - categorical_crossentropy: 0.4275 - val_loss: 0.4024 - val_acc: 0.8572 - val_categorical_crossentropy: 0.4024\n",
            "Epoch 137/1000\n",
            "139839/139839 [==============================] - 24s 172us/step - loss: 0.4286 - acc: 0.8497 - categorical_crossentropy: 0.4286 - val_loss: 0.4515 - val_acc: 0.8431 - val_categorical_crossentropy: 0.4515\n",
            "Epoch 138/1000\n",
            "139839/139839 [==============================] - 24s 169us/step - loss: 0.4266 - acc: 0.8503 - categorical_crossentropy: 0.4266 - val_loss: 0.4208 - val_acc: 0.8501 - val_categorical_crossentropy: 0.4208\n",
            "Epoch 139/1000\n",
            "139839/139839 [==============================] - 24s 170us/step - loss: 0.4252 - acc: 0.8515 - categorical_crossentropy: 0.4252 - val_loss: 0.4286 - val_acc: 0.8513 - val_categorical_crossentropy: 0.4286\n",
            "Epoch 140/1000\n",
            "139839/139839 [==============================] - 24s 171us/step - loss: 0.4263 - acc: 0.8509 - categorical_crossentropy: 0.4263 - val_loss: 0.4087 - val_acc: 0.8587 - val_categorical_crossentropy: 0.4087\n",
            "Epoch 141/1000\n",
            "139839/139839 [==============================] - 24s 173us/step - loss: 0.4246 - acc: 0.8510 - categorical_crossentropy: 0.4246 - val_loss: 0.4216 - val_acc: 0.8499 - val_categorical_crossentropy: 0.4216\n",
            "Epoch 142/1000\n",
            "139839/139839 [==============================] - 24s 171us/step - loss: 0.4253 - acc: 0.8508 - categorical_crossentropy: 0.4253 - val_loss: 0.4022 - val_acc: 0.8587 - val_categorical_crossentropy: 0.4022\n",
            "Epoch 143/1000\n",
            "139839/139839 [==============================] - 23s 168us/step - loss: 0.4249 - acc: 0.8514 - categorical_crossentropy: 0.4249 - val_loss: 0.4009 - val_acc: 0.8609 - val_categorical_crossentropy: 0.4009\n",
            "Epoch 144/1000\n",
            "139839/139839 [==============================] - 24s 169us/step - loss: 0.4258 - acc: 0.8514 - categorical_crossentropy: 0.4258 - val_loss: 0.4653 - val_acc: 0.8290 - val_categorical_crossentropy: 0.4653\n",
            "Epoch 145/1000\n",
            "139839/139839 [==============================] - 24s 171us/step - loss: 0.4253 - acc: 0.8504 - categorical_crossentropy: 0.4253 - val_loss: 0.4208 - val_acc: 0.8539 - val_categorical_crossentropy: 0.4208\n",
            "Epoch 146/1000\n",
            "139839/139839 [==============================] - 24s 169us/step - loss: 0.4247 - acc: 0.8513 - categorical_crossentropy: 0.4247 - val_loss: 0.4012 - val_acc: 0.8598 - val_categorical_crossentropy: 0.4012\n",
            "Epoch 147/1000\n",
            "139839/139839 [==============================] - 24s 170us/step - loss: 0.4247 - acc: 0.8516 - categorical_crossentropy: 0.4247 - val_loss: 0.3928 - val_acc: 0.8650 - val_categorical_crossentropy: 0.3928\n",
            "Epoch 148/1000\n",
            "139839/139839 [==============================] - 24s 170us/step - loss: 0.4262 - acc: 0.8513 - categorical_crossentropy: 0.4262 - val_loss: 0.4033 - val_acc: 0.8612 - val_categorical_crossentropy: 0.4033\n",
            "Epoch 149/1000\n",
            "139839/139839 [==============================] - 24s 171us/step - loss: 0.4241 - acc: 0.8515 - categorical_crossentropy: 0.4241 - val_loss: 0.4021 - val_acc: 0.8599 - val_categorical_crossentropy: 0.4021\n",
            "Epoch 150/1000\n",
            "139839/139839 [==============================] - 24s 175us/step - loss: 0.4258 - acc: 0.8517 - categorical_crossentropy: 0.4258 - val_loss: 0.4239 - val_acc: 0.8542 - val_categorical_crossentropy: 0.4239\n",
            "Epoch 151/1000\n",
            "139839/139839 [==============================] - 24s 172us/step - loss: 0.4231 - acc: 0.8519 - categorical_crossentropy: 0.4231 - val_loss: 0.4468 - val_acc: 0.8495 - val_categorical_crossentropy: 0.4468\n",
            "Epoch 152/1000\n",
            "139839/139839 [==============================] - 23s 164us/step - loss: 0.4237 - acc: 0.8512 - categorical_crossentropy: 0.4237 - val_loss: 0.4052 - val_acc: 0.8580 - val_categorical_crossentropy: 0.4052\n",
            "Epoch 153/1000\n",
            "139839/139839 [==============================] - 24s 171us/step - loss: 0.4232 - acc: 0.8520 - categorical_crossentropy: 0.4232 - val_loss: 0.4063 - val_acc: 0.8588 - val_categorical_crossentropy: 0.4063\n",
            "Epoch 154/1000\n",
            "139839/139839 [==============================] - 24s 170us/step - loss: 0.4255 - acc: 0.8513 - categorical_crossentropy: 0.4255 - val_loss: 0.4211 - val_acc: 0.8536 - val_categorical_crossentropy: 0.4211\n",
            "Epoch 155/1000\n",
            "139839/139839 [==============================] - 24s 169us/step - loss: 0.4261 - acc: 0.8504 - categorical_crossentropy: 0.4261 - val_loss: 0.4267 - val_acc: 0.8519 - val_categorical_crossentropy: 0.4267\n",
            "Epoch 156/1000\n",
            "139839/139839 [==============================] - 23s 167us/step - loss: 0.4241 - acc: 0.8517 - categorical_crossentropy: 0.4241 - val_loss: 0.4083 - val_acc: 0.8572 - val_categorical_crossentropy: 0.4083\n",
            "Epoch 157/1000\n",
            "139839/139839 [==============================] - 23s 167us/step - loss: 0.4224 - acc: 0.8522 - categorical_crossentropy: 0.4224 - val_loss: 0.3955 - val_acc: 0.8620 - val_categorical_crossentropy: 0.3955\n",
            "Epoch 158/1000\n",
            "139839/139839 [==============================] - 23s 167us/step - loss: 0.4224 - acc: 0.8515 - categorical_crossentropy: 0.4224 - val_loss: 0.4282 - val_acc: 0.8470 - val_categorical_crossentropy: 0.4282\n",
            "Epoch 159/1000\n",
            "139839/139839 [==============================] - 23s 166us/step - loss: 0.4219 - acc: 0.8521 - categorical_crossentropy: 0.4219 - val_loss: 0.4117 - val_acc: 0.8567 - val_categorical_crossentropy: 0.4117\n",
            "Epoch 160/1000\n",
            "139839/139839 [==============================] - 24s 169us/step - loss: 0.4235 - acc: 0.8512 - categorical_crossentropy: 0.4235 - val_loss: 0.4013 - val_acc: 0.8596 - val_categorical_crossentropy: 0.4013\n",
            "Epoch 161/1000\n",
            "139839/139839 [==============================] - 24s 172us/step - loss: 0.4232 - acc: 0.8519 - categorical_crossentropy: 0.4232 - val_loss: 0.3995 - val_acc: 0.8588 - val_categorical_crossentropy: 0.3995\n",
            "Epoch 162/1000\n",
            "139839/139839 [==============================] - 23s 165us/step - loss: 0.4231 - acc: 0.8510 - categorical_crossentropy: 0.4231 - val_loss: 0.4011 - val_acc: 0.8590 - val_categorical_crossentropy: 0.4011\n",
            "Epoch 163/1000\n",
            "139839/139839 [==============================] - 24s 170us/step - loss: 0.4232 - acc: 0.8515 - categorical_crossentropy: 0.4232 - val_loss: 0.4673 - val_acc: 0.8326 - val_categorical_crossentropy: 0.4673\n",
            "Epoch 164/1000\n",
            "139839/139839 [==============================] - 24s 174us/step - loss: 0.4221 - acc: 0.8520 - categorical_crossentropy: 0.4221 - val_loss: 0.4026 - val_acc: 0.8605 - val_categorical_crossentropy: 0.4026\n",
            "Epoch 165/1000\n",
            "139839/139839 [==============================] - 24s 175us/step - loss: 0.4227 - acc: 0.8520 - categorical_crossentropy: 0.4227 - val_loss: 0.4298 - val_acc: 0.8502 - val_categorical_crossentropy: 0.4298\n",
            "Epoch 166/1000\n",
            "139839/139839 [==============================] - 24s 173us/step - loss: 0.4233 - acc: 0.8506 - categorical_crossentropy: 0.4233 - val_loss: 0.3997 - val_acc: 0.8611 - val_categorical_crossentropy: 0.3997\n",
            "Epoch 167/1000\n",
            "139839/139839 [==============================] - 25s 175us/step - loss: 0.4198 - acc: 0.8529 - categorical_crossentropy: 0.4198 - val_loss: 0.3891 - val_acc: 0.8627 - val_categorical_crossentropy: 0.3891\n",
            "Epoch 168/1000\n",
            "139839/139839 [==============================] - 27s 192us/step - loss: 0.4207 - acc: 0.8521 - categorical_crossentropy: 0.4207 - val_loss: 0.4196 - val_acc: 0.8541 - val_categorical_crossentropy: 0.4196\n",
            "Epoch 169/1000\n",
            "139839/139839 [==============================] - 26s 188us/step - loss: 0.4217 - acc: 0.8528 - categorical_crossentropy: 0.4217 - val_loss: 0.3984 - val_acc: 0.8610 - val_categorical_crossentropy: 0.3984\n",
            "Epoch 170/1000\n",
            "139839/139839 [==============================] - 27s 192us/step - loss: 0.4217 - acc: 0.8520 - categorical_crossentropy: 0.4217 - val_loss: 0.4355 - val_acc: 0.8477 - val_categorical_crossentropy: 0.4355\n",
            "Epoch 171/1000\n",
            "139839/139839 [==============================] - 27s 192us/step - loss: 0.4230 - acc: 0.8520 - categorical_crossentropy: 0.4230 - val_loss: 0.3951 - val_acc: 0.8629 - val_categorical_crossentropy: 0.3951\n",
            "Epoch 172/1000\n",
            "139839/139839 [==============================] - 26s 187us/step - loss: 0.4217 - acc: 0.8516 - categorical_crossentropy: 0.4217 - val_loss: 0.4096 - val_acc: 0.8566 - val_categorical_crossentropy: 0.4096\n",
            "Epoch 173/1000\n",
            "139839/139839 [==============================] - 26s 185us/step - loss: 0.4226 - acc: 0.8519 - categorical_crossentropy: 0.4226 - val_loss: 0.4013 - val_acc: 0.8606 - val_categorical_crossentropy: 0.4013\n",
            "Epoch 174/1000\n",
            "139839/139839 [==============================] - 27s 191us/step - loss: 0.4204 - acc: 0.8522 - categorical_crossentropy: 0.4204 - val_loss: 0.4013 - val_acc: 0.8593 - val_categorical_crossentropy: 0.4013\n",
            "Epoch 175/1000\n",
            "139839/139839 [==============================] - 26s 189us/step - loss: 0.4218 - acc: 0.8522 - categorical_crossentropy: 0.4218 - val_loss: 0.4108 - val_acc: 0.8575 - val_categorical_crossentropy: 0.4108\n",
            "Epoch 176/1000\n",
            "139839/139839 [==============================] - 27s 190us/step - loss: 0.4206 - acc: 0.8526 - categorical_crossentropy: 0.4206 - val_loss: 0.3978 - val_acc: 0.8622 - val_categorical_crossentropy: 0.3978\n",
            "Epoch 177/1000\n",
            "139839/139839 [==============================] - 26s 185us/step - loss: 0.4202 - acc: 0.8529 - categorical_crossentropy: 0.4202 - val_loss: 0.4299 - val_acc: 0.8491 - val_categorical_crossentropy: 0.4299\n",
            "Epoch 178/1000\n",
            "139839/139839 [==============================] - 27s 190us/step - loss: 0.4199 - acc: 0.8522 - categorical_crossentropy: 0.4199 - val_loss: 0.3943 - val_acc: 0.8633 - val_categorical_crossentropy: 0.3943\n",
            "Epoch 179/1000\n",
            "139839/139839 [==============================] - 26s 189us/step - loss: 0.4195 - acc: 0.8527 - categorical_crossentropy: 0.4195 - val_loss: 0.4013 - val_acc: 0.8587 - val_categorical_crossentropy: 0.4013\n",
            "Epoch 180/1000\n",
            "139839/139839 [==============================] - 26s 189us/step - loss: 0.4223 - acc: 0.8523 - categorical_crossentropy: 0.4223 - val_loss: 0.4095 - val_acc: 0.8567 - val_categorical_crossentropy: 0.4095\n",
            "Epoch 181/1000\n",
            "139839/139839 [==============================] - 27s 192us/step - loss: 0.4178 - acc: 0.8532 - categorical_crossentropy: 0.4178 - val_loss: 0.4230 - val_acc: 0.8538 - val_categorical_crossentropy: 0.4230\n",
            "Epoch 182/1000\n",
            "139839/139839 [==============================] - 26s 189us/step - loss: 0.4215 - acc: 0.8528 - categorical_crossentropy: 0.4215 - val_loss: 0.4104 - val_acc: 0.8578 - val_categorical_crossentropy: 0.4104\n",
            "Epoch 183/1000\n",
            "139839/139839 [==============================] - 27s 193us/step - loss: 0.4196 - acc: 0.8531 - categorical_crossentropy: 0.4196 - val_loss: 0.4100 - val_acc: 0.8566 - val_categorical_crossentropy: 0.4100\n",
            "Epoch 184/1000\n",
            "139839/139839 [==============================] - 27s 190us/step - loss: 0.4191 - acc: 0.8523 - categorical_crossentropy: 0.4191 - val_loss: 0.4018 - val_acc: 0.8604 - val_categorical_crossentropy: 0.4018\n",
            "Epoch 185/1000\n",
            "139839/139839 [==============================] - 26s 189us/step - loss: 0.4189 - acc: 0.8530 - categorical_crossentropy: 0.4189 - val_loss: 0.4037 - val_acc: 0.8585 - val_categorical_crossentropy: 0.4037\n",
            "Epoch 186/1000\n",
            "139839/139839 [==============================] - 27s 190us/step - loss: 0.4186 - acc: 0.8526 - categorical_crossentropy: 0.4186 - val_loss: 0.3895 - val_acc: 0.8651 - val_categorical_crossentropy: 0.3895\n",
            "Epoch 187/1000\n",
            "139839/139839 [==============================] - 27s 193us/step - loss: 0.4198 - acc: 0.8528 - categorical_crossentropy: 0.4198 - val_loss: 0.3982 - val_acc: 0.8597 - val_categorical_crossentropy: 0.3982\n",
            "Epoch 188/1000\n",
            "139839/139839 [==============================] - 27s 192us/step - loss: 0.4193 - acc: 0.8524 - categorical_crossentropy: 0.4193 - val_loss: 0.4060 - val_acc: 0.8589 - val_categorical_crossentropy: 0.4060\n",
            "Epoch 189/1000\n",
            "139839/139839 [==============================] - 26s 188us/step - loss: 0.4189 - acc: 0.8534 - categorical_crossentropy: 0.4189 - val_loss: 0.3886 - val_acc: 0.8641 - val_categorical_crossentropy: 0.3886\n",
            "Epoch 190/1000\n",
            "139839/139839 [==============================] - 27s 196us/step - loss: 0.4193 - acc: 0.8529 - categorical_crossentropy: 0.4193 - val_loss: 0.4067 - val_acc: 0.8607 - val_categorical_crossentropy: 0.4067\n",
            "Epoch 191/1000\n",
            "139839/139839 [==============================] - 28s 197us/step - loss: 0.4190 - acc: 0.8529 - categorical_crossentropy: 0.4190 - val_loss: 0.3906 - val_acc: 0.8623 - val_categorical_crossentropy: 0.3906\n",
            "Epoch 192/1000\n",
            "139839/139839 [==============================] - 27s 191us/step - loss: 0.4205 - acc: 0.8525 - categorical_crossentropy: 0.4205 - val_loss: 0.3899 - val_acc: 0.8634 - val_categorical_crossentropy: 0.3899\n",
            "Epoch 193/1000\n",
            "139839/139839 [==============================] - 28s 200us/step - loss: 0.4181 - acc: 0.8535 - categorical_crossentropy: 0.4181 - val_loss: 0.4087 - val_acc: 0.8572 - val_categorical_crossentropy: 0.4087\n",
            "Epoch 194/1000\n",
            "139839/139839 [==============================] - 27s 193us/step - loss: 0.4197 - acc: 0.8526 - categorical_crossentropy: 0.4197 - val_loss: 0.3845 - val_acc: 0.8673 - val_categorical_crossentropy: 0.3845\n",
            "Epoch 195/1000\n",
            "139839/139839 [==============================] - 27s 194us/step - loss: 0.4206 - acc: 0.8527 - categorical_crossentropy: 0.4206 - val_loss: 0.3947 - val_acc: 0.8613 - val_categorical_crossentropy: 0.3947\n",
            "Epoch 196/1000\n",
            "139839/139839 [==============================] - 27s 195us/step - loss: 0.4184 - acc: 0.8535 - categorical_crossentropy: 0.4184 - val_loss: 0.4160 - val_acc: 0.8545 - val_categorical_crossentropy: 0.4160\n",
            "Epoch 197/1000\n",
            "139839/139839 [==============================] - 27s 192us/step - loss: 0.4179 - acc: 0.8531 - categorical_crossentropy: 0.4179 - val_loss: 0.3906 - val_acc: 0.8664 - val_categorical_crossentropy: 0.3906\n",
            "Epoch 198/1000\n",
            "139839/139839 [==============================] - 29s 210us/step - loss: 0.4178 - acc: 0.8534 - categorical_crossentropy: 0.4178 - val_loss: 0.4247 - val_acc: 0.8492 - val_categorical_crossentropy: 0.4247\n",
            "Epoch 199/1000\n",
            "139839/139839 [==============================] - 29s 206us/step - loss: 0.4204 - acc: 0.8520 - categorical_crossentropy: 0.4204 - val_loss: 0.3894 - val_acc: 0.8638 - val_categorical_crossentropy: 0.3894\n",
            "Epoch 200/1000\n",
            "139839/139839 [==============================] - 30s 214us/step - loss: 0.4178 - acc: 0.8531 - categorical_crossentropy: 0.4178 - val_loss: 0.4034 - val_acc: 0.8586 - val_categorical_crossentropy: 0.4034\n",
            "Epoch 201/1000\n",
            "139839/139839 [==============================] - 29s 208us/step - loss: 0.4155 - acc: 0.8545 - categorical_crossentropy: 0.4155 - val_loss: 0.4122 - val_acc: 0.8586 - val_categorical_crossentropy: 0.4122\n",
            "Epoch 202/1000\n",
            "139839/139839 [==============================] - 29s 205us/step - loss: 0.4179 - acc: 0.8528 - categorical_crossentropy: 0.4179 - val_loss: 0.3944 - val_acc: 0.8631 - val_categorical_crossentropy: 0.3944\n",
            "Epoch 203/1000\n",
            "139839/139839 [==============================] - 29s 208us/step - loss: 0.4176 - acc: 0.8537 - categorical_crossentropy: 0.4176 - val_loss: 0.3861 - val_acc: 0.8653 - val_categorical_crossentropy: 0.3861\n",
            "Epoch 204/1000\n",
            "139839/139839 [==============================] - 27s 196us/step - loss: 0.4180 - acc: 0.8540 - categorical_crossentropy: 0.4180 - val_loss: 0.4162 - val_acc: 0.8548 - val_categorical_crossentropy: 0.4162\n",
            "Epoch 205/1000\n",
            "139839/139839 [==============================] - 27s 191us/step - loss: 0.4185 - acc: 0.8538 - categorical_crossentropy: 0.4185 - val_loss: 0.3895 - val_acc: 0.8641 - val_categorical_crossentropy: 0.3895\n",
            "Epoch 206/1000\n",
            "139839/139839 [==============================] - 27s 190us/step - loss: 0.4182 - acc: 0.8532 - categorical_crossentropy: 0.4182 - val_loss: 0.4061 - val_acc: 0.8575 - val_categorical_crossentropy: 0.4061\n",
            "Epoch 207/1000\n",
            "139839/139839 [==============================] - 26s 186us/step - loss: 0.4171 - acc: 0.8531 - categorical_crossentropy: 0.4171 - val_loss: 0.4288 - val_acc: 0.8523 - val_categorical_crossentropy: 0.4288\n",
            "Epoch 208/1000\n",
            "139839/139839 [==============================] - 26s 184us/step - loss: 0.4162 - acc: 0.8538 - categorical_crossentropy: 0.4162 - val_loss: 0.3947 - val_acc: 0.8629 - val_categorical_crossentropy: 0.3947\n",
            "Epoch 209/1000\n",
            "139839/139839 [==============================] - 26s 186us/step - loss: 0.4164 - acc: 0.8537 - categorical_crossentropy: 0.4164 - val_loss: 0.3904 - val_acc: 0.8649 - val_categorical_crossentropy: 0.3904\n",
            "Epoch 210/1000\n",
            "139839/139839 [==============================] - 26s 188us/step - loss: 0.4150 - acc: 0.8547 - categorical_crossentropy: 0.4150 - val_loss: 0.3997 - val_acc: 0.8596 - val_categorical_crossentropy: 0.3997\n",
            "Epoch 211/1000\n",
            "139839/139839 [==============================] - 26s 185us/step - loss: 0.4186 - acc: 0.8528 - categorical_crossentropy: 0.4186 - val_loss: 0.4066 - val_acc: 0.8580 - val_categorical_crossentropy: 0.4066\n",
            "Epoch 212/1000\n",
            "139839/139839 [==============================] - 26s 185us/step - loss: 0.4174 - acc: 0.8543 - categorical_crossentropy: 0.4174 - val_loss: 0.3975 - val_acc: 0.8613 - val_categorical_crossentropy: 0.3975\n",
            "Epoch 213/1000\n",
            "139839/139839 [==============================] - 26s 188us/step - loss: 0.4177 - acc: 0.8535 - categorical_crossentropy: 0.4177 - val_loss: 0.3879 - val_acc: 0.8643 - val_categorical_crossentropy: 0.3879\n",
            "Epoch 214/1000\n",
            "139839/139839 [==============================] - 26s 187us/step - loss: 0.4156 - acc: 0.8537 - categorical_crossentropy: 0.4156 - val_loss: 0.4002 - val_acc: 0.8593 - val_categorical_crossentropy: 0.4002\n",
            "Epoch 215/1000\n",
            "139839/139839 [==============================] - 26s 185us/step - loss: 0.4164 - acc: 0.8542 - categorical_crossentropy: 0.4164 - val_loss: 0.4014 - val_acc: 0.8609 - val_categorical_crossentropy: 0.4014\n",
            "Epoch 216/1000\n",
            "139839/139839 [==============================] - 26s 186us/step - loss: 0.4165 - acc: 0.8535 - categorical_crossentropy: 0.4165 - val_loss: 0.4200 - val_acc: 0.8510 - val_categorical_crossentropy: 0.4200\n",
            "Epoch 217/1000\n",
            "139839/139839 [==============================] - 26s 187us/step - loss: 0.4149 - acc: 0.8540 - categorical_crossentropy: 0.4149 - val_loss: 0.3859 - val_acc: 0.8658 - val_categorical_crossentropy: 0.3859\n",
            "Epoch 218/1000\n",
            "139839/139839 [==============================] - 26s 183us/step - loss: 0.4151 - acc: 0.8547 - categorical_crossentropy: 0.4151 - val_loss: 0.3992 - val_acc: 0.8605 - val_categorical_crossentropy: 0.3992\n",
            "Epoch 219/1000\n",
            "139839/139839 [==============================] - 26s 188us/step - loss: 0.4153 - acc: 0.8544 - categorical_crossentropy: 0.4153 - val_loss: 0.3868 - val_acc: 0.8644 - val_categorical_crossentropy: 0.3868\n",
            "Epoch 220/1000\n",
            "139839/139839 [==============================] - 26s 185us/step - loss: 0.4166 - acc: 0.8532 - categorical_crossentropy: 0.4166 - val_loss: 0.4004 - val_acc: 0.8586 - val_categorical_crossentropy: 0.4004\n",
            "Epoch 221/1000\n",
            "139839/139839 [==============================] - 26s 184us/step - loss: 0.4165 - acc: 0.8537 - categorical_crossentropy: 0.4165 - val_loss: 0.4039 - val_acc: 0.8596 - val_categorical_crossentropy: 0.4039\n",
            "Epoch 222/1000\n",
            "139839/139839 [==============================] - 27s 191us/step - loss: 0.4163 - acc: 0.8544 - categorical_crossentropy: 0.4163 - val_loss: 0.3852 - val_acc: 0.8654 - val_categorical_crossentropy: 0.3852\n",
            "Epoch 223/1000\n",
            "139839/139839 [==============================] - 26s 184us/step - loss: 0.4149 - acc: 0.8542 - categorical_crossentropy: 0.4149 - val_loss: 0.4166 - val_acc: 0.8574 - val_categorical_crossentropy: 0.4166\n",
            "Epoch 224/1000\n",
            "139839/139839 [==============================] - 27s 191us/step - loss: 0.4162 - acc: 0.8541 - categorical_crossentropy: 0.4162 - val_loss: 0.3827 - val_acc: 0.8672 - val_categorical_crossentropy: 0.3827\n",
            "Epoch 225/1000\n",
            "139839/139839 [==============================] - 26s 187us/step - loss: 0.4160 - acc: 0.8538 - categorical_crossentropy: 0.4160 - val_loss: 0.4028 - val_acc: 0.8576 - val_categorical_crossentropy: 0.4028\n",
            "Epoch 226/1000\n",
            "139839/139839 [==============================] - 26s 187us/step - loss: 0.4151 - acc: 0.8544 - categorical_crossentropy: 0.4151 - val_loss: 0.4038 - val_acc: 0.8620 - val_categorical_crossentropy: 0.4038\n",
            "Epoch 227/1000\n",
            "139839/139839 [==============================] - 26s 189us/step - loss: 0.4150 - acc: 0.8538 - categorical_crossentropy: 0.4150 - val_loss: 0.3991 - val_acc: 0.8606 - val_categorical_crossentropy: 0.3991\n",
            "Epoch 228/1000\n",
            "139839/139839 [==============================] - 26s 188us/step - loss: 0.4160 - acc: 0.8535 - categorical_crossentropy: 0.4160 - val_loss: 0.3995 - val_acc: 0.8615 - val_categorical_crossentropy: 0.3995\n",
            "Epoch 229/1000\n",
            "139839/139839 [==============================] - 27s 192us/step - loss: 0.4158 - acc: 0.8539 - categorical_crossentropy: 0.4158 - val_loss: 0.3977 - val_acc: 0.8610 - val_categorical_crossentropy: 0.3977\n",
            "Epoch 230/1000\n",
            "139839/139839 [==============================] - 26s 187us/step - loss: 0.4150 - acc: 0.8543 - categorical_crossentropy: 0.4150 - val_loss: 0.3954 - val_acc: 0.8632 - val_categorical_crossentropy: 0.3954\n",
            "Epoch 231/1000\n",
            "139839/139839 [==============================] - 27s 192us/step - loss: 0.4137 - acc: 0.8546 - categorical_crossentropy: 0.4137 - val_loss: 0.4018 - val_acc: 0.8596 - val_categorical_crossentropy: 0.4018\n",
            "Epoch 232/1000\n",
            "139839/139839 [==============================] - 26s 183us/step - loss: 0.4154 - acc: 0.8542 - categorical_crossentropy: 0.4154 - val_loss: 0.4004 - val_acc: 0.8611 - val_categorical_crossentropy: 0.4004\n",
            "Epoch 233/1000\n",
            "139839/139839 [==============================] - 26s 189us/step - loss: 0.4138 - acc: 0.8548 - categorical_crossentropy: 0.4138 - val_loss: 0.4101 - val_acc: 0.8555 - val_categorical_crossentropy: 0.4101\n",
            "Epoch 234/1000\n",
            "139839/139839 [==============================] - 27s 193us/step - loss: 0.4141 - acc: 0.8539 - categorical_crossentropy: 0.4141 - val_loss: 0.3864 - val_acc: 0.8640 - val_categorical_crossentropy: 0.3864\n",
            "Epoch 235/1000\n",
            "139839/139839 [==============================] - 27s 190us/step - loss: 0.4153 - acc: 0.8546 - categorical_crossentropy: 0.4153 - val_loss: 0.4061 - val_acc: 0.8592 - val_categorical_crossentropy: 0.4061\n",
            "Epoch 236/1000\n",
            "139839/139839 [==============================] - 27s 192us/step - loss: 0.4137 - acc: 0.8549 - categorical_crossentropy: 0.4137 - val_loss: 0.3973 - val_acc: 0.8625 - val_categorical_crossentropy: 0.3973\n",
            "Epoch 237/1000\n",
            "139839/139839 [==============================] - 26s 187us/step - loss: 0.4140 - acc: 0.8544 - categorical_crossentropy: 0.4140 - val_loss: 0.4006 - val_acc: 0.8593 - val_categorical_crossentropy: 0.4006\n",
            "Epoch 238/1000\n",
            "139839/139839 [==============================] - 26s 189us/step - loss: 0.4141 - acc: 0.8543 - categorical_crossentropy: 0.4141 - val_loss: 0.3872 - val_acc: 0.8653 - val_categorical_crossentropy: 0.3872\n",
            "Epoch 239/1000\n",
            "139839/139839 [==============================] - 26s 186us/step - loss: 0.4157 - acc: 0.8541 - categorical_crossentropy: 0.4157 - val_loss: 0.4023 - val_acc: 0.8594 - val_categorical_crossentropy: 0.4023\n",
            "Epoch 240/1000\n",
            "139839/139839 [==============================] - 26s 189us/step - loss: 0.4145 - acc: 0.8544 - categorical_crossentropy: 0.4145 - val_loss: 0.3869 - val_acc: 0.8644 - val_categorical_crossentropy: 0.3869\n",
            "Epoch 241/1000\n",
            "139839/139839 [==============================] - 27s 194us/step - loss: 0.4128 - acc: 0.8553 - categorical_crossentropy: 0.4128 - val_loss: 0.3908 - val_acc: 0.8636 - val_categorical_crossentropy: 0.3908\n",
            "Epoch 242/1000\n",
            "139839/139839 [==============================] - 26s 188us/step - loss: 0.4130 - acc: 0.8545 - categorical_crossentropy: 0.4130 - val_loss: 0.4203 - val_acc: 0.8518 - val_categorical_crossentropy: 0.4203\n",
            "Epoch 243/1000\n",
            "139839/139839 [==============================] - 27s 191us/step - loss: 0.4141 - acc: 0.8541 - categorical_crossentropy: 0.4141 - val_loss: 0.3918 - val_acc: 0.8630 - val_categorical_crossentropy: 0.3918\n",
            "Epoch 244/1000\n",
            "139839/139839 [==============================] - 26s 187us/step - loss: 0.4137 - acc: 0.8546 - categorical_crossentropy: 0.4137 - val_loss: 0.3986 - val_acc: 0.8609 - val_categorical_crossentropy: 0.3986\n",
            "Epoch 245/1000\n",
            "139839/139839 [==============================] - 27s 193us/step - loss: 0.4125 - acc: 0.8549 - categorical_crossentropy: 0.4125 - val_loss: 0.4026 - val_acc: 0.8590 - val_categorical_crossentropy: 0.4026\n",
            "Epoch 246/1000\n",
            "139839/139839 [==============================] - 26s 188us/step - loss: 0.4124 - acc: 0.8547 - categorical_crossentropy: 0.4124 - val_loss: 0.4054 - val_acc: 0.8592 - val_categorical_crossentropy: 0.4054\n",
            "Epoch 247/1000\n",
            "139839/139839 [==============================] - 28s 198us/step - loss: 0.4131 - acc: 0.8556 - categorical_crossentropy: 0.4131 - val_loss: 0.4150 - val_acc: 0.8524 - val_categorical_crossentropy: 0.4150\n",
            "Epoch 248/1000\n",
            "139839/139839 [==============================] - 26s 189us/step - loss: 0.4135 - acc: 0.8549 - categorical_crossentropy: 0.4135 - val_loss: 0.4099 - val_acc: 0.8560 - val_categorical_crossentropy: 0.4099\n",
            "Epoch 249/1000\n",
            "139839/139839 [==============================] - 27s 191us/step - loss: 0.4127 - acc: 0.8556 - categorical_crossentropy: 0.4127 - val_loss: 0.4145 - val_acc: 0.8559 - val_categorical_crossentropy: 0.4145\n",
            "Epoch 250/1000\n",
            "139839/139839 [==============================] - 26s 188us/step - loss: 0.4134 - acc: 0.8545 - categorical_crossentropy: 0.4134 - val_loss: 0.4338 - val_acc: 0.8529 - val_categorical_crossentropy: 0.4338\n",
            "Epoch 251/1000\n",
            "139839/139839 [==============================] - 26s 187us/step - loss: 0.4130 - acc: 0.8549 - categorical_crossentropy: 0.4130 - val_loss: 0.4036 - val_acc: 0.8565 - val_categorical_crossentropy: 0.4036\n",
            "Epoch 252/1000\n",
            "139839/139839 [==============================] - 27s 191us/step - loss: 0.4124 - acc: 0.8557 - categorical_crossentropy: 0.4124 - val_loss: 0.3858 - val_acc: 0.8660 - val_categorical_crossentropy: 0.3858\n",
            "Epoch 253/1000\n",
            "139839/139839 [==============================] - 26s 186us/step - loss: 0.4126 - acc: 0.8548 - categorical_crossentropy: 0.4126 - val_loss: 0.3901 - val_acc: 0.8638 - val_categorical_crossentropy: 0.3901\n",
            "Epoch 254/1000\n",
            "139839/139839 [==============================] - 27s 193us/step - loss: 0.4125 - acc: 0.8555 - categorical_crossentropy: 0.4125 - val_loss: 0.3849 - val_acc: 0.8654 - val_categorical_crossentropy: 0.3849\n",
            "Epoch 255/1000\n",
            "139839/139839 [==============================] - 27s 193us/step - loss: 0.4137 - acc: 0.8549 - categorical_crossentropy: 0.4137 - val_loss: 0.3952 - val_acc: 0.8621 - val_categorical_crossentropy: 0.3952\n",
            "Epoch 256/1000\n",
            "139839/139839 [==============================] - 26s 187us/step - loss: 0.4122 - acc: 0.8555 - categorical_crossentropy: 0.4122 - val_loss: 0.4119 - val_acc: 0.8585 - val_categorical_crossentropy: 0.4119\n",
            "Epoch 257/1000\n",
            "139839/139839 [==============================] - 26s 188us/step - loss: 0.4116 - acc: 0.8556 - categorical_crossentropy: 0.4116 - val_loss: 0.3958 - val_acc: 0.8617 - val_categorical_crossentropy: 0.3958\n",
            "Epoch 258/1000\n",
            "139839/139839 [==============================] - 27s 190us/step - loss: 0.4124 - acc: 0.8546 - categorical_crossentropy: 0.4124 - val_loss: 0.3919 - val_acc: 0.8626 - val_categorical_crossentropy: 0.3919\n",
            "Epoch 259/1000\n",
            "139839/139839 [==============================] - 26s 186us/step - loss: 0.4127 - acc: 0.8546 - categorical_crossentropy: 0.4127 - val_loss: 0.3957 - val_acc: 0.8611 - val_categorical_crossentropy: 0.3957\n",
            "Epoch 260/1000\n",
            "139839/139839 [==============================] - 26s 186us/step - loss: 0.4124 - acc: 0.8548 - categorical_crossentropy: 0.4124 - val_loss: 0.3956 - val_acc: 0.8616 - val_categorical_crossentropy: 0.3956\n",
            "Epoch 261/1000\n",
            "139839/139839 [==============================] - 26s 187us/step - loss: 0.4113 - acc: 0.8555 - categorical_crossentropy: 0.4113 - val_loss: 0.4031 - val_acc: 0.8612 - val_categorical_crossentropy: 0.4031\n",
            "Epoch 262/1000\n",
            "139839/139839 [==============================] - 28s 198us/step - loss: 0.4118 - acc: 0.8548 - categorical_crossentropy: 0.4118 - val_loss: 0.3943 - val_acc: 0.8631 - val_categorical_crossentropy: 0.3943\n",
            "Epoch 263/1000\n",
            "139839/139839 [==============================] - 29s 206us/step - loss: 0.4109 - acc: 0.8558 - categorical_crossentropy: 0.4109 - val_loss: 0.3965 - val_acc: 0.8626 - val_categorical_crossentropy: 0.3965\n",
            "Epoch 264/1000\n",
            "139839/139839 [==============================] - 29s 204us/step - loss: 0.4121 - acc: 0.8548 - categorical_crossentropy: 0.4121 - val_loss: 0.3834 - val_acc: 0.8663 - val_categorical_crossentropy: 0.3834\n",
            "Epoch 265/1000\n",
            "139839/139839 [==============================] - 28s 202us/step - loss: 0.4098 - acc: 0.8562 - categorical_crossentropy: 0.4098 - val_loss: 0.3917 - val_acc: 0.8636 - val_categorical_crossentropy: 0.3917\n",
            "Epoch 266/1000\n",
            "139839/139839 [==============================] - 28s 200us/step - loss: 0.4119 - acc: 0.8553 - categorical_crossentropy: 0.4119 - val_loss: 0.4143 - val_acc: 0.8579 - val_categorical_crossentropy: 0.4143\n",
            "Epoch 267/1000\n",
            "139839/139839 [==============================] - 28s 202us/step - loss: 0.4111 - acc: 0.8556 - categorical_crossentropy: 0.4111 - val_loss: 0.3960 - val_acc: 0.8635 - val_categorical_crossentropy: 0.3960\n",
            "Epoch 268/1000\n",
            "139839/139839 [==============================] - 28s 197us/step - loss: 0.4108 - acc: 0.8553 - categorical_crossentropy: 0.4108 - val_loss: 0.3852 - val_acc: 0.8648 - val_categorical_crossentropy: 0.3852\n",
            "Epoch 269/1000\n",
            "139839/139839 [==============================] - 27s 195us/step - loss: 0.4130 - acc: 0.8558 - categorical_crossentropy: 0.4130 - val_loss: 0.3854 - val_acc: 0.8668 - val_categorical_crossentropy: 0.3854\n",
            "Epoch 270/1000\n",
            "139839/139839 [==============================] - 27s 191us/step - loss: 0.4108 - acc: 0.8555 - categorical_crossentropy: 0.4108 - val_loss: 0.3968 - val_acc: 0.8634 - val_categorical_crossentropy: 0.3968\n",
            "Epoch 271/1000\n",
            "139839/139839 [==============================] - 27s 192us/step - loss: 0.4120 - acc: 0.8549 - categorical_crossentropy: 0.4120 - val_loss: 0.4709 - val_acc: 0.8351 - val_categorical_crossentropy: 0.4709\n",
            "Epoch 272/1000\n",
            "139839/139839 [==============================] - 27s 193us/step - loss: 0.4102 - acc: 0.8561 - categorical_crossentropy: 0.4102 - val_loss: 0.3871 - val_acc: 0.8655 - val_categorical_crossentropy: 0.3871\n",
            "Epoch 273/1000\n",
            "139839/139839 [==============================] - 27s 193us/step - loss: 0.4103 - acc: 0.8562 - categorical_crossentropy: 0.4103 - val_loss: 0.3859 - val_acc: 0.8648 - val_categorical_crossentropy: 0.3859\n",
            "Epoch 274/1000\n",
            "139839/139839 [==============================] - 26s 189us/step - loss: 0.4113 - acc: 0.8546 - categorical_crossentropy: 0.4113 - val_loss: 0.3993 - val_acc: 0.8595 - val_categorical_crossentropy: 0.3993\n",
            "Epoch 275/1000\n",
            "139839/139839 [==============================] - 26s 187us/step - loss: 0.4113 - acc: 0.8553 - categorical_crossentropy: 0.4113 - val_loss: 0.3916 - val_acc: 0.8644 - val_categorical_crossentropy: 0.3916\n",
            "Epoch 276/1000\n",
            "139839/139839 [==============================] - 27s 195us/step - loss: 0.4120 - acc: 0.8549 - categorical_crossentropy: 0.4120 - val_loss: 0.3869 - val_acc: 0.8646 - val_categorical_crossentropy: 0.3869\n",
            "Epoch 277/1000\n",
            "139839/139839 [==============================] - 27s 190us/step - loss: 0.4111 - acc: 0.8552 - categorical_crossentropy: 0.4111 - val_loss: 0.3903 - val_acc: 0.8644 - val_categorical_crossentropy: 0.3903\n",
            "Epoch 278/1000\n",
            "139839/139839 [==============================] - 26s 189us/step - loss: 0.4106 - acc: 0.8558 - categorical_crossentropy: 0.4106 - val_loss: 0.3923 - val_acc: 0.8637 - val_categorical_crossentropy: 0.3923\n",
            "Epoch 279/1000\n",
            "139839/139839 [==============================] - 26s 186us/step - loss: 0.4100 - acc: 0.8556 - categorical_crossentropy: 0.4100 - val_loss: 0.3940 - val_acc: 0.8631 - val_categorical_crossentropy: 0.3940\n",
            "Epoch 280/1000\n",
            "139839/139839 [==============================] - 26s 184us/step - loss: 0.4103 - acc: 0.8557 - categorical_crossentropy: 0.4103 - val_loss: 0.3858 - val_acc: 0.8648 - val_categorical_crossentropy: 0.3858\n",
            "Epoch 281/1000\n",
            "139839/139839 [==============================] - 26s 184us/step - loss: 0.4097 - acc: 0.8559 - categorical_crossentropy: 0.4097 - val_loss: 0.3898 - val_acc: 0.8645 - val_categorical_crossentropy: 0.3898\n",
            "Epoch 282/1000\n",
            "139839/139839 [==============================] - 26s 185us/step - loss: 0.4105 - acc: 0.8559 - categorical_crossentropy: 0.4105 - val_loss: 0.3898 - val_acc: 0.8645 - val_categorical_crossentropy: 0.3898\n",
            "Epoch 283/1000\n",
            "139839/139839 [==============================] - 25s 179us/step - loss: 0.4107 - acc: 0.8562 - categorical_crossentropy: 0.4107 - val_loss: 0.3846 - val_acc: 0.8660 - val_categorical_crossentropy: 0.3846\n",
            "Epoch 284/1000\n",
            "139839/139839 [==============================] - 26s 184us/step - loss: 0.4110 - acc: 0.8548 - categorical_crossentropy: 0.4110 - val_loss: 0.3933 - val_acc: 0.8639 - val_categorical_crossentropy: 0.3933\n",
            "Epoch 285/1000\n",
            "139839/139839 [==============================] - 26s 183us/step - loss: 0.4108 - acc: 0.8562 - categorical_crossentropy: 0.4108 - val_loss: 0.4037 - val_acc: 0.8584 - val_categorical_crossentropy: 0.4037\n",
            "Epoch 286/1000\n",
            "139839/139839 [==============================] - 25s 177us/step - loss: 0.4112 - acc: 0.8556 - categorical_crossentropy: 0.4112 - val_loss: 0.4030 - val_acc: 0.8595 - val_categorical_crossentropy: 0.4030\n",
            "Epoch 287/1000\n",
            "139839/139839 [==============================] - 25s 180us/step - loss: 0.4093 - acc: 0.8568 - categorical_crossentropy: 0.4093 - val_loss: 0.4047 - val_acc: 0.8563 - val_categorical_crossentropy: 0.4047\n",
            "Epoch 288/1000\n",
            "139839/139839 [==============================] - 26s 183us/step - loss: 0.4106 - acc: 0.8558 - categorical_crossentropy: 0.4106 - val_loss: 0.4123 - val_acc: 0.8591 - val_categorical_crossentropy: 0.4123\n",
            "Epoch 289/1000\n",
            "139839/139839 [==============================] - 26s 187us/step - loss: 0.4098 - acc: 0.8560 - categorical_crossentropy: 0.4098 - val_loss: 0.4091 - val_acc: 0.8579 - val_categorical_crossentropy: 0.4091\n",
            "Epoch 290/1000\n",
            "139839/139839 [==============================] - 26s 189us/step - loss: 0.4090 - acc: 0.8566 - categorical_crossentropy: 0.4090 - val_loss: 0.4049 - val_acc: 0.8580 - val_categorical_crossentropy: 0.4049\n",
            "Epoch 291/1000\n",
            "139839/139839 [==============================] - 27s 191us/step - loss: 0.4091 - acc: 0.8561 - categorical_crossentropy: 0.4091 - val_loss: 0.3909 - val_acc: 0.8643 - val_categorical_crossentropy: 0.3909\n",
            "Epoch 292/1000\n",
            "139839/139839 [==============================] - 27s 197us/step - loss: 0.4100 - acc: 0.8561 - categorical_crossentropy: 0.4100 - val_loss: 0.4322 - val_acc: 0.8530 - val_categorical_crossentropy: 0.4322\n",
            "Epoch 293/1000\n",
            "139839/139839 [==============================] - 27s 194us/step - loss: 0.4088 - acc: 0.8569 - categorical_crossentropy: 0.4088 - val_loss: 0.4010 - val_acc: 0.8579 - val_categorical_crossentropy: 0.4010\n",
            "Epoch 294/1000\n",
            "139839/139839 [==============================] - 27s 193us/step - loss: 0.4093 - acc: 0.8562 - categorical_crossentropy: 0.4093 - val_loss: 0.4077 - val_acc: 0.8575 - val_categorical_crossentropy: 0.4077\n",
            "Epoch 295/1000\n",
            "139839/139839 [==============================] - 27s 196us/step - loss: 0.4103 - acc: 0.8557 - categorical_crossentropy: 0.4103 - val_loss: 0.4005 - val_acc: 0.8625 - val_categorical_crossentropy: 0.4005\n",
            "Epoch 296/1000\n",
            "139839/139839 [==============================] - 27s 196us/step - loss: 0.4086 - acc: 0.8573 - categorical_crossentropy: 0.4086 - val_loss: 0.3946 - val_acc: 0.8617 - val_categorical_crossentropy: 0.3946\n",
            "Epoch 297/1000\n",
            "139839/139839 [==============================] - 27s 193us/step - loss: 0.4089 - acc: 0.8570 - categorical_crossentropy: 0.4089 - val_loss: 0.3861 - val_acc: 0.8658 - val_categorical_crossentropy: 0.3861\n",
            "Epoch 298/1000\n",
            "139839/139839 [==============================] - 28s 199us/step - loss: 0.4088 - acc: 0.8563 - categorical_crossentropy: 0.4088 - val_loss: 0.3992 - val_acc: 0.8604 - val_categorical_crossentropy: 0.3992\n",
            "Epoch 299/1000\n",
            "139839/139839 [==============================] - 28s 203us/step - loss: 0.4092 - acc: 0.8561 - categorical_crossentropy: 0.4092 - val_loss: 0.3928 - val_acc: 0.8622 - val_categorical_crossentropy: 0.3928\n",
            "Epoch 300/1000\n",
            "139839/139839 [==============================] - 28s 198us/step - loss: 0.4103 - acc: 0.8565 - categorical_crossentropy: 0.4103 - val_loss: 0.3997 - val_acc: 0.8593 - val_categorical_crossentropy: 0.3997\n",
            "Epoch 301/1000\n",
            "139839/139839 [==============================] - 28s 200us/step - loss: 0.4077 - acc: 0.8567 - categorical_crossentropy: 0.4077 - val_loss: 0.4144 - val_acc: 0.8534 - val_categorical_crossentropy: 0.4144\n",
            "Epoch 302/1000\n",
            "139839/139839 [==============================] - 28s 201us/step - loss: 0.4080 - acc: 0.8569 - categorical_crossentropy: 0.4080 - val_loss: 0.3892 - val_acc: 0.8657 - val_categorical_crossentropy: 0.3892\n",
            "Epoch 303/1000\n",
            "139839/139839 [==============================] - 28s 201us/step - loss: 0.4088 - acc: 0.8564 - categorical_crossentropy: 0.4088 - val_loss: 0.3926 - val_acc: 0.8616 - val_categorical_crossentropy: 0.3926\n",
            "Epoch 304/1000\n",
            "139839/139839 [==============================] - 29s 207us/step - loss: 0.4085 - acc: 0.8562 - categorical_crossentropy: 0.4085 - val_loss: 0.4024 - val_acc: 0.8599 - val_categorical_crossentropy: 0.4024\n",
            "Epoch 305/1000\n",
            "139839/139839 [==============================] - 28s 199us/step - loss: 0.4083 - acc: 0.8557 - categorical_crossentropy: 0.4083 - val_loss: 0.3828 - val_acc: 0.8659 - val_categorical_crossentropy: 0.3828\n",
            "Epoch 306/1000\n",
            "139839/139839 [==============================] - 29s 205us/step - loss: 0.4087 - acc: 0.8563 - categorical_crossentropy: 0.4087 - val_loss: 0.3938 - val_acc: 0.8617 - val_categorical_crossentropy: 0.3938\n",
            "Epoch 307/1000\n",
            "139839/139839 [==============================] - 28s 202us/step - loss: 0.4072 - acc: 0.8560 - categorical_crossentropy: 0.4072 - val_loss: 0.3980 - val_acc: 0.8621 - val_categorical_crossentropy: 0.3980\n",
            "Epoch 308/1000\n",
            "139839/139839 [==============================] - 29s 204us/step - loss: 0.4087 - acc: 0.8563 - categorical_crossentropy: 0.4087 - val_loss: 0.4003 - val_acc: 0.8593 - val_categorical_crossentropy: 0.4003\n",
            "Epoch 309/1000\n",
            "139839/139839 [==============================] - 29s 207us/step - loss: 0.4108 - acc: 0.8556 - categorical_crossentropy: 0.4108 - val_loss: 0.3863 - val_acc: 0.8647 - val_categorical_crossentropy: 0.3863\n",
            "Epoch 310/1000\n",
            "139839/139839 [==============================] - 29s 204us/step - loss: 0.4085 - acc: 0.8560 - categorical_crossentropy: 0.4085 - val_loss: 0.4014 - val_acc: 0.8598 - val_categorical_crossentropy: 0.4014\n",
            "Epoch 311/1000\n",
            "139839/139839 [==============================] - 28s 203us/step - loss: 0.4072 - acc: 0.8564 - categorical_crossentropy: 0.4072 - val_loss: 0.3857 - val_acc: 0.8655 - val_categorical_crossentropy: 0.3857\n",
            "Epoch 312/1000\n",
            "139839/139839 [==============================] - 29s 208us/step - loss: 0.4080 - acc: 0.8572 - categorical_crossentropy: 0.4080 - val_loss: 0.4511 - val_acc: 0.8416 - val_categorical_crossentropy: 0.4511\n",
            "Epoch 313/1000\n",
            "139839/139839 [==============================] - 28s 200us/step - loss: 0.4092 - acc: 0.8562 - categorical_crossentropy: 0.4092 - val_loss: 0.4168 - val_acc: 0.8556 - val_categorical_crossentropy: 0.4168\n",
            "Epoch 314/1000\n",
            "139839/139839 [==============================] - 29s 206us/step - loss: 0.4089 - acc: 0.8558 - categorical_crossentropy: 0.4089 - val_loss: 0.3945 - val_acc: 0.8627 - val_categorical_crossentropy: 0.3945\n",
            "Epoch 315/1000\n",
            "139839/139839 [==============================] - 29s 204us/step - loss: 0.4093 - acc: 0.8557 - categorical_crossentropy: 0.4093 - val_loss: 0.3937 - val_acc: 0.8633 - val_categorical_crossentropy: 0.3937\n",
            "Epoch 316/1000\n",
            "139839/139839 [==============================] - 28s 202us/step - loss: 0.4087 - acc: 0.8562 - categorical_crossentropy: 0.4087 - val_loss: 0.3824 - val_acc: 0.8672 - val_categorical_crossentropy: 0.3824\n",
            "Epoch 317/1000\n",
            "139839/139839 [==============================] - 29s 206us/step - loss: 0.4088 - acc: 0.8561 - categorical_crossentropy: 0.4088 - val_loss: 0.3932 - val_acc: 0.8618 - val_categorical_crossentropy: 0.3932\n",
            "Epoch 318/1000\n",
            "139839/139839 [==============================] - 29s 207us/step - loss: 0.4086 - acc: 0.8564 - categorical_crossentropy: 0.4086 - val_loss: 0.3860 - val_acc: 0.8645 - val_categorical_crossentropy: 0.3860\n",
            "Epoch 319/1000\n",
            "139839/139839 [==============================] - 29s 204us/step - loss: 0.4067 - acc: 0.8565 - categorical_crossentropy: 0.4067 - val_loss: 0.4281 - val_acc: 0.8471 - val_categorical_crossentropy: 0.4281\n",
            "Epoch 320/1000\n",
            "139839/139839 [==============================] - 28s 203us/step - loss: 0.4070 - acc: 0.8567 - categorical_crossentropy: 0.4070 - val_loss: 0.4008 - val_acc: 0.8626 - val_categorical_crossentropy: 0.4008\n",
            "Epoch 321/1000\n",
            "139839/139839 [==============================] - 28s 203us/step - loss: 0.4094 - acc: 0.8556 - categorical_crossentropy: 0.4094 - val_loss: 0.3880 - val_acc: 0.8644 - val_categorical_crossentropy: 0.3880\n",
            "Epoch 322/1000\n",
            "139839/139839 [==============================] - 29s 205us/step - loss: 0.4075 - acc: 0.8568 - categorical_crossentropy: 0.4075 - val_loss: 0.3909 - val_acc: 0.8635 - val_categorical_crossentropy: 0.3909\n",
            "Epoch 323/1000\n",
            "139839/139839 [==============================] - 28s 198us/step - loss: 0.4074 - acc: 0.8570 - categorical_crossentropy: 0.4074 - val_loss: 0.4069 - val_acc: 0.8575 - val_categorical_crossentropy: 0.4069\n",
            "Epoch 324/1000\n",
            "139839/139839 [==============================] - 29s 208us/step - loss: 0.4072 - acc: 0.8567 - categorical_crossentropy: 0.4072 - val_loss: 0.3862 - val_acc: 0.8646 - val_categorical_crossentropy: 0.3862\n",
            "Epoch 325/1000\n",
            "139839/139839 [==============================] - 30s 212us/step - loss: 0.4088 - acc: 0.8564 - categorical_crossentropy: 0.4088 - val_loss: 0.3935 - val_acc: 0.8636 - val_categorical_crossentropy: 0.3935\n",
            "Epoch 326/1000\n",
            "139839/139839 [==============================] - 29s 208us/step - loss: 0.4083 - acc: 0.8569 - categorical_crossentropy: 0.4083 - val_loss: 0.3918 - val_acc: 0.8626 - val_categorical_crossentropy: 0.3918\n",
            "Epoch 327/1000\n",
            "139839/139839 [==============================] - 29s 204us/step - loss: 0.4079 - acc: 0.8571 - categorical_crossentropy: 0.4079 - val_loss: 0.4049 - val_acc: 0.8605 - val_categorical_crossentropy: 0.4049\n",
            "Epoch 328/1000\n",
            "139839/139839 [==============================] - 29s 206us/step - loss: 0.4086 - acc: 0.8560 - categorical_crossentropy: 0.4086 - val_loss: 0.3912 - val_acc: 0.8631 - val_categorical_crossentropy: 0.3912\n",
            "Epoch 329/1000\n",
            "139839/139839 [==============================] - 30s 213us/step - loss: 0.4081 - acc: 0.8569 - categorical_crossentropy: 0.4081 - val_loss: 0.3848 - val_acc: 0.8668 - val_categorical_crossentropy: 0.3848\n",
            "Epoch 330/1000\n",
            "139839/139839 [==============================] - 30s 213us/step - loss: 0.4071 - acc: 0.8572 - categorical_crossentropy: 0.4071 - val_loss: 0.3869 - val_acc: 0.8650 - val_categorical_crossentropy: 0.3869\n",
            "Epoch 331/1000\n",
            "139839/139839 [==============================] - 29s 210us/step - loss: 0.4074 - acc: 0.8566 - categorical_crossentropy: 0.4074 - val_loss: 0.3845 - val_acc: 0.8667 - val_categorical_crossentropy: 0.3845\n",
            "Epoch 332/1000\n",
            "139839/139839 [==============================] - 29s 204us/step - loss: 0.4086 - acc: 0.8567 - categorical_crossentropy: 0.4086 - val_loss: 0.3789 - val_acc: 0.8671 - val_categorical_crossentropy: 0.3789\n",
            "Epoch 333/1000\n",
            "139839/139839 [==============================] - 28s 201us/step - loss: 0.4073 - acc: 0.8569 - categorical_crossentropy: 0.4073 - val_loss: 0.3872 - val_acc: 0.8647 - val_categorical_crossentropy: 0.3872\n",
            "Epoch 334/1000\n",
            "139839/139839 [==============================] - 29s 205us/step - loss: 0.4078 - acc: 0.8560 - categorical_crossentropy: 0.4078 - val_loss: 0.3833 - val_acc: 0.8682 - val_categorical_crossentropy: 0.3833\n",
            "Epoch 335/1000\n",
            "139839/139839 [==============================] - 28s 201us/step - loss: 0.4073 - acc: 0.8566 - categorical_crossentropy: 0.4073 - val_loss: 0.3885 - val_acc: 0.8635 - val_categorical_crossentropy: 0.3885\n",
            "Epoch 336/1000\n",
            "139839/139839 [==============================] - 29s 205us/step - loss: 0.4067 - acc: 0.8566 - categorical_crossentropy: 0.4067 - val_loss: 0.3890 - val_acc: 0.8643 - val_categorical_crossentropy: 0.3890\n",
            "Epoch 337/1000\n",
            "139839/139839 [==============================] - 27s 193us/step - loss: 0.4063 - acc: 0.8571 - categorical_crossentropy: 0.4063 - val_loss: 0.3831 - val_acc: 0.8666 - val_categorical_crossentropy: 0.3831\n",
            "Epoch 338/1000\n",
            "139839/139839 [==============================] - 28s 199us/step - loss: 0.4071 - acc: 0.8574 - categorical_crossentropy: 0.4071 - val_loss: 0.3910 - val_acc: 0.8650 - val_categorical_crossentropy: 0.3910\n",
            "Epoch 339/1000\n",
            "139839/139839 [==============================] - 28s 201us/step - loss: 0.4065 - acc: 0.8577 - categorical_crossentropy: 0.4065 - val_loss: 0.3894 - val_acc: 0.8641 - val_categorical_crossentropy: 0.3894\n",
            "Epoch 340/1000\n",
            "139839/139839 [==============================] - 29s 208us/step - loss: 0.4081 - acc: 0.8572 - categorical_crossentropy: 0.4081 - val_loss: 0.3833 - val_acc: 0.8662 - val_categorical_crossentropy: 0.3833\n",
            "Epoch 341/1000\n",
            "139839/139839 [==============================] - 28s 201us/step - loss: 0.4060 - acc: 0.8570 - categorical_crossentropy: 0.4060 - val_loss: 0.3867 - val_acc: 0.8643 - val_categorical_crossentropy: 0.3867\n",
            "Epoch 342/1000\n",
            "139839/139839 [==============================] - 29s 207us/step - loss: 0.4074 - acc: 0.8565 - categorical_crossentropy: 0.4074 - val_loss: 0.3944 - val_acc: 0.8615 - val_categorical_crossentropy: 0.3944\n",
            "Epoch 343/1000\n",
            "139839/139839 [==============================] - 28s 203us/step - loss: 0.4064 - acc: 0.8559 - categorical_crossentropy: 0.4064 - val_loss: 0.3827 - val_acc: 0.8684 - val_categorical_crossentropy: 0.3827\n",
            "Epoch 344/1000\n",
            "139839/139839 [==============================] - 29s 207us/step - loss: 0.4067 - acc: 0.8571 - categorical_crossentropy: 0.4067 - val_loss: 0.4005 - val_acc: 0.8612 - val_categorical_crossentropy: 0.4005\n",
            "Epoch 345/1000\n",
            "139839/139839 [==============================] - 28s 202us/step - loss: 0.4057 - acc: 0.8581 - categorical_crossentropy: 0.4057 - val_loss: 0.4145 - val_acc: 0.8540 - val_categorical_crossentropy: 0.4145\n",
            "Epoch 346/1000\n",
            "139839/139839 [==============================] - 29s 207us/step - loss: 0.4063 - acc: 0.8572 - categorical_crossentropy: 0.4063 - val_loss: 0.3911 - val_acc: 0.8624 - val_categorical_crossentropy: 0.3911\n",
            "Epoch 347/1000\n",
            "139839/139839 [==============================] - 30s 212us/step - loss: 0.4061 - acc: 0.8568 - categorical_crossentropy: 0.4061 - val_loss: 0.4050 - val_acc: 0.8607 - val_categorical_crossentropy: 0.4050\n",
            "Epoch 348/1000\n",
            "139839/139839 [==============================] - 29s 206us/step - loss: 0.4048 - acc: 0.8568 - categorical_crossentropy: 0.4048 - val_loss: 0.3880 - val_acc: 0.8641 - val_categorical_crossentropy: 0.3880\n",
            "Epoch 349/1000\n",
            "139839/139839 [==============================] - 29s 210us/step - loss: 0.4064 - acc: 0.8572 - categorical_crossentropy: 0.4064 - val_loss: 0.3835 - val_acc: 0.8671 - val_categorical_crossentropy: 0.3835\n",
            "Epoch 350/1000\n",
            "139839/139839 [==============================] - 29s 209us/step - loss: 0.4052 - acc: 0.8570 - categorical_crossentropy: 0.4052 - val_loss: 0.3913 - val_acc: 0.8627 - val_categorical_crossentropy: 0.3913\n",
            "Epoch 351/1000\n",
            "139839/139839 [==============================] - 29s 209us/step - loss: 0.4065 - acc: 0.8557 - categorical_crossentropy: 0.4065 - val_loss: 0.4132 - val_acc: 0.8561 - val_categorical_crossentropy: 0.4132\n",
            "Epoch 352/1000\n",
            "139839/139839 [==============================] - 29s 209us/step - loss: 0.4058 - acc: 0.8572 - categorical_crossentropy: 0.4058 - val_loss: 0.3830 - val_acc: 0.8671 - val_categorical_crossentropy: 0.3830\n",
            "Epoch 353/1000\n",
            "139839/139839 [==============================] - 29s 210us/step - loss: 0.4058 - acc: 0.8571 - categorical_crossentropy: 0.4058 - val_loss: 0.3854 - val_acc: 0.8664 - val_categorical_crossentropy: 0.3854\n",
            "Epoch 354/1000\n",
            "139839/139839 [==============================] - 29s 205us/step - loss: 0.4043 - acc: 0.8580 - categorical_crossentropy: 0.4043 - val_loss: 0.3952 - val_acc: 0.8604 - val_categorical_crossentropy: 0.3952\n",
            "Epoch 355/1000\n",
            "139839/139839 [==============================] - 29s 209us/step - loss: 0.4059 - acc: 0.8579 - categorical_crossentropy: 0.4059 - val_loss: 0.3884 - val_acc: 0.8641 - val_categorical_crossentropy: 0.3884\n",
            "Epoch 356/1000\n",
            "139839/139839 [==============================] - 29s 206us/step - loss: 0.4065 - acc: 0.8575 - categorical_crossentropy: 0.4065 - val_loss: 0.3934 - val_acc: 0.8619 - val_categorical_crossentropy: 0.3934\n",
            "Epoch 357/1000\n",
            "139839/139839 [==============================] - 30s 215us/step - loss: 0.4055 - acc: 0.8576 - categorical_crossentropy: 0.4055 - val_loss: 0.3916 - val_acc: 0.8650 - val_categorical_crossentropy: 0.3916\n",
            "Epoch 358/1000\n",
            "139839/139839 [==============================] - 29s 206us/step - loss: 0.4053 - acc: 0.8564 - categorical_crossentropy: 0.4053 - val_loss: 0.3842 - val_acc: 0.8657 - val_categorical_crossentropy: 0.3842\n",
            "Epoch 359/1000\n",
            "139839/139839 [==============================] - 29s 204us/step - loss: 0.4075 - acc: 0.8565 - categorical_crossentropy: 0.4075 - val_loss: 0.3998 - val_acc: 0.8618 - val_categorical_crossentropy: 0.3998\n",
            "Epoch 360/1000\n",
            "139839/139839 [==============================] - 29s 210us/step - loss: 0.4067 - acc: 0.8572 - categorical_crossentropy: 0.4067 - val_loss: 0.3796 - val_acc: 0.8670 - val_categorical_crossentropy: 0.3796\n",
            "Epoch 361/1000\n",
            "139839/139839 [==============================] - 29s 206us/step - loss: 0.4066 - acc: 0.8568 - categorical_crossentropy: 0.4066 - val_loss: 0.3855 - val_acc: 0.8664 - val_categorical_crossentropy: 0.3855\n",
            "Epoch 362/1000\n",
            "139839/139839 [==============================] - 30s 212us/step - loss: 0.4053 - acc: 0.8573 - categorical_crossentropy: 0.4053 - val_loss: 0.3974 - val_acc: 0.8615 - val_categorical_crossentropy: 0.3974\n",
            "Epoch 363/1000\n",
            "139839/139839 [==============================] - 29s 207us/step - loss: 0.4042 - acc: 0.8583 - categorical_crossentropy: 0.4042 - val_loss: 0.3856 - val_acc: 0.8662 - val_categorical_crossentropy: 0.3856\n",
            "Epoch 364/1000\n",
            "139839/139839 [==============================] - 28s 199us/step - loss: 0.4041 - acc: 0.8583 - categorical_crossentropy: 0.4041 - val_loss: 0.3968 - val_acc: 0.8620 - val_categorical_crossentropy: 0.3968\n",
            "Epoch 365/1000\n",
            "139839/139839 [==============================] - 28s 197us/step - loss: 0.4049 - acc: 0.8579 - categorical_crossentropy: 0.4049 - val_loss: 0.3914 - val_acc: 0.8642 - val_categorical_crossentropy: 0.3914\n",
            "Epoch 366/1000\n",
            "139839/139839 [==============================] - 28s 199us/step - loss: 0.4053 - acc: 0.8584 - categorical_crossentropy: 0.4053 - val_loss: 0.4005 - val_acc: 0.8593 - val_categorical_crossentropy: 0.4005\n",
            "Epoch 367/1000\n",
            "139839/139839 [==============================] - 27s 193us/step - loss: 0.4059 - acc: 0.8572 - categorical_crossentropy: 0.4059 - val_loss: 0.3901 - val_acc: 0.8620 - val_categorical_crossentropy: 0.3901\n",
            "Epoch 368/1000\n",
            "139839/139839 [==============================] - 27s 196us/step - loss: 0.4046 - acc: 0.8579 - categorical_crossentropy: 0.4046 - val_loss: 0.3771 - val_acc: 0.8677 - val_categorical_crossentropy: 0.3771\n",
            "Epoch 369/1000\n",
            "139839/139839 [==============================] - 27s 193us/step - loss: 0.4055 - acc: 0.8573 - categorical_crossentropy: 0.4055 - val_loss: 0.3831 - val_acc: 0.8661 - val_categorical_crossentropy: 0.3831\n",
            "Epoch 370/1000\n",
            "139839/139839 [==============================] - 27s 191us/step - loss: 0.4056 - acc: 0.8567 - categorical_crossentropy: 0.4056 - val_loss: 0.3975 - val_acc: 0.8611 - val_categorical_crossentropy: 0.3975\n",
            "Epoch 371/1000\n",
            "139839/139839 [==============================] - 28s 199us/step - loss: 0.4042 - acc: 0.8580 - categorical_crossentropy: 0.4042 - val_loss: 0.3930 - val_acc: 0.8616 - val_categorical_crossentropy: 0.3930\n",
            "Epoch 372/1000\n",
            "139839/139839 [==============================] - 27s 196us/step - loss: 0.4056 - acc: 0.8574 - categorical_crossentropy: 0.4056 - val_loss: 0.3900 - val_acc: 0.8642 - val_categorical_crossentropy: 0.3900\n",
            "Epoch 373/1000\n",
            "139839/139839 [==============================] - 27s 194us/step - loss: 0.4051 - acc: 0.8575 - categorical_crossentropy: 0.4051 - val_loss: 0.4058 - val_acc: 0.8568 - val_categorical_crossentropy: 0.4058\n",
            "Epoch 374/1000\n",
            "139839/139839 [==============================] - 27s 194us/step - loss: 0.4051 - acc: 0.8576 - categorical_crossentropy: 0.4051 - val_loss: 0.3892 - val_acc: 0.8641 - val_categorical_crossentropy: 0.3892\n",
            "Epoch 375/1000\n",
            "139839/139839 [==============================] - 27s 190us/step - loss: 0.4043 - acc: 0.8577 - categorical_crossentropy: 0.4043 - val_loss: 0.3885 - val_acc: 0.8650 - val_categorical_crossentropy: 0.3885\n",
            "Epoch 376/1000\n",
            "139839/139839 [==============================] - 27s 192us/step - loss: 0.4048 - acc: 0.8572 - categorical_crossentropy: 0.4048 - val_loss: 0.4009 - val_acc: 0.8623 - val_categorical_crossentropy: 0.4009\n",
            "Epoch 377/1000\n",
            "139839/139839 [==============================] - 26s 189us/step - loss: 0.4050 - acc: 0.8576 - categorical_crossentropy: 0.4050 - val_loss: 0.3822 - val_acc: 0.8671 - val_categorical_crossentropy: 0.3822\n",
            "Epoch 378/1000\n",
            "139839/139839 [==============================] - 27s 196us/step - loss: 0.4057 - acc: 0.8570 - categorical_crossentropy: 0.4057 - val_loss: 0.3895 - val_acc: 0.8629 - val_categorical_crossentropy: 0.3895\n",
            "Epoch 379/1000\n",
            "139839/139839 [==============================] - 27s 194us/step - loss: 0.4053 - acc: 0.8582 - categorical_crossentropy: 0.4053 - val_loss: 0.3916 - val_acc: 0.8659 - val_categorical_crossentropy: 0.3916\n",
            "Epoch 380/1000\n",
            "139839/139839 [==============================] - 29s 204us/step - loss: 0.4041 - acc: 0.8574 - categorical_crossentropy: 0.4041 - val_loss: 0.3881 - val_acc: 0.8640 - val_categorical_crossentropy: 0.3881\n",
            "Epoch 381/1000\n",
            "139839/139839 [==============================] - 28s 198us/step - loss: 0.4041 - acc: 0.8578 - categorical_crossentropy: 0.4041 - val_loss: 0.3793 - val_acc: 0.8669 - val_categorical_crossentropy: 0.3793\n",
            "Epoch 382/1000\n",
            "139839/139839 [==============================] - 28s 199us/step - loss: 0.4042 - acc: 0.8570 - categorical_crossentropy: 0.4042 - val_loss: 0.3890 - val_acc: 0.8651 - val_categorical_crossentropy: 0.3890\n",
            "Epoch 383/1000\n",
            "139839/139839 [==============================] - 28s 197us/step - loss: 0.4043 - acc: 0.8579 - categorical_crossentropy: 0.4043 - val_loss: 0.3833 - val_acc: 0.8665 - val_categorical_crossentropy: 0.3833\n",
            "Epoch 384/1000\n",
            "139839/139839 [==============================] - 27s 195us/step - loss: 0.4064 - acc: 0.8569 - categorical_crossentropy: 0.4064 - val_loss: 0.4090 - val_acc: 0.8556 - val_categorical_crossentropy: 0.4090\n",
            "Epoch 385/1000\n",
            "139839/139839 [==============================] - 28s 200us/step - loss: 0.4043 - acc: 0.8579 - categorical_crossentropy: 0.4043 - val_loss: 0.3904 - val_acc: 0.8642 - val_categorical_crossentropy: 0.3904\n",
            "Epoch 386/1000\n",
            "139839/139839 [==============================] - 29s 205us/step - loss: 0.4047 - acc: 0.8579 - categorical_crossentropy: 0.4047 - val_loss: 0.4163 - val_acc: 0.8539 - val_categorical_crossentropy: 0.4163\n",
            "Epoch 387/1000\n",
            "139839/139839 [==============================] - 28s 199us/step - loss: 0.4030 - acc: 0.8584 - categorical_crossentropy: 0.4030 - val_loss: 0.3780 - val_acc: 0.8682 - val_categorical_crossentropy: 0.3780\n",
            "Epoch 388/1000\n",
            "139839/139839 [==============================] - 28s 197us/step - loss: 0.4066 - acc: 0.8576 - categorical_crossentropy: 0.4066 - val_loss: 0.3800 - val_acc: 0.8675 - val_categorical_crossentropy: 0.3800\n",
            "Epoch 389/1000\n",
            "139839/139839 [==============================] - 28s 197us/step - loss: 0.4051 - acc: 0.8571 - categorical_crossentropy: 0.4051 - val_loss: 0.3880 - val_acc: 0.8656 - val_categorical_crossentropy: 0.3880\n",
            "Epoch 390/1000\n",
            "139839/139839 [==============================] - 29s 205us/step - loss: 0.4046 - acc: 0.8573 - categorical_crossentropy: 0.4046 - val_loss: 0.3863 - val_acc: 0.8664 - val_categorical_crossentropy: 0.3863\n",
            "Epoch 391/1000\n",
            "139839/139839 [==============================] - 28s 203us/step - loss: 0.4031 - acc: 0.8580 - categorical_crossentropy: 0.4031 - val_loss: 0.3940 - val_acc: 0.8630 - val_categorical_crossentropy: 0.3940\n",
            "Epoch 392/1000\n",
            "139839/139839 [==============================] - 28s 202us/step - loss: 0.4051 - acc: 0.8567 - categorical_crossentropy: 0.4051 - val_loss: 0.3935 - val_acc: 0.8633 - val_categorical_crossentropy: 0.3935\n",
            "Epoch 393/1000\n",
            "139839/139839 [==============================] - 29s 208us/step - loss: 0.4048 - acc: 0.8572 - categorical_crossentropy: 0.4048 - val_loss: 0.3937 - val_acc: 0.8639 - val_categorical_crossentropy: 0.3937\n",
            "Epoch 394/1000\n",
            "139839/139839 [==============================] - 29s 210us/step - loss: 0.4023 - acc: 0.8587 - categorical_crossentropy: 0.4023 - val_loss: 0.3792 - val_acc: 0.8669 - val_categorical_crossentropy: 0.3792\n",
            "Epoch 395/1000\n",
            "139839/139839 [==============================] - 29s 208us/step - loss: 0.4045 - acc: 0.8578 - categorical_crossentropy: 0.4045 - val_loss: 0.4114 - val_acc: 0.8586 - val_categorical_crossentropy: 0.4114\n",
            "Epoch 396/1000\n",
            "139839/139839 [==============================] - 29s 207us/step - loss: 0.4030 - acc: 0.8585 - categorical_crossentropy: 0.4030 - val_loss: 0.3803 - val_acc: 0.8674 - val_categorical_crossentropy: 0.3803\n",
            "Epoch 397/1000\n",
            "139839/139839 [==============================] - 29s 207us/step - loss: 0.4046 - acc: 0.8576 - categorical_crossentropy: 0.4046 - val_loss: 0.3831 - val_acc: 0.8657 - val_categorical_crossentropy: 0.3831\n",
            "Epoch 398/1000\n",
            "139839/139839 [==============================] - 29s 205us/step - loss: 0.4042 - acc: 0.8579 - categorical_crossentropy: 0.4042 - val_loss: 0.4393 - val_acc: 0.8453 - val_categorical_crossentropy: 0.4393\n",
            "Epoch 399/1000\n",
            "139839/139839 [==============================] - 28s 201us/step - loss: 0.4022 - acc: 0.8588 - categorical_crossentropy: 0.4022 - val_loss: 0.3842 - val_acc: 0.8660 - val_categorical_crossentropy: 0.3842\n",
            "Epoch 400/1000\n",
            "139839/139839 [==============================] - 27s 196us/step - loss: 0.4049 - acc: 0.8573 - categorical_crossentropy: 0.4049 - val_loss: 0.3925 - val_acc: 0.8624 - val_categorical_crossentropy: 0.3925\n",
            "Epoch 401/1000\n",
            "139839/139839 [==============================] - 28s 197us/step - loss: 0.4033 - acc: 0.8581 - categorical_crossentropy: 0.4033 - val_loss: 0.4102 - val_acc: 0.8585 - val_categorical_crossentropy: 0.4102\n",
            "Epoch 402/1000\n",
            "139839/139839 [==============================] - 28s 198us/step - loss: 0.4030 - acc: 0.8570 - categorical_crossentropy: 0.4030 - val_loss: 0.3843 - val_acc: 0.8674 - val_categorical_crossentropy: 0.3843\n",
            "Epoch 403/1000\n",
            "139839/139839 [==============================] - 28s 201us/step - loss: 0.4026 - acc: 0.8577 - categorical_crossentropy: 0.4026 - val_loss: 0.3817 - val_acc: 0.8670 - val_categorical_crossentropy: 0.3817\n",
            "Epoch 404/1000\n",
            "139839/139839 [==============================] - 28s 199us/step - loss: 0.4034 - acc: 0.8575 - categorical_crossentropy: 0.4034 - val_loss: 0.3885 - val_acc: 0.8650 - val_categorical_crossentropy: 0.3885\n",
            "Epoch 405/1000\n",
            "139839/139839 [==============================] - 28s 201us/step - loss: 0.4013 - acc: 0.8584 - categorical_crossentropy: 0.4013 - val_loss: 0.3843 - val_acc: 0.8668 - val_categorical_crossentropy: 0.3843\n",
            "Epoch 406/1000\n",
            "139839/139839 [==============================] - 28s 200us/step - loss: 0.4041 - acc: 0.8578 - categorical_crossentropy: 0.4041 - val_loss: 0.3909 - val_acc: 0.8640 - val_categorical_crossentropy: 0.3909\n",
            "Epoch 407/1000\n",
            "139839/139839 [==============================] - 28s 201us/step - loss: 0.4029 - acc: 0.8574 - categorical_crossentropy: 0.4029 - val_loss: 0.3871 - val_acc: 0.8656 - val_categorical_crossentropy: 0.3871\n",
            "Epoch 408/1000\n",
            "139839/139839 [==============================] - 28s 203us/step - loss: 0.4037 - acc: 0.8576 - categorical_crossentropy: 0.4037 - val_loss: 0.3972 - val_acc: 0.8617 - val_categorical_crossentropy: 0.3972\n",
            "Epoch 409/1000\n",
            "139839/139839 [==============================] - 28s 203us/step - loss: 0.4037 - acc: 0.8581 - categorical_crossentropy: 0.4037 - val_loss: 0.3936 - val_acc: 0.8616 - val_categorical_crossentropy: 0.3936\n",
            "Epoch 410/1000\n",
            "139839/139839 [==============================] - 28s 198us/step - loss: 0.4048 - acc: 0.8576 - categorical_crossentropy: 0.4048 - val_loss: 0.3869 - val_acc: 0.8653 - val_categorical_crossentropy: 0.3869\n",
            "Epoch 411/1000\n",
            "139839/139839 [==============================] - 28s 197us/step - loss: 0.4033 - acc: 0.8582 - categorical_crossentropy: 0.4033 - val_loss: 0.3840 - val_acc: 0.8654 - val_categorical_crossentropy: 0.3840\n",
            "Epoch 412/1000\n",
            "139839/139839 [==============================] - 28s 201us/step - loss: 0.4040 - acc: 0.8585 - categorical_crossentropy: 0.4040 - val_loss: 0.4122 - val_acc: 0.8548 - val_categorical_crossentropy: 0.4122\n",
            "Epoch 413/1000\n",
            "139839/139839 [==============================] - 29s 207us/step - loss: 0.4017 - acc: 0.8595 - categorical_crossentropy: 0.4017 - val_loss: 0.3938 - val_acc: 0.8625 - val_categorical_crossentropy: 0.3938\n",
            "Epoch 414/1000\n",
            "139839/139839 [==============================] - 28s 203us/step - loss: 0.4039 - acc: 0.8576 - categorical_crossentropy: 0.4039 - val_loss: 0.3907 - val_acc: 0.8639 - val_categorical_crossentropy: 0.3907\n",
            "Epoch 415/1000\n",
            "139839/139839 [==============================] - 28s 197us/step - loss: 0.4038 - acc: 0.8579 - categorical_crossentropy: 0.4038 - val_loss: 0.3799 - val_acc: 0.8686 - val_categorical_crossentropy: 0.3799\n",
            "Epoch 416/1000\n",
            "139839/139839 [==============================] - 28s 197us/step - loss: 0.4033 - acc: 0.8583 - categorical_crossentropy: 0.4033 - val_loss: 0.3847 - val_acc: 0.8651 - val_categorical_crossentropy: 0.3847\n",
            "Epoch 417/1000\n",
            "139839/139839 [==============================] - 27s 195us/step - loss: 0.4026 - acc: 0.8579 - categorical_crossentropy: 0.4026 - val_loss: 0.4064 - val_acc: 0.8570 - val_categorical_crossentropy: 0.4064\n",
            "Epoch 418/1000\n",
            "139839/139839 [==============================] - 28s 199us/step - loss: 0.4042 - acc: 0.8578 - categorical_crossentropy: 0.4042 - val_loss: 0.3913 - val_acc: 0.8645 - val_categorical_crossentropy: 0.3913\n",
            "Epoch 419/1000\n",
            "139839/139839 [==============================] - 28s 199us/step - loss: 0.4013 - acc: 0.8582 - categorical_crossentropy: 0.4013 - val_loss: 0.3934 - val_acc: 0.8625 - val_categorical_crossentropy: 0.3934\n",
            "Epoch 420/1000\n",
            "139839/139839 [==============================] - 28s 202us/step - loss: 0.4024 - acc: 0.8585 - categorical_crossentropy: 0.4024 - val_loss: 0.3789 - val_acc: 0.8682 - val_categorical_crossentropy: 0.3789\n",
            "Epoch 421/1000\n",
            "139839/139839 [==============================] - 28s 203us/step - loss: 0.4018 - acc: 0.8589 - categorical_crossentropy: 0.4018 - val_loss: 0.4053 - val_acc: 0.8601 - val_categorical_crossentropy: 0.4053\n",
            "Epoch 422/1000\n",
            "139839/139839 [==============================] - 27s 197us/step - loss: 0.4025 - acc: 0.8572 - categorical_crossentropy: 0.4025 - val_loss: 0.4123 - val_acc: 0.8584 - val_categorical_crossentropy: 0.4123\n",
            "Epoch 423/1000\n",
            "139839/139839 [==============================] - 28s 200us/step - loss: 0.4019 - acc: 0.8584 - categorical_crossentropy: 0.4019 - val_loss: 0.3794 - val_acc: 0.8674 - val_categorical_crossentropy: 0.3794\n",
            "Epoch 424/1000\n",
            "139839/139839 [==============================] - 28s 204us/step - loss: 0.4029 - acc: 0.8584 - categorical_crossentropy: 0.4029 - val_loss: 0.3876 - val_acc: 0.8636 - val_categorical_crossentropy: 0.3876\n",
            "Epoch 425/1000\n",
            "139839/139839 [==============================] - 27s 197us/step - loss: 0.4021 - acc: 0.8589 - categorical_crossentropy: 0.4021 - val_loss: 0.4141 - val_acc: 0.8542 - val_categorical_crossentropy: 0.4141\n",
            "Epoch 426/1000\n",
            "139839/139839 [==============================] - 27s 195us/step - loss: 0.4026 - acc: 0.8576 - categorical_crossentropy: 0.4026 - val_loss: 0.3776 - val_acc: 0.8686 - val_categorical_crossentropy: 0.3776\n",
            "Epoch 427/1000\n",
            "139839/139839 [==============================] - 27s 196us/step - loss: 0.4021 - acc: 0.8583 - categorical_crossentropy: 0.4021 - val_loss: 0.3999 - val_acc: 0.8625 - val_categorical_crossentropy: 0.3999\n",
            "Epoch 428/1000\n",
            "139839/139839 [==============================] - 27s 191us/step - loss: 0.4026 - acc: 0.8580 - categorical_crossentropy: 0.4026 - val_loss: 0.3850 - val_acc: 0.8662 - val_categorical_crossentropy: 0.3850\n",
            "Epoch 429/1000\n",
            "139839/139839 [==============================] - 28s 199us/step - loss: 0.4022 - acc: 0.8582 - categorical_crossentropy: 0.4022 - val_loss: 0.4094 - val_acc: 0.8566 - val_categorical_crossentropy: 0.4094\n",
            "Epoch 430/1000\n",
            "139839/139839 [==============================] - 28s 198us/step - loss: 0.4007 - acc: 0.8592 - categorical_crossentropy: 0.4007 - val_loss: 0.3789 - val_acc: 0.8674 - val_categorical_crossentropy: 0.3789\n",
            "Epoch 431/1000\n",
            "139839/139839 [==============================] - 28s 197us/step - loss: 0.4020 - acc: 0.8588 - categorical_crossentropy: 0.4020 - val_loss: 0.3853 - val_acc: 0.8657 - val_categorical_crossentropy: 0.3853\n",
            "Epoch 432/1000\n",
            "139839/139839 [==============================] - 28s 197us/step - loss: 0.4031 - acc: 0.8586 - categorical_crossentropy: 0.4031 - val_loss: 0.4098 - val_acc: 0.8564 - val_categorical_crossentropy: 0.4098\n",
            "Epoch 433/1000\n",
            "139839/139839 [==============================] - 27s 195us/step - loss: 0.4020 - acc: 0.8583 - categorical_crossentropy: 0.4020 - val_loss: 0.3889 - val_acc: 0.8648 - val_categorical_crossentropy: 0.3889\n",
            "Epoch 434/1000\n",
            "139839/139839 [==============================] - 28s 198us/step - loss: 0.4018 - acc: 0.8578 - categorical_crossentropy: 0.4018 - val_loss: 0.3875 - val_acc: 0.8666 - val_categorical_crossentropy: 0.3875\n",
            "Epoch 435/1000\n",
            "139839/139839 [==============================] - 28s 200us/step - loss: 0.4039 - acc: 0.8578 - categorical_crossentropy: 0.4039 - val_loss: 0.3893 - val_acc: 0.8651 - val_categorical_crossentropy: 0.3893\n",
            "Epoch 436/1000\n",
            "139839/139839 [==============================] - 27s 191us/step - loss: 0.4029 - acc: 0.8589 - categorical_crossentropy: 0.4029 - val_loss: 0.3824 - val_acc: 0.8664 - val_categorical_crossentropy: 0.3824\n",
            "Epoch 437/1000\n",
            "139839/139839 [==============================] - 27s 194us/step - loss: 0.4020 - acc: 0.8584 - categorical_crossentropy: 0.4020 - val_loss: 0.3830 - val_acc: 0.8666 - val_categorical_crossentropy: 0.3830\n",
            "Epoch 438/1000\n",
            "139839/139839 [==============================] - 27s 193us/step - loss: 0.4039 - acc: 0.8579 - categorical_crossentropy: 0.4039 - val_loss: 0.3893 - val_acc: 0.8633 - val_categorical_crossentropy: 0.3893\n",
            "Epoch 439/1000\n",
            "139839/139839 [==============================] - 27s 192us/step - loss: 0.4015 - acc: 0.8588 - categorical_crossentropy: 0.4015 - val_loss: 0.3879 - val_acc: 0.8663 - val_categorical_crossentropy: 0.3879\n",
            "Epoch 440/1000\n",
            "139839/139839 [==============================] - 27s 191us/step - loss: 0.4013 - acc: 0.8580 - categorical_crossentropy: 0.4013 - val_loss: 0.3913 - val_acc: 0.8643 - val_categorical_crossentropy: 0.3913\n",
            "Epoch 441/1000\n",
            "139839/139839 [==============================] - 27s 194us/step - loss: 0.4004 - acc: 0.8590 - categorical_crossentropy: 0.4004 - val_loss: 0.3836 - val_acc: 0.8664 - val_categorical_crossentropy: 0.3836\n",
            "Epoch 442/1000\n",
            "139839/139839 [==============================] - 27s 193us/step - loss: 0.4005 - acc: 0.8587 - categorical_crossentropy: 0.4005 - val_loss: 0.3777 - val_acc: 0.8681 - val_categorical_crossentropy: 0.3777\n",
            "Epoch 443/1000\n",
            "139839/139839 [==============================] - 27s 190us/step - loss: 0.3997 - acc: 0.8594 - categorical_crossentropy: 0.3997 - val_loss: 0.3790 - val_acc: 0.8675 - val_categorical_crossentropy: 0.3790\n",
            "Epoch 444/1000\n",
            "139839/139839 [==============================] - 27s 191us/step - loss: 0.4008 - acc: 0.8583 - categorical_crossentropy: 0.4008 - val_loss: 0.3852 - val_acc: 0.8651 - val_categorical_crossentropy: 0.3852\n",
            "Epoch 445/1000\n",
            "139839/139839 [==============================] - 28s 200us/step - loss: 0.4032 - acc: 0.8586 - categorical_crossentropy: 0.4032 - val_loss: 0.3900 - val_acc: 0.8634 - val_categorical_crossentropy: 0.3900\n",
            "Epoch 446/1000\n",
            "139839/139839 [==============================] - 27s 195us/step - loss: 0.4018 - acc: 0.8589 - categorical_crossentropy: 0.4018 - val_loss: 0.3965 - val_acc: 0.8626 - val_categorical_crossentropy: 0.3965\n",
            "Epoch 447/1000\n",
            "139839/139839 [==============================] - 28s 197us/step - loss: 0.4039 - acc: 0.8584 - categorical_crossentropy: 0.4039 - val_loss: 0.3854 - val_acc: 0.8646 - val_categorical_crossentropy: 0.3854\n",
            "Epoch 448/1000\n",
            "139839/139839 [==============================] - 27s 192us/step - loss: 0.4009 - acc: 0.8593 - categorical_crossentropy: 0.4009 - val_loss: 0.3946 - val_acc: 0.8620 - val_categorical_crossentropy: 0.3946\n",
            "Epoch 449/1000\n",
            "139839/139839 [==============================] - 27s 196us/step - loss: 0.4004 - acc: 0.8591 - categorical_crossentropy: 0.4004 - val_loss: 0.3836 - val_acc: 0.8668 - val_categorical_crossentropy: 0.3836\n",
            "Epoch 450/1000\n",
            "139839/139839 [==============================] - 27s 192us/step - loss: 0.4026 - acc: 0.8586 - categorical_crossentropy: 0.4026 - val_loss: 0.3977 - val_acc: 0.8597 - val_categorical_crossentropy: 0.3977\n",
            "Epoch 451/1000\n",
            "139839/139839 [==============================] - 27s 196us/step - loss: 0.4022 - acc: 0.8581 - categorical_crossentropy: 0.4022 - val_loss: 0.3891 - val_acc: 0.8643 - val_categorical_crossentropy: 0.3891\n",
            "Epoch 452/1000\n",
            "139839/139839 [==============================] - 27s 191us/step - loss: 0.4020 - acc: 0.8585 - categorical_crossentropy: 0.4020 - val_loss: 0.3776 - val_acc: 0.8682 - val_categorical_crossentropy: 0.3776\n",
            "Epoch 453/1000\n",
            "139839/139839 [==============================] - 28s 198us/step - loss: 0.4027 - acc: 0.8586 - categorical_crossentropy: 0.4027 - val_loss: 0.3937 - val_acc: 0.8629 - val_categorical_crossentropy: 0.3937\n",
            "Epoch 454/1000\n",
            "139839/139839 [==============================] - 27s 190us/step - loss: 0.4037 - acc: 0.8584 - categorical_crossentropy: 0.4037 - val_loss: 0.3813 - val_acc: 0.8666 - val_categorical_crossentropy: 0.3813\n",
            "Epoch 455/1000\n",
            "139839/139839 [==============================] - 27s 191us/step - loss: 0.4010 - acc: 0.8584 - categorical_crossentropy: 0.4010 - val_loss: 0.3835 - val_acc: 0.8655 - val_categorical_crossentropy: 0.3835\n",
            "Epoch 456/1000\n",
            "139839/139839 [==============================] - 27s 194us/step - loss: 0.4028 - acc: 0.8581 - categorical_crossentropy: 0.4028 - val_loss: 0.3921 - val_acc: 0.8633 - val_categorical_crossentropy: 0.3921\n",
            "Epoch 457/1000\n",
            "139839/139839 [==============================] - 28s 198us/step - loss: 0.4006 - acc: 0.8591 - categorical_crossentropy: 0.4006 - val_loss: 0.3839 - val_acc: 0.8659 - val_categorical_crossentropy: 0.3839\n",
            "Epoch 458/1000\n",
            "139839/139839 [==============================] - 28s 197us/step - loss: 0.4015 - acc: 0.8580 - categorical_crossentropy: 0.4015 - val_loss: 0.3905 - val_acc: 0.8650 - val_categorical_crossentropy: 0.3905\n",
            "Epoch 459/1000\n",
            "139839/139839 [==============================] - 29s 207us/step - loss: 0.4014 - acc: 0.8589 - categorical_crossentropy: 0.4014 - val_loss: 0.3988 - val_acc: 0.8602 - val_categorical_crossentropy: 0.3988\n",
            "Epoch 460/1000\n",
            "139839/139839 [==============================] - 29s 208us/step - loss: 0.4009 - acc: 0.8587 - categorical_crossentropy: 0.4009 - val_loss: 0.3796 - val_acc: 0.8679 - val_categorical_crossentropy: 0.3796\n",
            "Epoch 461/1000\n",
            "139839/139839 [==============================] - 29s 205us/step - loss: 0.4008 - acc: 0.8590 - categorical_crossentropy: 0.4008 - val_loss: 0.3940 - val_acc: 0.8624 - val_categorical_crossentropy: 0.3940\n",
            "Epoch 462/1000\n",
            "139839/139839 [==============================] - 29s 210us/step - loss: 0.4011 - acc: 0.8586 - categorical_crossentropy: 0.4011 - val_loss: 0.4099 - val_acc: 0.8565 - val_categorical_crossentropy: 0.4099\n",
            "Epoch 463/1000\n",
            "139839/139839 [==============================] - 29s 207us/step - loss: 0.4012 - acc: 0.8596 - categorical_crossentropy: 0.4012 - val_loss: 0.4188 - val_acc: 0.8580 - val_categorical_crossentropy: 0.4188\n",
            "Epoch 464/1000\n",
            "139839/139839 [==============================] - 29s 204us/step - loss: 0.4009 - acc: 0.8590 - categorical_crossentropy: 0.4009 - val_loss: 0.3913 - val_acc: 0.8645 - val_categorical_crossentropy: 0.3913\n",
            "Epoch 465/1000\n",
            "139839/139839 [==============================] - 27s 197us/step - loss: 0.4022 - acc: 0.8583 - categorical_crossentropy: 0.4022 - val_loss: 0.3804 - val_acc: 0.8669 - val_categorical_crossentropy: 0.3804\n",
            "Epoch 466/1000\n",
            "139839/139839 [==============================] - 28s 197us/step - loss: 0.4014 - acc: 0.8595 - categorical_crossentropy: 0.4014 - val_loss: 0.3903 - val_acc: 0.8638 - val_categorical_crossentropy: 0.3903\n",
            "Epoch 467/1000\n",
            "139839/139839 [==============================] - 28s 199us/step - loss: 0.4012 - acc: 0.8592 - categorical_crossentropy: 0.4012 - val_loss: 0.3816 - val_acc: 0.8669 - val_categorical_crossentropy: 0.3816\n",
            "Epoch 468/1000\n",
            "139839/139839 [==============================] - 27s 192us/step - loss: 0.4023 - acc: 0.8583 - categorical_crossentropy: 0.4023 - val_loss: 0.3902 - val_acc: 0.8639 - val_categorical_crossentropy: 0.3902\n",
            "Epoch 00468: early stopping\n",
            "59931/59931 [==============================] - 6s 97us/step\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.3901850055069698, 0.8638767916397454, 0.3901850055069698]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "04uzx-RuIdI-",
        "outputId": "73f1bebf-9782-41b7-f16d-1fc124d4a10b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 107
        }
      },
      "source": [
        "### 최적 모델 불러오기\n",
        "best_model = keras.models.load_model('best_model.h5')\n",
        "val_loss, val_acc, val_category = best_model.evaluate(X_test, y_test)"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "If using Keras pass *_constraint arguments to layers.\n",
            "59931/59931 [==============================] - 7s 118us/sample - loss: 0.3773 - acc: 0.8677 - categorical_crossentropy: 0.3773\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iv59_h-y2G_L",
        "colab_type": "code",
        "outputId": "41b7c4d9-c2f2-43a6-a07d-67e7799272a7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 542
        }
      },
      "source": [
        "## 그래프로 수치 명확하게 나타내주기\n",
        "import plotly.graph_objects as go\n",
        "fig = go.Figure()\n",
        "fig.add_trace(go.Scatter(y=history.history['loss'],\n",
        "                    mode='lines',\n",
        "                    name='loss'))\n",
        "fig.add_trace(go.Scatter(y=history.history['val_loss'],\n",
        "                    mode='lines',\n",
        "                    name='val_loss'))\n",
        "fig.add_trace(go.Scatter(y=history.history['val_acc'],\n",
        "                    mode='lines',\n",
        "                    name='val_acc'))\n",
        "fig.show()"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<html>\n",
              "<head><meta charset=\"utf-8\" /></head>\n",
              "<body>\n",
              "    <div>\n",
              "            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>\n",
              "                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
              "        <script src=\"https://cdn.plot.ly/plotly-latest.min.js\"></script>    \n",
              "            <div id=\"543730d8-f864-47a9-9438-4a9154eb4c12\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>\n",
              "            <script type=\"text/javascript\">\n",
              "                \n",
              "                    window.PLOTLYENV=window.PLOTLYENV || {};\n",
              "                    \n",
              "                if (document.getElementById(\"543730d8-f864-47a9-9438-4a9154eb4c12\")) {\n",
              "                    Plotly.newPlot(\n",
              "                        '543730d8-f864-47a9-9438-4a9154eb4c12',\n",
              "                        [{\"mode\": \"lines\", \"name\": \"loss\", \"type\": \"scatter\", \"y\": [0.9737601186371925, 0.6456201706273675, 0.5980814953428115, 0.5741853064309328, 0.555855261086386, 0.5450627691476087, 0.5355583287932212, 0.5280922618236165, 0.5201197493601364, 0.5155486224038465, 0.5108348901749258, 0.5062484163795337, 0.5045905820604195, 0.5010167689702231, 0.49921196285073904, 0.49565188007273786, 0.49260225679608804, 0.4902978226267443, 0.4860426423049914, 0.4874928039422204, 0.48457755517990797, 0.48168315310299836, 0.4807574039060038, 0.48079404804147846, 0.47633978105433444, 0.47726332911627445, 0.4720690926077154, 0.47445541382072925, 0.4742991717558504, 0.4705063715624118, 0.4698630942916704, 0.46843464744610275, 0.469582646274699, 0.4669798306745658, 0.46598397823219206, 0.4666525870897262, 0.4631726485302274, 0.46281058989407003, 0.4620729741719649, 0.46182158498382675, 0.46003785899668886, 0.46090737533923626, 0.45957946751087514, 0.4589876850041992, 0.459469253418916, 0.4555345940002038, 0.4551573978924448, 0.45545644192263957, 0.4550465620651218, 0.4532229122005429, 0.4545397712211529, 0.45233646586255727, 0.45263017819336254, 0.45357348157351746, 0.452498441998777, 0.4505949288779057, 0.4520736776018413, 0.45148865577690195, 0.4506524650835011, 0.4483471269521495, 0.44930854221096816, 0.45047644903183814, 0.4475862542292047, 0.44931173137765007, 0.4471861918571224, 0.447464091735783, 0.4493562423032647, 0.4439823975725122, 0.4430806828101491, 0.443674829635893, 0.4439635549228481, 0.44594776709298195, 0.443138491153983, 0.4462687776488679, 0.4407014153760674, 0.4419822053054303, 0.4432563560035037, 0.4428213371397508, 0.4404258981263648, 0.4417483556553536, 0.4406293152122655, 0.4390202451978885, 0.44058985737772766, 0.4385478060203521, 0.4384615747735653, 0.4385088478765558, 0.43882775828587023, 0.4404969904685391, 0.4371333757705535, 0.4378847800014226, 0.4353575968632998, 0.4362409336843519, 0.43611709913762026, 0.43631685184854796, 0.43850340813935207, 0.4352088210392017, 0.437372973039295, 0.43374313593127295, 0.4316157579553278, 0.43423218593750584, 0.43571412723930314, 0.43373760208463535, 0.4319711431058212, 0.43612430798606666, 0.43357940613726914, 0.4333913764917366, 0.4350846651629985, 0.4338787169464035, 0.4326307416775907, 0.4303825003879974, 0.4315388951080852, 0.4314189603757176, 0.4321283771836, 0.43103768705732654, 0.43292835568222177, 0.4315649038091665, 0.4306281610716714, 0.4305099228256207, 0.43164463773579603, 0.43059401857581764, 0.42944424401650827, 0.4285365026019957, 0.4314843328033947, 0.42885759851409944, 0.4287587330827404, 0.4295182412632226, 0.4292629025818714, 0.4286885004237296, 0.42876083449097524, 0.42943737920086794, 0.4276976751966114, 0.426729362098326, 0.4274873029874631, 0.4273703136620145, 0.4253489431823227, 0.4275429054372992, 0.42859577900031515, 0.426597559312528, 0.4252234984538707, 0.42627448660904926, 0.42456812962101875, 0.42531367599623576, 0.42490968725092226, 0.4257739609067775, 0.42532816308759946, 0.42471038208780737, 0.4246532023240744, 0.426182119713051, 0.42410641392599724, 0.42583109301479843, 0.4230952926690256, 0.42368858690420025, 0.4232027517840413, 0.4255006422969344, 0.42607651863928525, 0.42410538014521887, 0.42239216287714276, 0.42243009355316635, 0.42190912727256347, 0.42347483559624016, 0.423191613526273, 0.42311562515541035, 0.42316467390450585, 0.4220610502022135, 0.4227479750271719, 0.42331078379866993, 0.41983760796983205, 0.4207244827981196, 0.4217070707308032, 0.42174309493219425, 0.42299927749300065, 0.42174866367661207, 0.42256870926155776, 0.4203527626375171, 0.4217816821522782, 0.4205654255142141, 0.4202161425941967, 0.4198765115927199, 0.4194512891516565, 0.4222798216458351, 0.4177705276972223, 0.4214862111871513, 0.4195706792870164, 0.4191300557523409, 0.41885560531299737, 0.4186043351137839, 0.4197725952276858, 0.41928466780756396, 0.41893811613285714, 0.41928443018008194, 0.4190489338069323, 0.42049521404304996, 0.41811219525072185, 0.4196607644351279, 0.4205570254835289, 0.41840468537014747, 0.4178852834385713, 0.41777816949782615, 0.4203759580664122, 0.4178445338446309, 0.4155496068899865, 0.41793702100123387, 0.4176465157697803, 0.4179815484578359, 0.4184602122120336, 0.4182189312104316, 0.4170591449358027, 0.41620977642646323, 0.41638929487661697, 0.41502517362484675, 0.41857202234911567, 0.4174035128714916, 0.417661368568347, 0.41562215262279295, 0.41637375760008016, 0.41648583525200106, 0.4148583956968176, 0.4151459800289507, 0.4153308396452318, 0.4165846563661544, 0.41649495951093896, 0.41625309499512814, 0.4149497713051593, 0.41620491983839575, 0.4159904576042071, 0.4150791832696053, 0.4149921251356575, 0.41597340236736424, 0.4157616677350069, 0.41502233578730685, 0.4137085022291424, 0.41543874159557703, 0.41375972842321784, 0.41411166706754843, 0.41527171863951484, 0.4137223207806268, 0.4139560889858554, 0.4140622823735059, 0.4157163175881927, 0.4144953196433578, 0.41277483576779944, 0.41301254273634797, 0.4141054578708197, 0.41372047256159694, 0.41248706599927787, 0.41241694499492076, 0.4131458001830729, 0.41352839590650003, 0.4127198223918027, 0.4134189493180614, 0.41298536384629697, 0.41237920263984884, 0.4126206259150983, 0.4124997149798372, 0.4136655102684759, 0.4122458719699736, 0.41156866598456965, 0.4124327748910538, 0.41274132498745064, 0.4123769116988687, 0.41125116567399633, 0.41183284413929716, 0.41086718152792995, 0.4120583471306736, 0.4098141349674184, 0.4119213913715089, 0.4110583596753689, 0.41082124497595024, 0.4129522807071847, 0.4108359946816986, 0.4120001707097554, 0.4101638123673843, 0.4103469386667938, 0.4112805431681028, 0.41134381301560463, 0.4120055985336172, 0.4111197264280895, 0.41063937444422416, 0.40998997129726084, 0.4103062377361912, 0.40967799312436415, 0.4105147386005735, 0.4106767446081661, 0.4110228584449666, 0.41078776691615976, 0.4111960372598716, 0.40931556729641805, 0.41057157281196316, 0.4097592163165559, 0.4090301314747623, 0.4091104139293761, 0.40998375114856916, 0.408848105612771, 0.4093494612955169, 0.4102782909673175, 0.4085542624002651, 0.408881840992542, 0.40884544234351894, 0.4091809283376447, 0.41031578379222133, 0.4077421510801559, 0.4080359841099513, 0.40883359016115345, 0.4084546548448531, 0.4083275482744661, 0.4087416468729049, 0.4072020655704674, 0.40874277649619933, 0.41075964846718455, 0.4085238651217455, 0.4071774873697785, 0.4080122800698002, 0.4091827795601581, 0.4089257969169014, 0.40926626160850504, 0.408653849330251, 0.40880902502315625, 0.40861944786967225, 0.40665356812868636, 0.4070030551361856, 0.40940148903607343, 0.40748254612578055, 0.40735242630103335, 0.40719558806098294, 0.40884311675474694, 0.40833406635452746, 0.407897475476077, 0.40858039949094216, 0.4081282426043415, 0.4071428844995558, 0.40742648045260327, 0.4086129451774289, 0.407311673934204, 0.4077601021014244, 0.40729226794522405, 0.4066902118575303, 0.4062789824734756, 0.40713107306103286, 0.4064758123704234, 0.40812391565660305, 0.40599060373945667, 0.40735309129994346, 0.40635096575098306, 0.4066657664364717, 0.40570873931223034, 0.4063221469909079, 0.4060821785906632, 0.4048124467804257, 0.40637891548242144, 0.40520057961078215, 0.40645636735619106, 0.4057890329353358, 0.4058195808402686, 0.4042711085444724, 0.40593318727360356, 0.4065199398895303, 0.4055257264051388, 0.4053170820277166, 0.4074881936355036, 0.4067015054186043, 0.40657024623508187, 0.4053330302817295, 0.40423675887837307, 0.4041073735959768, 0.40488902780488456, 0.40528570229105304, 0.40585096223201284, 0.4045560040447102, 0.40550382343115954, 0.40560847786502163, 0.4041525581119605, 0.4056362094145783, 0.40506071843218233, 0.4051023715499582, 0.404313928125901, 0.4048205991578803, 0.4049654340612567, 0.40565875615390706, 0.40531549813121875, 0.4041167175718913, 0.4041395978254404, 0.4041822440265055, 0.40426406108408697, 0.40641953260852437, 0.40434114416490624, 0.40472395135782485, 0.40304325256458545, 0.406553001317163, 0.40514920998816845, 0.4045804820776366, 0.4030671003900356, 0.4050825683787898, 0.40481455431497415, 0.4022732068854791, 0.4045292922912882, 0.40301934397320605, 0.40460318128792194, 0.40419216348311493, 0.402229276270258, 0.40489499262039585, 0.4032994566639144, 0.4030224002630755, 0.402623141478087, 0.4033589946930753, 0.4013427521743798, 0.404117492946316, 0.40293795377023955, 0.4036968644927881, 0.4036791928491912, 0.40481859444847296, 0.4032618401030773, 0.40404114093273225, 0.4016817296448701, 0.40391364054157336, 0.4037883686239248, 0.40332017999039127, 0.40256916914148244, 0.40417594941750873, 0.40127667718091226, 0.40243040557637, 0.4018063582501532, 0.40248958633186566, 0.4018625213604016, 0.4029038773034973, 0.4020630432966368, 0.40257040066690036, 0.4020800682599516, 0.4026306591911116, 0.4021501932509093, 0.4006755654339963, 0.4019966336795589, 0.40314882914162176, 0.40204541553654877, 0.4017959437920556, 0.4038654339781601, 0.40292168299904385, 0.40204596934838793, 0.40394147365055844, 0.40149436245510084, 0.4012947729821055, 0.40041947179372445, 0.4004735263385687, 0.3997135078188632, 0.40077260023502154, 0.40321858751621154, 0.40184207079979817, 0.4039177819580855, 0.40088417545677163, 0.4003519813607582, 0.4026467217109099, 0.4022174334930391, 0.4020489948436537, 0.40267287970747745, 0.40368993344770454, 0.4010194998941079, 0.40281842650634675, 0.40055101439522506, 0.40148663132340007, 0.40137652517995837, 0.4008667351449138, 0.4007944955768963, 0.40113322273592494, 0.4012483214387318, 0.40091875607397975, 0.40215431226692866, 0.4013528769174775, 0.4011913930842355, 0.40230031295986285]}, {\"mode\": \"lines\", \"name\": \"val_loss\", \"type\": \"scatter\", \"y\": [1.1518674757576457, 0.5282494779775344, 0.9987094381586717, 0.5654471943641051, 0.5415778977360416, 0.5392290108497998, 0.47903909260402644, 0.4747182893786071, 0.9284308075544817, 0.47287002356076147, 0.48138416911036375, 0.5568134525119766, 0.6345263115933762, 0.48383959493553386, 0.5105269033333076, 0.7128830994459079, 0.4479138932550165, 0.49072257895024185, 0.4514826564503501, 0.5265887000492295, 0.5883616593813336, 0.5258241949027954, 0.5306740483565193, 0.474861161854355, 0.47514297471435757, 0.46640215240628635, 0.4408138780103676, 0.4714098651629025, 0.5070066581417906, 0.44728510520640063, 0.43745114056264556, 0.47057185529423323, 0.5628287266136216, 0.41816964864221623, 0.4713437444776129, 0.5243208184193078, 0.431125953495408, 0.562317249117771, 0.4232130205630659, 0.4513709683786339, 0.43534802407783646, 0.4546272785291522, 0.42939548375690834, 0.45658408599244277, 0.6385862026913414, 0.505267954074973, 0.449484524993647, 0.4638297241373519, 0.434006786495022, 0.4201676139665492, 0.7751503368703088, 0.5073634279854149, 0.41771630375005486, 0.48992784342815376, 0.44796362638262666, 0.4384321224008015, 0.416020765480164, 0.496509272465508, 0.47060494818665716, 0.4684852554324281, 0.4450256995904874, 0.42567316230999824, 0.43883900764247835, 0.5711735048952622, 0.44225138700920796, 0.4496249830232891, 0.4325020183831619, 0.4657723226831843, 0.5422584836978807, 0.5347813519682261, 0.41488287153142334, 0.42681885208798476, 0.40955449274282424, 0.4344968981051922, 0.40962434532871866, 0.4583444666815545, 0.40355553485847095, 0.43061718988911085, 0.5626996820265908, 0.43609256995688794, 0.40467795631922165, 0.4138136558264901, 0.4481066121112773, 0.43295591164780184, 0.42206099758445603, 0.4359248494921318, 0.4145428827877041, 0.536081732349786, 0.41465843212868875, 0.4827513674812421, 0.4322123448360319, 0.44539989254280543, 0.40552479555417836, 0.4688384404919359, 0.4347080723381367, 0.43257160807946415, 0.4179710611069221, 0.4282231449591551, 0.44513774644673904, 0.41908252533118145, 0.41359078485606776, 0.4325289363026136, 0.41682159584894235, 0.42471233653719076, 0.3889141201543314, 0.40946855687424366, 0.4328049052877716, 0.402165455064483, 0.4786492800412628, 0.41358879517622565, 0.42460593090735105, 0.4318948291249955, 0.419473418396833, 0.4050595672556135, 0.42974035638672925, 0.42624614332565286, 0.40701264667219783, 0.4010024569966315, 0.43481949840640877, 0.4429665097288287, 0.4202263619060704, 0.439626615306954, 0.4321619437984506, 0.4211387332539459, 0.46162058605698786, 0.4127126286350102, 0.40199802727274486, 0.43897367546641963, 0.42964962571628124, 0.4473460968290118, 0.40597936011972297, 0.3966762619422662, 0.4533297893811286, 0.4053174060157744, 0.40765192145545887, 0.40240967169582303, 0.45154637927174085, 0.4207883017617426, 0.4285535599264795, 0.40873202110120166, 0.42164627209424366, 0.4021554932253605, 0.4008952220953284, 0.46533013483052643, 0.4208458904485573, 0.4012086003871092, 0.39280134426539176, 0.4032604807825231, 0.4020585393420695, 0.4238515615804389, 0.446770293024066, 0.4051829884848955, 0.4063389580401874, 0.4210835137828881, 0.4266615609243415, 0.4082837975788398, 0.39553193527032143, 0.428151941778217, 0.41168077967772426, 0.4012966707585776, 0.39953813928539456, 0.40109748089622416, 0.4673085426178694, 0.40256089128535094, 0.42977379779193003, 0.39971152985941943, 0.3890847264462256, 0.4196108780137804, 0.39840459238511994, 0.43550602010113904, 0.3950986296937522, 0.4096038054225263, 0.4012740175409671, 0.40131124654033196, 0.41080241614277907, 0.3977688834670627, 0.4298502949048325, 0.3943388125554168, 0.40126857492857737, 0.40949849440830255, 0.4229834989073542, 0.41040531892492127, 0.4099894363342183, 0.40176805340404936, 0.4036662959994408, 0.38948811485373086, 0.39823488683237973, 0.4060182762355648, 0.388639945262417, 0.4067020518977353, 0.3906276723604391, 0.3899344358361308, 0.40872626354871355, 0.3845065947456654, 0.3947217524179964, 0.41599128836913607, 0.3906079062499582, 0.4247114568239131, 0.3894416599338447, 0.4033599161866633, 0.41222456596073553, 0.3943877827558069, 0.3861020882349545, 0.41622027669699496, 0.3894721299747518, 0.4061496025702694, 0.4287771773150148, 0.3947223757311499, 0.39037151403185727, 0.39969295757136436, 0.40660098757148455, 0.39747320564383826, 0.38788710977820673, 0.4001579390468675, 0.40144650074265686, 0.41999130414139374, 0.38585382881671537, 0.39923500758363056, 0.386778706279956, 0.400441617201761, 0.4039387370064509, 0.38522825435066776, 0.4166458621960524, 0.38273964164717766, 0.4027634686967484, 0.4037895763953324, 0.39909610836647236, 0.39954223359668056, 0.3977092524273086, 0.3954009284546441, 0.40181708239703046, 0.40036006849401795, 0.41006132419530517, 0.38642671909816984, 0.4061097649857744, 0.3972869920729795, 0.4005979422064455, 0.38722314081876114, 0.402327500287572, 0.3868909632865647, 0.39081547172455317, 0.4202553169863898, 0.3917693147084489, 0.39860693107161554, 0.4025727131775651, 0.40538107569215176, 0.41497237798188236, 0.4098817142170837, 0.4145035935433647, 0.433785480518737, 0.403631034413335, 0.3858347221570224, 0.3901295821781012, 0.3849239577774617, 0.3952338143160508, 0.4118660883342893, 0.3957635778855753, 0.3918732426827754, 0.39567472700664447, 0.39562937918801133, 0.4031004663178573, 0.39432053312785326, 0.39647167175647696, 0.38342115739463173, 0.39166965331318515, 0.41430180596337796, 0.39599107976125353, 0.38523713788138686, 0.3854172627240545, 0.39677986699420004, 0.4708887662246444, 0.38711866402589834, 0.3859054616393643, 0.39931542329540287, 0.3915750655098208, 0.3868521805494301, 0.39034920528316497, 0.392334536360695, 0.39395397219767936, 0.38576241227961505, 0.3897510343521624, 0.3898391828031197, 0.3845515283691545, 0.3933107836704662, 0.4036621691841252, 0.4030260010320268, 0.40471330127982447, 0.412266258581292, 0.40912924871161693, 0.40492765861423136, 0.39092382900197425, 0.4321625065084266, 0.400965628914611, 0.40770604119391785, 0.40045659390831895, 0.39456581293047743, 0.3860866363610954, 0.39916421014462067, 0.3928476166019821, 0.39973825413115666, 0.4144375815867494, 0.38915039319148764, 0.3925760379502903, 0.4024444329434482, 0.38278268715124764, 0.39376862340487356, 0.3980319670316774, 0.40032586201286213, 0.3862924762458677, 0.4014162818789711, 0.38566668414593785, 0.45113865558333827, 0.41684957965133096, 0.3945462149603722, 0.3936874412889187, 0.3823936610493496, 0.39324689001544627, 0.38598032150324885, 0.42813816336162364, 0.40079366810166933, 0.38799260749119274, 0.3908877723839323, 0.4068628375309969, 0.38622877715106596, 0.39347694244797865, 0.3918168349379113, 0.4049013218487686, 0.39117593938589745, 0.3847723920113655, 0.386945246883345, 0.3844847813890371, 0.378864167444467, 0.38723184831830937, 0.38331042642745033, 0.3884638634910911, 0.38903484684858747, 0.38306123449304685, 0.39096778294454176, 0.3894476896571074, 0.3833328693897784, 0.3866819540420893, 0.3944204090042615, 0.38266560110622794, 0.4004947971091075, 0.4145410449872718, 0.3911216753544903, 0.40500762612555, 0.3879746967235934, 0.3834500021321148, 0.3912945482231241, 0.4132319837104962, 0.38302552346279695, 0.385411823268878, 0.39524725672887645, 0.3883686076584091, 0.39342827100728006, 0.3915748683851438, 0.38416981392201843, 0.3998394961425224, 0.37961713563009297, 0.3855150069778048, 0.39744391158255227, 0.38561094707789545, 0.3968468343705748, 0.3914287212025037, 0.4004682636237515, 0.39009556671903595, 0.37709022544453563, 0.3831402560557483, 0.397537615812773, 0.39302652022821527, 0.39003913664045636, 0.40583595990303195, 0.38916570168589687, 0.38847142972345616, 0.40092334788031514, 0.3821870182149929, 0.3894516134550108, 0.39156167205592873, 0.38807815460135475, 0.3793079546978746, 0.38902778485733486, 0.3833221071764703, 0.4089843423157571, 0.3903790758354712, 0.4163381449362415, 0.3780001708273754, 0.38004610954842954, 0.3879931429086046, 0.38626346866450895, 0.39404098907587326, 0.3935067232482073, 0.3937250462880599, 0.37918410311591644, 0.41135703291675557, 0.3803186721735401, 0.38312288797625144, 0.4393201280663793, 0.3842183407360958, 0.3925431831860355, 0.41016015108774906, 0.3842727019056394, 0.381727346394366, 0.38847970663611064, 0.3843495861250054, 0.39094631938963287, 0.3870854516148784, 0.3971550903387783, 0.39362510889945135, 0.38693476033468144, 0.3839543114754807, 0.4122181721156607, 0.393760926446278, 0.3907495606013416, 0.37994405913632634, 0.38472639105736534, 0.4064106304797785, 0.39128310354951285, 0.3933934099053901, 0.3788700994413143, 0.4053219072569839, 0.41227259187838716, 0.3793749821587667, 0.38757057878650497, 0.41412504520125215, 0.37755281558190923, 0.39987006900793115, 0.38496507600351887, 0.40940365810555485, 0.3789277125573708, 0.38528986475623667, 0.40983292849660485, 0.38887179540538774, 0.3874570868366208, 0.38931855181418357, 0.3823854024727988, 0.3830415683855166, 0.3892583846856933, 0.387925117659932, 0.39126522181096984, 0.38359874899663327, 0.3776999907216429, 0.3789609437028135, 0.3852297162840967, 0.3899584978436487, 0.3964501941664152, 0.3854291231880752, 0.39460487974469566, 0.3836271597523109, 0.39770093716612503, 0.38912822334078273, 0.3776462041604278, 0.39371677195677157, 0.38128788534654606, 0.3834537251085822, 0.3920991821809891, 0.3839417452900193, 0.3904898323268989, 0.3987776281991544, 0.37961771760061114, 0.39404957258083306, 0.40987621251224476, 0.4188072384641998, 0.39128829771871154, 0.3803825386344568, 0.39034753339779266, 0.38162337520813905, 0.39018500333287365]}, {\"mode\": \"lines\", \"name\": \"val_acc\", \"type\": \"scatter\", \"y\": [0.6385843730154246, 0.8238807941166949, 0.6766114375584157, 0.8120838946897605, 0.8160217564886634, 0.8109659419522659, 0.8347265999588603, 0.8380470862934581, 0.6981695628938371, 0.8352271757710493, 0.8337087643468551, 0.7919106953247229, 0.803740966790661, 0.8322237228422691, 0.8191253244543686, 0.7675493476246867, 0.8481587149684312, 0.8286195768385619, 0.8464901291608584, 0.8264504166111762, 0.776976856222277, 0.8066276199748317, 0.8115165741272451, 0.8375131383666792, 0.8357444376594299, 0.8355608934250673, 0.8456892067768937, 0.8346765433354968, 0.8174233682677035, 0.8447381141250168, 0.8474745944862647, 0.8362783855175845, 0.8084797492827859, 0.8549331719974274, 0.8272179657248787, 0.8149204909830325, 0.846039610897963, 0.798718524032694, 0.8526472094017975, 0.840700136661625, 0.8461730983786755, 0.8388146355066161, 0.8509118809702558, 0.8339423660996802, 0.7669987148599366, 0.8238140506214964, 0.8463900150876567, 0.8402663050338608, 0.8460229248595647, 0.8509619391849065, 0.7318249330275413, 0.8148370602937632, 0.856351470511054, 0.8225792984377586, 0.8461397263327098, 0.8463232716610823, 0.8524803513739131, 0.829604042760701, 0.8350102597582563, 0.8380303991610498, 0.8544826551269084, 0.8507283370650908, 0.8447214287519753, 0.8076621428495319, 0.8470073907817037, 0.8375631953262022, 0.8505948496530026, 0.8426356969263836, 0.7927449878649996, 0.8138525941727133, 0.8537151045899983, 0.8486426055070343, 0.8571190194566768, 0.8475580239820686, 0.8582536580028277, 0.8368457048558032, 0.8589544643861441, 0.8523134922142256, 0.8021891821270358, 0.8510119962369229, 0.8580200562500027, 0.8558675801713619, 0.8473577940076741, 0.8464734428240936, 0.8553002607336877, 0.8485925468945619, 0.8558175228826415, 0.8340758527469561, 0.8576362815439682, 0.820960769651371, 0.8483589444763798, 0.8466236159453827, 0.85671855917869, 0.840766880019575, 0.8462398412701795, 0.8466903601984317, 0.8516794313768792, 0.8502110751150479, 0.845238689309642, 0.8568854176043963, 0.8574193656306307, 0.8436869050130074, 0.8557007219067735, 0.8505781634156934, 0.8640269631707418, 0.8566017579044557, 0.8499274153464831, 0.8603393896603397, 0.8442709090280794, 0.8556006064720266, 0.8510453679845222, 0.8521132622089997, 0.8513790849731833, 0.8595217840227292, 0.8471241909310969, 0.8521466345155387, 0.8596719559505528, 0.8604895626821732, 0.8464901297267599, 0.8394987553234255, 0.8509118807027207, 0.842936041440426, 0.84722430885223, 0.8555338632821563, 0.8354440924183681, 0.8591880660086825, 0.8595718419390135, 0.846406701554708, 0.8541322522987598, 0.8407835660579734, 0.8592047517795457, 0.8619746039192242, 0.8384976031639773, 0.8593382383651591, 0.8582202866530503, 0.857169077571872, 0.8430695286536033, 0.8500609023915806, 0.8513290271563544, 0.8586541196423596, 0.8498940433999729, 0.8586874894625123, 0.8609067093963803, 0.8290367234224822, 0.8539153331033925, 0.8597887553351337, 0.8649613724695174, 0.8611736817033392, 0.8599222428466773, 0.8542490514844298, 0.8495269544031394, 0.8580033703418909, 0.8588209773410465, 0.8535983042108631, 0.8518796608539965, 0.8572024478276395, 0.8620079753992883, 0.846974020265363, 0.8567352438247122, 0.8596385835753897, 0.858820978335601, 0.8589878353380997, 0.8325741248439429, 0.8605062481546701, 0.8502110752145033, 0.8611236260745302, 0.8627421527345603, 0.8541155645387876, 0.8609901369716995, 0.8476915102693157, 0.8629256976342798, 0.8566351307768961, 0.8606063633596749, 0.8592714955353176, 0.8574861075962044, 0.8621581470595768, 0.8490931224083845, 0.8633261583100884, 0.8586874904262355, 0.8566685024558711, 0.8538152193593883, 0.8578031385772982, 0.856551700783815, 0.8604061329188343, 0.8584705743139871, 0.8650614877053534, 0.8597387007008791, 0.8588543487216551, 0.86409370722488, 0.8607231643663741, 0.8623083209078852, 0.8634262733161823, 0.8572191347919682, 0.8672973927825207, 0.8612737973369969, 0.8545160253826759, 0.866362983452914, 0.8491765509782582, 0.8638267336627933, 0.8585706887850106, 0.858637432441327, 0.8630925575518178, 0.8653117746014778, 0.8548497431978117, 0.8641437647433425, 0.8574694221853699, 0.8522634363865057, 0.8629423844683218, 0.8648779415505061, 0.8596385839045873, 0.8580033700126933, 0.8612571120942422, 0.8643273097733486, 0.8592881809461521, 0.8608900235260616, 0.8509786246265721, 0.8658123509487372, 0.8604895633097371, 0.8643773671923557, 0.8585540033125137, 0.8596052120267014, 0.86542857673998, 0.8574193649652737, 0.8671972761543085, 0.8575528523465307, 0.8620079743739026, 0.8606397348705702, 0.8615074001152077, 0.8610401956836273, 0.8632260433417877, 0.8595551540109616, 0.8610568814544906, 0.8555338636799781, 0.8640102785247197, 0.859238122861788, 0.8625085510811907, 0.8593382386635255, 0.8653117747695576, 0.8593882962814434, 0.8643773677890884, 0.8635597593667254, 0.8517628595797622, 0.8630258129009469, 0.8608566510822742, 0.8589711484046023, 0.8591546939318857, 0.8523969217786538, 0.8559676959353062, 0.8558842652152058, 0.8529475562033152, 0.8565016418729762, 0.8659792090760771, 0.8638434189363793, 0.8653952044642723, 0.8620580333841968, 0.8585206318324496, 0.8617243158982586, 0.8625919815407179, 0.8611236256767084, 0.8616075137597564, 0.8611903678720243, 0.863125926415209, 0.8626253529213266, 0.8663129265311841, 0.8635931319099682, 0.8579032539125896, 0.8634596454238103, 0.864794514671375, 0.8668135035060074, 0.8634429595534915, 0.8350603181409867, 0.8654786332638881, 0.8648445710958277, 0.8595217820336202, 0.8643606811231261, 0.8646443411900573, 0.8644107393377768, 0.8637433046642666, 0.863092555830244, 0.8648445707974614, 0.8644774831243798, 0.8645108532806919, 0.8660459532982949, 0.8638601054412237, 0.8584372023366457, 0.8594550395707692, 0.8562847268547377, 0.8591213217864646, 0.8579199410449979, 0.8580367418905792, 0.8643439948858168, 0.8529976140201441, 0.857886569633558, 0.8574527366134175, 0.8624751789735627, 0.8616575715457541, 0.8658123506503708, 0.860406133316656, 0.862208206735228, 0.8592881788884188, 0.8534147597775896, 0.8656788639344708, 0.8616075157180342, 0.8599389277224415, 0.8658957805748276, 0.8617410025642209, 0.862058034279296, 0.859271496529872, 0.8646610266317231, 0.8597553863414558, 0.8654619486486971, 0.8416345447361041, 0.8555839209309055, 0.8626587241338555, 0.8632594148218518, 0.8672306489959177, 0.8618411172719485, 0.8645442249904981, 0.8470574479709687, 0.8626086663170266, 0.8643606809242153, 0.8635097022152535, 0.8574527367128729, 0.8645609120920752, 0.8636431900251634, 0.8626420381640814, 0.8604561904372968, 0.8631092420675532, 0.8667634443962576, 0.8649780589743619, 0.8667300720519256, 0.867113846528218, 0.8647277701885839, 0.8681650568028616, 0.8635430745904166, 0.8643273086793387, 0.8665632146207739, 0.865028116393369, 0.8641103941275462, 0.8661961258536824, 0.8643273109359828, 0.8614740273422228, 0.8684153449232827, 0.8612404254591111, 0.8540488222062232, 0.8624084355161572, 0.860723164136632, 0.8641103921384373, 0.8670804770372629, 0.8626754109370663, 0.8561345540318149, 0.8671138477216834, 0.8663796699885896, 0.8604061348084878, 0.8640603357139847, 0.8619078617547395, 0.8649780575133613, 0.8656955493075122, 0.8617743734167211, 0.8670304171627008, 0.8663629835523694, 0.8614573426962007, 0.8661627543736183, 0.8620246616365976, 0.8642105094628376, 0.859321552824038, 0.8619912886338705, 0.8677479113129513, 0.86614606833522, 0.8610902551225745, 0.8615741446357918, 0.8642271945375127, 0.8568353602540135, 0.8640603363107173, 0.8649947446457696, 0.8623250075121851, 0.8671138472552373, 0.8629256967391808, 0.8659124649224834, 0.8640269650295641, 0.8669303032884099, 0.8651449173692369, 0.8665131565055787, 0.8555505488232775, 0.8642271942083152, 0.853881962885418, 0.8681650565044953, 0.867497623123906, 0.8655787487980903, 0.8664130420962176, 0.8629757558797617, 0.8633261586084547, 0.8639435342408395, 0.8668969312116132, 0.8585706897487339, 0.8673808215513052, 0.8657456076902426, 0.8452553756841997, 0.8659625242003128, 0.8624084364112563, 0.8584538869140436, 0.8673808215821365, 0.8669803600112289, 0.8650281143356358, 0.8668135025114528, 0.864010277927987, 0.865628805918731, 0.8616909464073035, 0.861607514754311, 0.8652950908197236, 0.8653785181275075, 0.8547829992122977, 0.8625419227293345, 0.8638767917779885, 0.8686322602090564, 0.8651282310324722, 0.8570189043202964, 0.864544225854766, 0.862458493531897, 0.8681650582946934, 0.8601391584924797, 0.8583704597743392, 0.8674475632185127, 0.8635764458715698, 0.8541656225545273, 0.8686155748976773, 0.8625252375860352, 0.866229497861855, 0.8566184434455769, 0.8673975068935156, 0.8657289221799526, 0.8563848417922072, 0.8648278848276871, 0.866579899695449, 0.8651449168033355, 0.8664130414994848, 0.8665965853051945, 0.8632594149213072, 0.8662962409214386, 0.8643106238344057, 0.8663796696902233, 0.8681316844276985, 0.8675143092617598, 0.8651115444967965, 0.8633762157977197, 0.8625919807450743, 0.8646276553505698, 0.8619579192732021, 0.8668301889785043, 0.8596552700116099, 0.8643273086485075, 0.8681650567034062, 0.8629423835732228, 0.8666299584760012, 0.8654786339600762, 0.8633428444171111, 0.8659458383916565, 0.8649947443165722, 0.8602392738963953, 0.867881397531574, 0.8624418080902313, 0.8564515851809884, 0.8580367407965693, 0.8644774820303699, 0.8668635593337273, 0.8637599905037542, 0.8669303031889545, 0.8638767909823449]}],\n",
              "                        {\"template\": {\"data\": {\"bar\": [{\"error_x\": {\"color\": \"#2a3f5f\"}, \"error_y\": {\"color\": \"#2a3f5f\"}, \"marker\": {\"line\": {\"color\": \"#E5ECF6\", \"width\": 0.5}}, \"type\": \"bar\"}], \"barpolar\": [{\"marker\": {\"line\": {\"color\": \"#E5ECF6\", \"width\": 0.5}}, \"type\": \"barpolar\"}], \"carpet\": [{\"aaxis\": {\"endlinecolor\": \"#2a3f5f\", \"gridcolor\": \"white\", \"linecolor\": \"white\", \"minorgridcolor\": \"white\", \"startlinecolor\": \"#2a3f5f\"}, \"baxis\": {\"endlinecolor\": \"#2a3f5f\", \"gridcolor\": \"white\", \"linecolor\": \"white\", \"minorgridcolor\": \"white\", \"startlinecolor\": \"#2a3f5f\"}, \"type\": \"carpet\"}], \"choropleth\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"choropleth\"}], \"contour\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"contour\"}], \"contourcarpet\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"contourcarpet\"}], \"heatmap\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"heatmap\"}], \"heatmapgl\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"heatmapgl\"}], \"histogram\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"histogram\"}], \"histogram2d\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"histogram2d\"}], \"histogram2dcontour\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"histogram2dcontour\"}], \"mesh3d\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"mesh3d\"}], \"parcoords\": [{\"line\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"parcoords\"}], \"pie\": [{\"automargin\": true, \"type\": \"pie\"}], \"scatter\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatter\"}], \"scatter3d\": [{\"line\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatter3d\"}], \"scattercarpet\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattercarpet\"}], \"scattergeo\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattergeo\"}], \"scattergl\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattergl\"}], \"scattermapbox\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattermapbox\"}], \"scatterpolar\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterpolar\"}], \"scatterpolargl\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterpolargl\"}], \"scatterternary\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterternary\"}], \"surface\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"surface\"}], \"table\": [{\"cells\": {\"fill\": {\"color\": \"#EBF0F8\"}, \"line\": {\"color\": \"white\"}}, \"header\": {\"fill\": {\"color\": \"#C8D4E3\"}, \"line\": {\"color\": \"white\"}}, \"type\": \"table\"}]}, \"layout\": {\"annotationdefaults\": {\"arrowcolor\": \"#2a3f5f\", \"arrowhead\": 0, \"arrowwidth\": 1}, \"coloraxis\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"colorscale\": {\"diverging\": [[0, \"#8e0152\"], [0.1, \"#c51b7d\"], [0.2, \"#de77ae\"], [0.3, \"#f1b6da\"], [0.4, \"#fde0ef\"], [0.5, \"#f7f7f7\"], [0.6, \"#e6f5d0\"], [0.7, \"#b8e186\"], [0.8, \"#7fbc41\"], [0.9, \"#4d9221\"], [1, \"#276419\"]], \"sequential\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"sequentialminus\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]]}, \"colorway\": [\"#636efa\", \"#EF553B\", \"#00cc96\", \"#ab63fa\", \"#FFA15A\", \"#19d3f3\", \"#FF6692\", \"#B6E880\", \"#FF97FF\", \"#FECB52\"], \"font\": {\"color\": \"#2a3f5f\"}, \"geo\": {\"bgcolor\": \"white\", \"lakecolor\": \"white\", \"landcolor\": \"#E5ECF6\", \"showlakes\": true, \"showland\": true, \"subunitcolor\": \"white\"}, \"hoverlabel\": {\"align\": \"left\"}, \"hovermode\": \"closest\", \"mapbox\": {\"style\": \"light\"}, \"paper_bgcolor\": \"white\", \"plot_bgcolor\": \"#E5ECF6\", \"polar\": {\"angularaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}, \"bgcolor\": \"#E5ECF6\", \"radialaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}}, \"scene\": {\"xaxis\": {\"backgroundcolor\": \"#E5ECF6\", \"gridcolor\": \"white\", \"gridwidth\": 2, \"linecolor\": \"white\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\"}, \"yaxis\": {\"backgroundcolor\": \"#E5ECF6\", \"gridcolor\": \"white\", \"gridwidth\": 2, \"linecolor\": \"white\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\"}, \"zaxis\": {\"backgroundcolor\": \"#E5ECF6\", \"gridcolor\": \"white\", \"gridwidth\": 2, \"linecolor\": \"white\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\"}}, \"shapedefaults\": {\"line\": {\"color\": \"#2a3f5f\"}}, \"ternary\": {\"aaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}, \"baxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}, \"bgcolor\": \"#E5ECF6\", \"caxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}}, \"title\": {\"x\": 0.05}, \"xaxis\": {\"automargin\": true, \"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\", \"title\": {\"standoff\": 15}, \"zerolinecolor\": \"white\", \"zerolinewidth\": 2}, \"yaxis\": {\"automargin\": true, \"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\", \"title\": {\"standoff\": 15}, \"zerolinecolor\": \"white\", \"zerolinewidth\": 2}}}},\n",
              "                        {\"responsive\": true}\n",
              "                    ).then(function(){\n",
              "                            \n",
              "var gd = document.getElementById('543730d8-f864-47a9-9438-4a9154eb4c12');\n",
              "var x = new MutationObserver(function (mutations, observer) {{\n",
              "        var display = window.getComputedStyle(gd).display;\n",
              "        if (!display || display === 'none') {{\n",
              "            console.log([gd, 'removed!']);\n",
              "            Plotly.purge(gd);\n",
              "            observer.disconnect();\n",
              "        }}\n",
              "}});\n",
              "\n",
              "// Listen for the removal of the full notebook cells\n",
              "var notebookContainer = gd.closest('#notebook-container');\n",
              "if (notebookContainer) {{\n",
              "    x.observe(notebookContainer, {childList: true});\n",
              "}}\n",
              "\n",
              "// Listen for the clearing of the current output cell\n",
              "var outputEl = gd.closest('.output');\n",
              "if (outputEl) {{\n",
              "    x.observe(outputEl, {childList: true});\n",
              "}}\n",
              "\n",
              "                        })\n",
              "                };\n",
              "                \n",
              "            </script>\n",
              "        </div>\n",
              "</body>\n",
              "</html>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "fbtg6S6AIdJE",
        "colab": {}
      },
      "source": [
        "# fig, loss_ax = plt.subplots()\n",
        "# # acc_ax = loss_ax.twinx()\n",
        "\n",
        "# loss_ax.plot(history.history['loss'], 'y', label='train loss')\n",
        "# loss_ax.plot(history.history['val_loss'], 'r', label='val loss')\n",
        "# loss_ax.set_xlabel('epoch')\n",
        "# loss_ax.set_ylabel('loss')\n",
        "# loss_ax.legend(loc='upper left')\n",
        "\n",
        "# # # acc_ax.plot(history.history['categorical_crossentropy'], 'b', label='train crossentropy')\n",
        "# # # acc_ax.plot(history.history['val_categorical_crossentropy'], 'g', label='val crossentropy')\n",
        "# # # acc_ax.set_ylabel('categorical_crossentropy')\n",
        "# # # acc_ax.legend(loc='upper right')\n",
        "\n",
        "# plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "P1lPPJBiIdJJ",
        "colab": {}
      },
      "source": [
        "real_y_pred = best_model.predict(test_X)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "JwLvngasIdJO",
        "colab": {}
      },
      "source": [
        "submission = pd.DataFrame(data=real_y_pred, columns=sample_submission_df.columns, index=sample_submission_df.index)\n",
        "submission.to_csv('submission_keras_renewal_0.3734.csv', index=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "kUfxKxAUIdJT",
        "colab": {}
      },
      "source": [
        "### 기록 1.레이어 2. 옴티마이저  ==> val_loss\n",
        "#1. 9개,// 2. 0.0003 ==> 0.404\n",
        "#1. 8개(256*2)층 하나 제거 //2. 0.0001 ==> 0.666179819053121\n",
        "#1. 8개 //2. 0.0005 ==> 0.47\n",
        "#1. 7개 //2. 0.0002 ==> 0.38\n",
        "#1. 8개(256*1)층 하나 추가 //2. 0.0002 ==> 0.0.3935\n",
        "#1. 8개(파생변수만 남기고 전부 제거) // 2. 0.0002 ==>0.5719 "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "yA-2NZ7XuSJM",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}