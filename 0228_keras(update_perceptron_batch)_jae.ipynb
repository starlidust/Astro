{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "0228_keras(update_perceptron_feature_add)_jae의 사본",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.4"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/starlidust/Astro/blob/master/0228_keras(update_perceptron_batch)_jae.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "FAnG9WAJIdG3",
        "outputId": "72250978-98bf-4fe8-9102-a6e9b56a44bf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 63
        }
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import lightgbm as lgb\n",
        "import tensorflow as tf\n",
        "import chart_studio.plotly as py\n",
        "\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.metrics import log_loss\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "from tensorflow import keras"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "ratlOsTrIqkA",
        "outputId": "bf42ac20-cae6-4e3d-f345-8cf19d965705",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 125
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "MjaMyZkkI36o",
        "colab": {}
      },
      "source": [
        "import os\n",
        "os.chdir('/content/drive/My Drive/data_con/')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "9TJVuvADIdHA",
        "colab": {}
      },
      "source": [
        "path = \"./data/\" \n",
        "train_df = pd.read_csv(path+'train.csv',index_col=0)\n",
        "test_df = pd.read_csv(path+'test.csv',index_col=0)\n",
        "sample_submission_df = pd.read_csv(path+'sample_submission.csv',index_col=0)\n",
        "pd.options.display.max_columns = 30"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Vhfz2BXRIdHG",
        "colab": {}
      },
      "source": [
        "##conda install keras-gpu 하면 gpu도 괴롭힐 수 있음"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "quYDTIuSXfjd",
        "colab": {}
      },
      "source": [
        "## 원핫 인코딩 함수\n",
        "def prepare_inputs(X_train, X_test):\n",
        "    ohe =  OneHotEncoder()\n",
        "    ohe.fit(X_train)\n",
        "    x_train_enc = ohe.transform(X_train)\n",
        "    X_test_enc = ohe.transform(X_test)\n",
        "    return X_train_enc, X_test_enc"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "sZsLrP8DIdHL"
      },
      "source": [
        "## 전처리\n",
        " - 이상치 확인 및 처리"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "VdNREsVMIdHN",
        "outputId": "062ca4b0-d072-45d8-c0a8-4d8ff7ada6ee",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "train_df.shape"
      ],
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(199991, 22)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 65
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "T6PAAhPuIdHS",
        "outputId": "64370bd9-9528-48c6-bb11-b1bbec397ca8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 304
        }
      },
      "source": [
        "train_df.describe()"
      ],
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>fiberID</th>\n",
              "      <th>psfMag_u</th>\n",
              "      <th>psfMag_g</th>\n",
              "      <th>psfMag_r</th>\n",
              "      <th>psfMag_i</th>\n",
              "      <th>psfMag_z</th>\n",
              "      <th>fiberMag_u</th>\n",
              "      <th>fiberMag_g</th>\n",
              "      <th>fiberMag_r</th>\n",
              "      <th>fiberMag_i</th>\n",
              "      <th>fiberMag_z</th>\n",
              "      <th>petroMag_u</th>\n",
              "      <th>petroMag_g</th>\n",
              "      <th>petroMag_r</th>\n",
              "      <th>petroMag_i</th>\n",
              "      <th>petroMag_z</th>\n",
              "      <th>modelMag_u</th>\n",
              "      <th>modelMag_g</th>\n",
              "      <th>modelMag_r</th>\n",
              "      <th>modelMag_i</th>\n",
              "      <th>modelMag_z</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>199991.000000</td>\n",
              "      <td>1.999910e+05</td>\n",
              "      <td>199991.000000</td>\n",
              "      <td>199991.000000</td>\n",
              "      <td>199991.000000</td>\n",
              "      <td>199991.000000</td>\n",
              "      <td>1.999910e+05</td>\n",
              "      <td>199991.000000</td>\n",
              "      <td>199991.000000</td>\n",
              "      <td>199991.000000</td>\n",
              "      <td>199991.000000</td>\n",
              "      <td>199991.000000</td>\n",
              "      <td>199991.000000</td>\n",
              "      <td>199991.000000</td>\n",
              "      <td>199991.000000</td>\n",
              "      <td>199991.000000</td>\n",
              "      <td>199991.000000</td>\n",
              "      <td>199991.000000</td>\n",
              "      <td>199991.000000</td>\n",
              "      <td>199991.000000</td>\n",
              "      <td>199991.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>360.830152</td>\n",
              "      <td>-6.750146e+00</td>\n",
              "      <td>18.675373</td>\n",
              "      <td>18.401235</td>\n",
              "      <td>18.043495</td>\n",
              "      <td>17.663526</td>\n",
              "      <td>1.084986e+01</td>\n",
              "      <td>19.072693</td>\n",
              "      <td>19.134483</td>\n",
              "      <td>18.183331</td>\n",
              "      <td>18.000882</td>\n",
              "      <td>21.837903</td>\n",
              "      <td>18.454136</td>\n",
              "      <td>18.481525</td>\n",
              "      <td>17.686617</td>\n",
              "      <td>17.699207</td>\n",
              "      <td>20.110991</td>\n",
              "      <td>18.544375</td>\n",
              "      <td>18.181544</td>\n",
              "      <td>17.692395</td>\n",
              "      <td>17.189281</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>225.305890</td>\n",
              "      <td>1.187678e+04</td>\n",
              "      <td>155.423024</td>\n",
              "      <td>127.128078</td>\n",
              "      <td>116.622194</td>\n",
              "      <td>123.735298</td>\n",
              "      <td>4.172116e+03</td>\n",
              "      <td>749.256162</td>\n",
              "      <td>90.049058</td>\n",
              "      <td>122.378972</td>\n",
              "      <td>145.862346</td>\n",
              "      <td>789.472333</td>\n",
              "      <td>154.376277</td>\n",
              "      <td>97.240448</td>\n",
              "      <td>145.730872</td>\n",
              "      <td>142.691880</td>\n",
              "      <td>122.299062</td>\n",
              "      <td>161.728183</td>\n",
              "      <td>133.984475</td>\n",
              "      <td>131.183416</td>\n",
              "      <td>133.685138</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>1.000000</td>\n",
              "      <td>-5.310802e+06</td>\n",
              "      <td>-40022.466071</td>\n",
              "      <td>-27184.795793</td>\n",
              "      <td>-26566.310827</td>\n",
              "      <td>-24878.828280</td>\n",
              "      <td>-1.864766e+06</td>\n",
              "      <td>-215882.917191</td>\n",
              "      <td>-21802.656144</td>\n",
              "      <td>-20208.516262</td>\n",
              "      <td>-26505.602101</td>\n",
              "      <td>-24463.431833</td>\n",
              "      <td>-25958.752324</td>\n",
              "      <td>-23948.588523</td>\n",
              "      <td>-40438.184078</td>\n",
              "      <td>-30070.729379</td>\n",
              "      <td>-26236.578659</td>\n",
              "      <td>-36902.402336</td>\n",
              "      <td>-36439.638493</td>\n",
              "      <td>-38969.416822</td>\n",
              "      <td>-26050.710196</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>174.000000</td>\n",
              "      <td>1.965259e+01</td>\n",
              "      <td>18.701180</td>\n",
              "      <td>18.048572</td>\n",
              "      <td>17.747663</td>\n",
              "      <td>17.425523</td>\n",
              "      <td>1.994040e+01</td>\n",
              "      <td>18.902851</td>\n",
              "      <td>18.259352</td>\n",
              "      <td>17.903615</td>\n",
              "      <td>17.606148</td>\n",
              "      <td>19.247795</td>\n",
              "      <td>18.113933</td>\n",
              "      <td>17.479794</td>\n",
              "      <td>17.050294</td>\n",
              "      <td>16.804705</td>\n",
              "      <td>19.266214</td>\n",
              "      <td>18.076120</td>\n",
              "      <td>17.423425</td>\n",
              "      <td>16.977671</td>\n",
              "      <td>16.705774</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>349.000000</td>\n",
              "      <td>2.087136e+01</td>\n",
              "      <td>19.904235</td>\n",
              "      <td>19.454492</td>\n",
              "      <td>19.043895</td>\n",
              "      <td>18.611799</td>\n",
              "      <td>2.104910e+01</td>\n",
              "      <td>20.069038</td>\n",
              "      <td>19.631419</td>\n",
              "      <td>19.188763</td>\n",
              "      <td>18.710967</td>\n",
              "      <td>20.366848</td>\n",
              "      <td>19.586559</td>\n",
              "      <td>19.182789</td>\n",
              "      <td>18.693370</td>\n",
              "      <td>18.174592</td>\n",
              "      <td>20.406840</td>\n",
              "      <td>19.547674</td>\n",
              "      <td>19.143156</td>\n",
              "      <td>18.641756</td>\n",
              "      <td>18.100997</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>526.000000</td>\n",
              "      <td>2.216043e+01</td>\n",
              "      <td>21.150297</td>\n",
              "      <td>20.515936</td>\n",
              "      <td>20.073528</td>\n",
              "      <td>19.883760</td>\n",
              "      <td>2.233754e+01</td>\n",
              "      <td>21.385830</td>\n",
              "      <td>20.773911</td>\n",
              "      <td>20.331419</td>\n",
              "      <td>20.133179</td>\n",
              "      <td>21.797480</td>\n",
              "      <td>21.004397</td>\n",
              "      <td>20.457491</td>\n",
              "      <td>20.019112</td>\n",
              "      <td>19.807652</td>\n",
              "      <td>21.992898</td>\n",
              "      <td>20.962386</td>\n",
              "      <td>20.408140</td>\n",
              "      <td>19.968846</td>\n",
              "      <td>19.819554</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>1000.000000</td>\n",
              "      <td>1.877392e+04</td>\n",
              "      <td>3538.984910</td>\n",
              "      <td>3048.110913</td>\n",
              "      <td>4835.218639</td>\n",
              "      <td>9823.740407</td>\n",
              "      <td>4.870154e+03</td>\n",
              "      <td>248077.513380</td>\n",
              "      <td>12084.735440</td>\n",
              "      <td>8059.638535</td>\n",
              "      <td>18358.921741</td>\n",
              "      <td>298771.019041</td>\n",
              "      <td>12139.815877</td>\n",
              "      <td>7003.136546</td>\n",
              "      <td>9772.190537</td>\n",
              "      <td>17403.789263</td>\n",
              "      <td>14488.251976</td>\n",
              "      <td>10582.058590</td>\n",
              "      <td>12237.951703</td>\n",
              "      <td>4062.499371</td>\n",
              "      <td>7420.534172</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "             fiberID      psfMag_u       psfMag_g       psfMag_r  \\\n",
              "count  199991.000000  1.999910e+05  199991.000000  199991.000000   \n",
              "mean      360.830152 -6.750146e+00      18.675373      18.401235   \n",
              "std       225.305890  1.187678e+04     155.423024     127.128078   \n",
              "min         1.000000 -5.310802e+06  -40022.466071  -27184.795793   \n",
              "25%       174.000000  1.965259e+01      18.701180      18.048572   \n",
              "50%       349.000000  2.087136e+01      19.904235      19.454492   \n",
              "75%       526.000000  2.216043e+01      21.150297      20.515936   \n",
              "max      1000.000000  1.877392e+04    3538.984910    3048.110913   \n",
              "\n",
              "            psfMag_i       psfMag_z    fiberMag_u     fiberMag_g  \\\n",
              "count  199991.000000  199991.000000  1.999910e+05  199991.000000   \n",
              "mean       18.043495      17.663526  1.084986e+01      19.072693   \n",
              "std       116.622194     123.735298  4.172116e+03     749.256162   \n",
              "min    -26566.310827  -24878.828280 -1.864766e+06 -215882.917191   \n",
              "25%        17.747663      17.425523  1.994040e+01      18.902851   \n",
              "50%        19.043895      18.611799  2.104910e+01      20.069038   \n",
              "75%        20.073528      19.883760  2.233754e+01      21.385830   \n",
              "max      4835.218639    9823.740407  4.870154e+03  248077.513380   \n",
              "\n",
              "          fiberMag_r     fiberMag_i     fiberMag_z     petroMag_u  \\\n",
              "count  199991.000000  199991.000000  199991.000000  199991.000000   \n",
              "mean       19.134483      18.183331      18.000882      21.837903   \n",
              "std        90.049058     122.378972     145.862346     789.472333   \n",
              "min    -21802.656144  -20208.516262  -26505.602101  -24463.431833   \n",
              "25%        18.259352      17.903615      17.606148      19.247795   \n",
              "50%        19.631419      19.188763      18.710967      20.366848   \n",
              "75%        20.773911      20.331419      20.133179      21.797480   \n",
              "max     12084.735440    8059.638535   18358.921741  298771.019041   \n",
              "\n",
              "          petroMag_g     petroMag_r     petroMag_i     petroMag_z  \\\n",
              "count  199991.000000  199991.000000  199991.000000  199991.000000   \n",
              "mean       18.454136      18.481525      17.686617      17.699207   \n",
              "std       154.376277      97.240448     145.730872     142.691880   \n",
              "min    -25958.752324  -23948.588523  -40438.184078  -30070.729379   \n",
              "25%        18.113933      17.479794      17.050294      16.804705   \n",
              "50%        19.586559      19.182789      18.693370      18.174592   \n",
              "75%        21.004397      20.457491      20.019112      19.807652   \n",
              "max     12139.815877    7003.136546    9772.190537   17403.789263   \n",
              "\n",
              "          modelMag_u     modelMag_g     modelMag_r     modelMag_i  \\\n",
              "count  199991.000000  199991.000000  199991.000000  199991.000000   \n",
              "mean       20.110991      18.544375      18.181544      17.692395   \n",
              "std       122.299062     161.728183     133.984475     131.183416   \n",
              "min    -26236.578659  -36902.402336  -36439.638493  -38969.416822   \n",
              "25%        19.266214      18.076120      17.423425      16.977671   \n",
              "50%        20.406840      19.547674      19.143156      18.641756   \n",
              "75%        21.992898      20.962386      20.408140      19.968846   \n",
              "max     14488.251976   10582.058590   12237.951703    4062.499371   \n",
              "\n",
              "          modelMag_z  \n",
              "count  199991.000000  \n",
              "mean       17.189281  \n",
              "std       133.685138  \n",
              "min    -26050.710196  \n",
              "25%        16.705774  \n",
              "50%        18.100997  \n",
              "75%        19.819554  \n",
              "max      7420.534172  "
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 66
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "PQyieXjqIdHV",
        "colab": {}
      },
      "source": [
        "def del_outlier(data, min=0, max=60):\n",
        "    up_idx_t=()\n",
        "    dw_idx_t=()\n",
        "    train_light = data.iloc[:,2:]\n",
        "    for i in range(len(train_light.columns)):\n",
        "        col = train_light.columns[i]\n",
        "        up_idx_t+=tuple(data[data[col]>max].index)\n",
        "        dw_idx_t+=tuple(data[data[col]<min].index)\n",
        "    del_idx = set(up_idx_t+dw_idx_t)\n",
        "    \n",
        "    return data[~data.index.isin(del_idx)]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "nOW3yLvUIdHb",
        "colab": {}
      },
      "source": [
        "train_df = del_outlier(train_df, min=-20, max=60)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "h63rnOB9IdHg",
        "outputId": "8d628b20-90da-4723-8caa-644ce4b5ae02",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        }
      },
      "source": [
        "train_df.columns, train_df.shape"
      ],
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(Index(['type', 'fiberID', 'psfMag_u', 'psfMag_g', 'psfMag_r', 'psfMag_i',\n",
              "        'psfMag_z', 'fiberMag_u', 'fiberMag_g', 'fiberMag_r', 'fiberMag_i',\n",
              "        'fiberMag_z', 'petroMag_u', 'petroMag_g', 'petroMag_r', 'petroMag_i',\n",
              "        'petroMag_z', 'modelMag_u', 'modelMag_g', 'modelMag_r', 'modelMag_i',\n",
              "        'modelMag_z'],\n",
              "       dtype='object'), (199770, 22))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 69
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "xEriLvN2IdHj"
      },
      "source": [
        "## DATA Setting"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "t5-DMEgwIdHl",
        "colab": {}
      },
      "source": [
        "column_number = {}\n",
        "number_columns = {}\n",
        "for i, column in enumerate(sample_submission_df.columns):\n",
        "    column_number[column] = i\n",
        "    number_columns[i] = column\n",
        "    \n",
        "    \n",
        "def to_number(x, dic):\n",
        "    return dic[x]\n",
        "\n",
        "train_df['type_num'] = train_df['type'].apply(lambda x: to_number(x, column_number))\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "fsjNmwYlIdHq",
        "colab": {}
      },
      "source": [
        "def add_minus_feature(data,test = False):\n",
        "    from itertools import combinations\n",
        "    n = 0\n",
        "    for count in range(5,21,5):\n",
        "        s = 2\n",
        "        if test == True :\n",
        "            s = 1\n",
        "        selected = data.columns[s:].values[n:count]\n",
        "        mag = str.split(selected[0],'_')[0]\n",
        "        for combi in list(combinations(selected,2)):\n",
        "            name_1st = str.split(combi[0],'_')[1]\n",
        "            name_2nd = str.split(combi[1],'_')[1]\n",
        "            data[mag+\"_\"+name_1st+\"-\"+name_2nd] = data[combi[0]]-data[combi[1]]\n",
        "        n=count\n",
        "    return data"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9i_Fidfc4fqL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "##파생변수추가\n",
        "ori_name = [\"psfMag\",\"fiberMag\",\"petroMag\",\"modelMag\"]\n",
        "add_name = [\"u\",\"g\",\"r\",\"i\",\"z\"]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uG1fSpy14iRd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for add in add_name:\n",
        "    selected = list(map(lambda x : x+\"_\"+add,ori_name))\n",
        "    columns = train_df[selected].columns \n",
        "    columns = list(columns)\n",
        "    columns.append(\"fiberID\")\n",
        "    \n",
        "    #dictinary_set\n",
        "    std_dict = dict(train_df[columns].groupby(\"fiberID\").std().std(axis = 1))\n",
        "    \n",
        "    #save\n",
        "    train_df[\"std_\"+add] = train_df.fiberID.apply(lambda x : std_dict.get(x))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "79WJqELKPc8U",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for add in add_name:\n",
        "    selected = list(map(lambda x : x+\"_\"+add,ori_name))\n",
        "    columns = test_df[selected].columns \n",
        "    columns = list(columns)\n",
        "    columns.append(\"fiberID\")\n",
        "    \n",
        "    #dictinary_set\n",
        "    std_dict = dict(test_df[columns].groupby(\"fiberID\").std().std(axis = 1))\n",
        "    \n",
        "    #save\n",
        "    test_df[\"std_\"+add] = test_df.fiberID.apply(lambda x : std_dict.get(x))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "hQK90dmoIdHw",
        "colab": {}
      },
      "source": [
        "train_df = add_minus_feature(train_df)\n",
        "test_df = add_minus_feature(test_df,True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "wNh3Nq8tIdH1",
        "colab": {}
      },
      "source": [
        "train_X = train_df.drop(columns=['type', 'type_num'], axis=1)\n",
        "train_y = train_df['type_num']\n",
        "test_X = test_df"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Ebv7h9icIdH6",
        "outputId": "99e6e36a-0b10-40e1-f315-2ec9170057b8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 290
        }
      },
      "source": [
        "train_X.head()"
      ],
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>fiberID</th>\n",
              "      <th>psfMag_u</th>\n",
              "      <th>psfMag_g</th>\n",
              "      <th>psfMag_r</th>\n",
              "      <th>psfMag_i</th>\n",
              "      <th>psfMag_z</th>\n",
              "      <th>fiberMag_u</th>\n",
              "      <th>fiberMag_g</th>\n",
              "      <th>fiberMag_r</th>\n",
              "      <th>fiberMag_i</th>\n",
              "      <th>fiberMag_z</th>\n",
              "      <th>petroMag_u</th>\n",
              "      <th>petroMag_g</th>\n",
              "      <th>petroMag_r</th>\n",
              "      <th>petroMag_i</th>\n",
              "      <th>...</th>\n",
              "      <th>petroMag_g-i</th>\n",
              "      <th>petroMag_g-z</th>\n",
              "      <th>petroMag_r-i</th>\n",
              "      <th>petroMag_r-z</th>\n",
              "      <th>petroMag_i-z</th>\n",
              "      <th>modelMag_u-g</th>\n",
              "      <th>modelMag_u-r</th>\n",
              "      <th>modelMag_u-i</th>\n",
              "      <th>modelMag_u-z</th>\n",
              "      <th>modelMag_g-r</th>\n",
              "      <th>modelMag_g-i</th>\n",
              "      <th>modelMag_g-z</th>\n",
              "      <th>modelMag_r-i</th>\n",
              "      <th>modelMag_r-z</th>\n",
              "      <th>modelMag_i-z</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>id</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>601</td>\n",
              "      <td>23.198224</td>\n",
              "      <td>21.431953</td>\n",
              "      <td>21.314148</td>\n",
              "      <td>21.176553</td>\n",
              "      <td>21.171444</td>\n",
              "      <td>22.581309</td>\n",
              "      <td>21.644453</td>\n",
              "      <td>21.657571</td>\n",
              "      <td>21.387653</td>\n",
              "      <td>21.572827</td>\n",
              "      <td>22.504317</td>\n",
              "      <td>21.431636</td>\n",
              "      <td>21.478312</td>\n",
              "      <td>21.145409</td>\n",
              "      <td>...</td>\n",
              "      <td>0.286226</td>\n",
              "      <td>1.009190</td>\n",
              "      <td>0.332902</td>\n",
              "      <td>1.055866</td>\n",
              "      <td>0.722964</td>\n",
              "      <td>1.283708</td>\n",
              "      <td>1.385054</td>\n",
              "      <td>1.728637</td>\n",
              "      <td>1.601901</td>\n",
              "      <td>0.101347</td>\n",
              "      <td>0.444929</td>\n",
              "      <td>0.318194</td>\n",
              "      <td>0.343582</td>\n",
              "      <td>0.216847</td>\n",
              "      <td>-0.126735</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>788</td>\n",
              "      <td>21.431355</td>\n",
              "      <td>20.708104</td>\n",
              "      <td>20.678850</td>\n",
              "      <td>20.703420</td>\n",
              "      <td>20.473229</td>\n",
              "      <td>21.868797</td>\n",
              "      <td>21.029773</td>\n",
              "      <td>20.967054</td>\n",
              "      <td>20.937731</td>\n",
              "      <td>21.063646</td>\n",
              "      <td>21.360701</td>\n",
              "      <td>20.778968</td>\n",
              "      <td>20.889705</td>\n",
              "      <td>20.639812</td>\n",
              "      <td>...</td>\n",
              "      <td>0.139156</td>\n",
              "      <td>0.132308</td>\n",
              "      <td>0.249893</td>\n",
              "      <td>0.243045</td>\n",
              "      <td>-0.006847</td>\n",
              "      <td>0.734428</td>\n",
              "      <td>0.739030</td>\n",
              "      <td>0.799566</td>\n",
              "      <td>0.980641</td>\n",
              "      <td>0.004602</td>\n",
              "      <td>0.065138</td>\n",
              "      <td>0.246213</td>\n",
              "      <td>0.060537</td>\n",
              "      <td>0.241611</td>\n",
              "      <td>0.181074</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>427</td>\n",
              "      <td>17.851451</td>\n",
              "      <td>16.727898</td>\n",
              "      <td>16.679677</td>\n",
              "      <td>16.694640</td>\n",
              "      <td>16.641788</td>\n",
              "      <td>18.171890</td>\n",
              "      <td>17.033098</td>\n",
              "      <td>16.999682</td>\n",
              "      <td>17.095999</td>\n",
              "      <td>17.076449</td>\n",
              "      <td>17.867253</td>\n",
              "      <td>16.738784</td>\n",
              "      <td>16.688874</td>\n",
              "      <td>16.744210</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.005426</td>\n",
              "      <td>-0.069222</td>\n",
              "      <td>-0.055336</td>\n",
              "      <td>-0.119132</td>\n",
              "      <td>-0.063796</td>\n",
              "      <td>1.120628</td>\n",
              "      <td>1.176814</td>\n",
              "      <td>1.157885</td>\n",
              "      <td>1.129134</td>\n",
              "      <td>0.056186</td>\n",
              "      <td>0.037257</td>\n",
              "      <td>0.008506</td>\n",
              "      <td>-0.018929</td>\n",
              "      <td>-0.047680</td>\n",
              "      <td>-0.028751</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>864</td>\n",
              "      <td>20.789900</td>\n",
              "      <td>20.040371</td>\n",
              "      <td>19.926909</td>\n",
              "      <td>19.843840</td>\n",
              "      <td>19.463270</td>\n",
              "      <td>21.039030</td>\n",
              "      <td>20.317165</td>\n",
              "      <td>20.217898</td>\n",
              "      <td>20.073852</td>\n",
              "      <td>19.794505</td>\n",
              "      <td>20.433907</td>\n",
              "      <td>19.993727</td>\n",
              "      <td>19.985531</td>\n",
              "      <td>19.750917</td>\n",
              "      <td>...</td>\n",
              "      <td>0.242810</td>\n",
              "      <td>0.538610</td>\n",
              "      <td>0.234614</td>\n",
              "      <td>0.530413</td>\n",
              "      <td>0.295800</td>\n",
              "      <td>0.769012</td>\n",
              "      <td>0.880913</td>\n",
              "      <td>1.012598</td>\n",
              "      <td>1.217856</td>\n",
              "      <td>0.111901</td>\n",
              "      <td>0.243586</td>\n",
              "      <td>0.448844</td>\n",
              "      <td>0.131685</td>\n",
              "      <td>0.336943</td>\n",
              "      <td>0.205258</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>612</td>\n",
              "      <td>26.454969</td>\n",
              "      <td>23.058767</td>\n",
              "      <td>21.471406</td>\n",
              "      <td>19.504961</td>\n",
              "      <td>18.389096</td>\n",
              "      <td>25.700632</td>\n",
              "      <td>23.629122</td>\n",
              "      <td>21.742750</td>\n",
              "      <td>19.861718</td>\n",
              "      <td>18.810375</td>\n",
              "      <td>25.859229</td>\n",
              "      <td>22.426929</td>\n",
              "      <td>21.673551</td>\n",
              "      <td>19.610012</td>\n",
              "      <td>...</td>\n",
              "      <td>2.816917</td>\n",
              "      <td>4.050788</td>\n",
              "      <td>2.063539</td>\n",
              "      <td>3.297411</td>\n",
              "      <td>1.233871</td>\n",
              "      <td>1.729059</td>\n",
              "      <td>3.401710</td>\n",
              "      <td>5.389723</td>\n",
              "      <td>6.501398</td>\n",
              "      <td>1.672651</td>\n",
              "      <td>3.660663</td>\n",
              "      <td>4.772338</td>\n",
              "      <td>1.988012</td>\n",
              "      <td>3.099688</td>\n",
              "      <td>1.111675</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 66 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "    fiberID   psfMag_u   psfMag_g   psfMag_r   psfMag_i   psfMag_z  \\\n",
              "id                                                                   \n",
              "0       601  23.198224  21.431953  21.314148  21.176553  21.171444   \n",
              "1       788  21.431355  20.708104  20.678850  20.703420  20.473229   \n",
              "2       427  17.851451  16.727898  16.679677  16.694640  16.641788   \n",
              "3       864  20.789900  20.040371  19.926909  19.843840  19.463270   \n",
              "4       612  26.454969  23.058767  21.471406  19.504961  18.389096   \n",
              "\n",
              "    fiberMag_u  fiberMag_g  fiberMag_r  fiberMag_i  fiberMag_z  petroMag_u  \\\n",
              "id                                                                           \n",
              "0    22.581309   21.644453   21.657571   21.387653   21.572827   22.504317   \n",
              "1    21.868797   21.029773   20.967054   20.937731   21.063646   21.360701   \n",
              "2    18.171890   17.033098   16.999682   17.095999   17.076449   17.867253   \n",
              "3    21.039030   20.317165   20.217898   20.073852   19.794505   20.433907   \n",
              "4    25.700632   23.629122   21.742750   19.861718   18.810375   25.859229   \n",
              "\n",
              "    petroMag_g  petroMag_r  petroMag_i  ...  petroMag_g-i  petroMag_g-z  \\\n",
              "id                                      ...                               \n",
              "0    21.431636   21.478312   21.145409  ...      0.286226      1.009190   \n",
              "1    20.778968   20.889705   20.639812  ...      0.139156      0.132308   \n",
              "2    16.738784   16.688874   16.744210  ...     -0.005426     -0.069222   \n",
              "3    19.993727   19.985531   19.750917  ...      0.242810      0.538610   \n",
              "4    22.426929   21.673551   19.610012  ...      2.816917      4.050788   \n",
              "\n",
              "    petroMag_r-i  petroMag_r-z  petroMag_i-z  modelMag_u-g  modelMag_u-r  \\\n",
              "id                                                                         \n",
              "0       0.332902      1.055866      0.722964      1.283708      1.385054   \n",
              "1       0.249893      0.243045     -0.006847      0.734428      0.739030   \n",
              "2      -0.055336     -0.119132     -0.063796      1.120628      1.176814   \n",
              "3       0.234614      0.530413      0.295800      0.769012      0.880913   \n",
              "4       2.063539      3.297411      1.233871      1.729059      3.401710   \n",
              "\n",
              "    modelMag_u-i  modelMag_u-z  modelMag_g-r  modelMag_g-i  modelMag_g-z  \\\n",
              "id                                                                         \n",
              "0       1.728637      1.601901      0.101347      0.444929      0.318194   \n",
              "1       0.799566      0.980641      0.004602      0.065138      0.246213   \n",
              "2       1.157885      1.129134      0.056186      0.037257      0.008506   \n",
              "3       1.012598      1.217856      0.111901      0.243586      0.448844   \n",
              "4       5.389723      6.501398      1.672651      3.660663      4.772338   \n",
              "\n",
              "    modelMag_r-i  modelMag_r-z  modelMag_i-z  \n",
              "id                                            \n",
              "0       0.343582      0.216847     -0.126735  \n",
              "1       0.060537      0.241611      0.181074  \n",
              "2      -0.018929     -0.047680     -0.028751  \n",
              "3       0.131685      0.336943      0.205258  \n",
              "4       1.988012      3.099688      1.111675  \n",
              "\n",
              "[5 rows x 66 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 77
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "BiMDAd9ZIdID",
        "outputId": "2ea48386-70dc-475f-cd86-c7227c996143",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 298
        }
      },
      "source": [
        "train_X.columns"
      ],
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['fiberID', 'psfMag_u', 'psfMag_g', 'psfMag_r', 'psfMag_i', 'psfMag_z',\n",
              "       'fiberMag_u', 'fiberMag_g', 'fiberMag_r', 'fiberMag_i', 'fiberMag_z',\n",
              "       'petroMag_u', 'petroMag_g', 'petroMag_r', 'petroMag_i', 'petroMag_z',\n",
              "       'modelMag_u', 'modelMag_g', 'modelMag_r', 'modelMag_i', 'modelMag_z',\n",
              "       'std_u', 'std_g', 'std_r', 'std_i', 'std_z', 'psfMag_u-g', 'psfMag_u-r',\n",
              "       'psfMag_u-i', 'psfMag_u-z', 'psfMag_g-r', 'psfMag_g-i', 'psfMag_g-z',\n",
              "       'psfMag_r-i', 'psfMag_r-z', 'psfMag_i-z', 'fiberMag_u-g',\n",
              "       'fiberMag_u-r', 'fiberMag_u-i', 'fiberMag_u-z', 'fiberMag_g-r',\n",
              "       'fiberMag_g-i', 'fiberMag_g-z', 'fiberMag_r-i', 'fiberMag_r-z',\n",
              "       'fiberMag_i-z', 'petroMag_u-g', 'petroMag_u-r', 'petroMag_u-i',\n",
              "       'petroMag_u-z', 'petroMag_g-r', 'petroMag_g-i', 'petroMag_g-z',\n",
              "       'petroMag_r-i', 'petroMag_r-z', 'petroMag_i-z', 'modelMag_u-g',\n",
              "       'modelMag_u-r', 'modelMag_u-i', 'modelMag_u-z', 'modelMag_g-r',\n",
              "       'modelMag_g-i', 'modelMag_g-z', 'modelMag_r-i', 'modelMag_r-z',\n",
              "       'modelMag_i-z'],\n",
              "      dtype='object')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 78
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "sax8LG7lIdIK",
        "colab": {}
      },
      "source": [
        "## u-g, g-r, r-i, i-z 만 남기는게 좋지 않을까????\n",
        "train_X.drop(['psfMag_u-r','psfMag_u-i','psfMag_u-z','psfMag_g-i','psfMag_g-z','psfMag_r-z',\n",
        "             'fiberMag_u-r','fiberMag_u-i','fiberMag_u-z','fiberMag_g-i','fiberMag_g-z','fiberMag_r-z',\n",
        "             'petroMag_u-r','petroMag_u-i','petroMag_u-z','petroMag_g-i','petroMag_g-z','petroMag_r-z',\n",
        "             'modelMag_u-r','modelMag_u-i','modelMag_u-z','modelMag_g-i','modelMag_g-z','modelMag_r-z'] ,axis=1, inplace=True)\n",
        "\n",
        "test_X.drop(['psfMag_u-r','psfMag_u-i','psfMag_u-z','psfMag_g-i','psfMag_g-z','psfMag_r-z',\n",
        "             'fiberMag_u-r','fiberMag_u-i','fiberMag_u-z','fiberMag_g-i','fiberMag_g-z','fiberMag_r-z',\n",
        "             'petroMag_u-r','petroMag_u-i','petroMag_u-z','petroMag_g-i','petroMag_g-z','petroMag_r-z',\n",
        "         'modelMag_u-r','modelMag_u-i','modelMag_u-z','modelMag_g-i','modelMag_g-z','modelMag_r-z'] ,axis=1, inplace=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Y6pvdT1rIdIP",
        "outputId": "6ff3301c-a6b5-4348-9395-986ddebc45b9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "train_X.shape, test_X.shape"
      ],
      "execution_count": 80,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((199770, 42), (10009, 42))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 80
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "BUQNSQmmN5MR",
        "outputId": "707e7fc0-0233-45ca-b8df-ff1e32d39879",
        "scrolled": true,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 193
        }
      },
      "source": [
        "train_X.columns"
      ],
      "execution_count": 81,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['fiberID', 'psfMag_u', 'psfMag_g', 'psfMag_r', 'psfMag_i', 'psfMag_z',\n",
              "       'fiberMag_u', 'fiberMag_g', 'fiberMag_r', 'fiberMag_i', 'fiberMag_z',\n",
              "       'petroMag_u', 'petroMag_g', 'petroMag_r', 'petroMag_i', 'petroMag_z',\n",
              "       'modelMag_u', 'modelMag_g', 'modelMag_r', 'modelMag_i', 'modelMag_z',\n",
              "       'std_u', 'std_g', 'std_r', 'std_i', 'std_z', 'psfMag_u-g', 'psfMag_g-r',\n",
              "       'psfMag_r-i', 'psfMag_i-z', 'fiberMag_u-g', 'fiberMag_g-r',\n",
              "       'fiberMag_r-i', 'fiberMag_i-z', 'petroMag_u-g', 'petroMag_g-r',\n",
              "       'petroMag_r-i', 'petroMag_i-z', 'modelMag_u-g', 'modelMag_g-r',\n",
              "       'modelMag_r-i', 'modelMag_i-z'],\n",
              "      dtype='object')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 81
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O0Ku8WNU2G-k",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# train_fi, test_fi = prepare_inputs(train_X.fiberID, test_X.fiberID)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "iwqJJUOxOPIx",
        "colab": {}
      },
      "source": [
        "## fiber 관련변수 전부 제거\n",
        "train_X.drop(['fiberID'], axis=1, inplace=True)\n",
        "#'fiberMag_u', 'fiberMag_g', 'fiberMag_r', 'fiberMag_i', 'fiberMag_z', 'fiberMag_u-g','fiberMag_g-r', 'fiberMag_r-i', 'fiberMag_i-z', \n",
        "test_X.drop(['fiberID'], axis=1, inplace=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "yZVRWqedIdIa",
        "outputId": "a8dbf0ea-294a-40c3-a4e0-d3a9e0988731",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "train_X.shape, test_X.shape"
      ],
      "execution_count": 84,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((199770, 41), (10009, 41))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 84
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "3_Nds360IdIe",
        "colab": {}
      },
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(train_X, train_y, test_size=0.3, random_state=42,stratify = train_y)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "2fCs6Z2zIdIi",
        "colab": {}
      },
      "source": [
        "o_hot = OneHotEncoder()\n",
        "y_train= o_hot.fit_transform(y_train.values.reshape(-1,1))\n",
        "y_train = y_train.toarray()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "2mwvZZ0tIdIn",
        "scrolled": true,
        "colab": {}
      },
      "source": [
        "o2_hot = OneHotEncoder()\n",
        "y_test= o2_hot.fit_transform(y_test.values.reshape(-1,1))\n",
        "y_test = y_test.toarray()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "C8DaauwYIdIr",
        "outputId": "1469b518-53bd-4ab1-e27d-a607cbaba505",
        "scrolled": true,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "y_train.shape, y_test.shape"
      ],
      "execution_count": 88,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((139839, 19), (59931, 19))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 88
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "pg79AzKhIdIu",
        "outputId": "af6ff004-8609-4d0c-c6ca-51fce11b6363",
        "scrolled": true,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "X_train = X_train.values\n",
        "X_train.shape"
      ],
      "execution_count": 89,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(139839, 41)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 89
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "n8eI0u2nIdI0",
        "outputId": "8fc9d9f3-c9d8-4d93-ab87-c8b03e8cedf1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "X_test = X_test.values\n",
        "X_test.shape"
      ],
      "execution_count": 90,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(59931, 41)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 90
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "cWbu6unjIdI5",
        "outputId": "b877ff0e-b87b-448a-9bcf-5619a5063fb4",
        "scrolled": true,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Flatten, Dropout\n",
        "from keras.layers import BatchNormalization\n",
        "from keras.layers import ELU\n",
        "\n",
        "elu_alpha=0.3\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Dense(256*4, input_dim=X_train.shape[1]))\n",
        "model.add(BatchNormalization())\n",
        "model.add(ELU(alpha=elu_alpha))\n",
        "model.add(Dropout(0.3))\n",
        "model.add(Dense(256*3))\n",
        "model.add(BatchNormalization())\n",
        "model.add(ELU(alpha=elu_alpha))\n",
        "model.add(Dropout(0.3))\n",
        "model.add(Dense(256*2))\n",
        "model.add(BatchNormalization())\n",
        "model.add(ELU(alpha=elu_alpha))\n",
        "model.add(Dropout(0.3))\n",
        "model.add(Dense(256*1))\n",
        "model.add(BatchNormalization())\n",
        "model.add(ELU(alpha=elu_alpha))\n",
        "model.add(Dropout(0.3))\n",
        "model.add(Dense(256*1))\n",
        "model.add(BatchNormalization())\n",
        "model.add(ELU(alpha=elu_alpha))\n",
        "model.add(Dropout(0.3))\n",
        "model.add(Dense(128))\n",
        "model.add(BatchNormalization())\n",
        "model.add(ELU(alpha=elu_alpha))\n",
        "model.add(Dropout(0.3))\n",
        "model.add(Dense(64, activation='elu'))\n",
        "model.add(ELU(alpha=elu_alpha))\n",
        "model.add(Dense(32, activation='elu'))\n",
        "model.add(Dense(19, activation='softmax'))\n",
        "\n",
        "\n",
        "from keras.losses import categorical_crossentropy\n",
        "from keras.optimizers import Adam\n",
        "from keras.callbacks import EarlyStopping\n",
        "from keras.callbacks import ModelCheckpoint\n",
        "\n",
        "## 얼리스타핑\n",
        "es = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=110)\n",
        "\n",
        "##최적모델 기억\n",
        "mc = ModelCheckpoint('best_model.h5', monitor='val_loss', mode='min', save_best_only=True)\n",
        "epochs = 1000\n",
        "model.compile(loss='categorical_crossentropy',\n",
        "              optimizer=Adam(0.0001, decay=1e-2/epochs), metrics=['accuracy','categorical_crossentropy'])\n",
        "\n",
        "history=model.fit(X_train, y_train, validation_data=(X_test, y_test) ,batch_size=200, epochs=1000, verbose=1,\n",
        "                 callbacks=[es, mc])\n",
        "### validation_data를 쓰면 test 데이터가 따로있을때 직접 넣을 수 있다.\n",
        "model.evaluate(X_test, y_test)"
      ],
      "execution_count": 109,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 139839 samples, validate on 59931 samples\n",
            "Epoch 1/1000\n",
            "139839/139839 [==============================] - 17s 125us/step - loss: 1.1480 - acc: 0.6796 - categorical_crossentropy: 1.1480 - val_loss: 0.7409 - val_acc: 0.7770 - val_categorical_crossentropy: 0.7409\n",
            "Epoch 2/1000\n",
            "139839/139839 [==============================] - 12s 89us/step - loss: 0.6711 - acc: 0.7905 - categorical_crossentropy: 0.6711 - val_loss: 0.6068 - val_acc: 0.7998 - val_categorical_crossentropy: 0.6068\n",
            "Epoch 3/1000\n",
            "139839/139839 [==============================] - 12s 89us/step - loss: 0.6042 - acc: 0.8053 - categorical_crossentropy: 0.6042 - val_loss: 0.5480 - val_acc: 0.8169 - val_categorical_crossentropy: 0.5480\n",
            "Epoch 4/1000\n",
            "139839/139839 [==============================] - 13s 91us/step - loss: 0.5730 - acc: 0.8127 - categorical_crossentropy: 0.5730 - val_loss: 0.5046 - val_acc: 0.8256 - val_categorical_crossentropy: 0.5046\n",
            "Epoch 5/1000\n",
            "139839/139839 [==============================] - 13s 90us/step - loss: 0.5547 - acc: 0.8171 - categorical_crossentropy: 0.5547 - val_loss: 0.5035 - val_acc: 0.8283 - val_categorical_crossentropy: 0.5035\n",
            "Epoch 6/1000\n",
            "139839/139839 [==============================] - 12s 88us/step - loss: 0.5362 - acc: 0.8217 - categorical_crossentropy: 0.5362 - val_loss: 0.6368 - val_acc: 0.7831 - val_categorical_crossentropy: 0.6368\n",
            "Epoch 7/1000\n",
            "139839/139839 [==============================] - 12s 88us/step - loss: 0.5267 - acc: 0.8245 - categorical_crossentropy: 0.5267 - val_loss: 0.4797 - val_acc: 0.8332 - val_categorical_crossentropy: 0.4797\n",
            "Epoch 8/1000\n",
            "139839/139839 [==============================] - 12s 88us/step - loss: 0.5172 - acc: 0.8261 - categorical_crossentropy: 0.5172 - val_loss: 0.8203 - val_acc: 0.6940 - val_categorical_crossentropy: 0.8203\n",
            "Epoch 9/1000\n",
            "139839/139839 [==============================] - 12s 88us/step - loss: 0.5084 - acc: 0.8283 - categorical_crossentropy: 0.5084 - val_loss: 1.6066 - val_acc: 0.5999 - val_categorical_crossentropy: 1.6066\n",
            "Epoch 10/1000\n",
            "139839/139839 [==============================] - 12s 87us/step - loss: 0.5019 - acc: 0.8315 - categorical_crossentropy: 0.5019 - val_loss: 1.1087 - val_acc: 0.6849 - val_categorical_crossentropy: 1.1087\n",
            "Epoch 11/1000\n",
            "139839/139839 [==============================] - 12s 88us/step - loss: 0.4976 - acc: 0.8320 - categorical_crossentropy: 0.4976 - val_loss: 1.2569 - val_acc: 0.6704 - val_categorical_crossentropy: 1.2569\n",
            "Epoch 12/1000\n",
            "139839/139839 [==============================] - 12s 87us/step - loss: 0.4899 - acc: 0.8333 - categorical_crossentropy: 0.4899 - val_loss: 0.6557 - val_acc: 0.7654 - val_categorical_crossentropy: 0.6557\n",
            "Epoch 13/1000\n",
            "139839/139839 [==============================] - 12s 89us/step - loss: 0.4893 - acc: 0.8349 - categorical_crossentropy: 0.4893 - val_loss: 0.6589 - val_acc: 0.7659 - val_categorical_crossentropy: 0.6589\n",
            "Epoch 14/1000\n",
            "139839/139839 [==============================] - 13s 92us/step - loss: 0.4832 - acc: 0.8361 - categorical_crossentropy: 0.4832 - val_loss: 0.4553 - val_acc: 0.8448 - val_categorical_crossentropy: 0.4553\n",
            "Epoch 15/1000\n",
            "139839/139839 [==============================] - 12s 87us/step - loss: 0.4775 - acc: 0.8380 - categorical_crossentropy: 0.4775 - val_loss: 0.8856 - val_acc: 0.6794 - val_categorical_crossentropy: 0.8856\n",
            "Epoch 16/1000\n",
            "139839/139839 [==============================] - 12s 87us/step - loss: 0.4771 - acc: 0.8377 - categorical_crossentropy: 0.4771 - val_loss: 0.8845 - val_acc: 0.7132 - val_categorical_crossentropy: 0.8845\n",
            "Epoch 17/1000\n",
            "139839/139839 [==============================] - 12s 87us/step - loss: 0.4742 - acc: 0.8399 - categorical_crossentropy: 0.4742 - val_loss: 0.4890 - val_acc: 0.8281 - val_categorical_crossentropy: 0.4890\n",
            "Epoch 18/1000\n",
            "139839/139839 [==============================] - 12s 89us/step - loss: 0.4711 - acc: 0.8403 - categorical_crossentropy: 0.4711 - val_loss: 0.6868 - val_acc: 0.7442 - val_categorical_crossentropy: 0.6868\n",
            "Epoch 19/1000\n",
            "139839/139839 [==============================] - 12s 87us/step - loss: 0.4667 - acc: 0.8408 - categorical_crossentropy: 0.4667 - val_loss: 0.7375 - val_acc: 0.7591 - val_categorical_crossentropy: 0.7375\n",
            "Epoch 20/1000\n",
            "139839/139839 [==============================] - 12s 87us/step - loss: 0.4649 - acc: 0.8412 - categorical_crossentropy: 0.4649 - val_loss: 0.4492 - val_acc: 0.8438 - val_categorical_crossentropy: 0.4492\n",
            "Epoch 21/1000\n",
            "139839/139839 [==============================] - 12s 87us/step - loss: 0.4631 - acc: 0.8416 - categorical_crossentropy: 0.4631 - val_loss: 0.6328 - val_acc: 0.7842 - val_categorical_crossentropy: 0.6328\n",
            "Epoch 22/1000\n",
            "139839/139839 [==============================] - 12s 87us/step - loss: 0.4632 - acc: 0.8421 - categorical_crossentropy: 0.4632 - val_loss: 0.5423 - val_acc: 0.8009 - val_categorical_crossentropy: 0.5423\n",
            "Epoch 23/1000\n",
            "139839/139839 [==============================] - 12s 88us/step - loss: 0.4595 - acc: 0.8431 - categorical_crossentropy: 0.4595 - val_loss: 0.4971 - val_acc: 0.8277 - val_categorical_crossentropy: 0.4971\n",
            "Epoch 24/1000\n",
            "139839/139839 [==============================] - 12s 87us/step - loss: 0.4567 - acc: 0.8437 - categorical_crossentropy: 0.4567 - val_loss: 1.1436 - val_acc: 0.7120 - val_categorical_crossentropy: 1.1436\n",
            "Epoch 25/1000\n",
            "139839/139839 [==============================] - 12s 86us/step - loss: 0.4550 - acc: 0.8445 - categorical_crossentropy: 0.4550 - val_loss: 0.6568 - val_acc: 0.7547 - val_categorical_crossentropy: 0.6568\n",
            "Epoch 26/1000\n",
            "139839/139839 [==============================] - 12s 87us/step - loss: 0.4540 - acc: 0.8446 - categorical_crossentropy: 0.4540 - val_loss: 1.1970 - val_acc: 0.6574 - val_categorical_crossentropy: 1.1970\n",
            "Epoch 27/1000\n",
            "139839/139839 [==============================] - 12s 88us/step - loss: 0.4523 - acc: 0.8454 - categorical_crossentropy: 0.4523 - val_loss: 0.4434 - val_acc: 0.8458 - val_categorical_crossentropy: 0.4434\n",
            "Epoch 28/1000\n",
            "139839/139839 [==============================] - 12s 88us/step - loss: 0.4502 - acc: 0.8465 - categorical_crossentropy: 0.4502 - val_loss: 0.4749 - val_acc: 0.8411 - val_categorical_crossentropy: 0.4749\n",
            "Epoch 29/1000\n",
            "139839/139839 [==============================] - 12s 87us/step - loss: 0.4494 - acc: 0.8464 - categorical_crossentropy: 0.4494 - val_loss: 0.4257 - val_acc: 0.8514 - val_categorical_crossentropy: 0.4257\n",
            "Epoch 30/1000\n",
            "139839/139839 [==============================] - 12s 88us/step - loss: 0.4464 - acc: 0.8467 - categorical_crossentropy: 0.4464 - val_loss: 0.5280 - val_acc: 0.8323 - val_categorical_crossentropy: 0.5280\n",
            "Epoch 31/1000\n",
            "139839/139839 [==============================] - 12s 86us/step - loss: 0.4454 - acc: 0.8470 - categorical_crossentropy: 0.4454 - val_loss: 0.4644 - val_acc: 0.8380 - val_categorical_crossentropy: 0.4644\n",
            "Epoch 32/1000\n",
            "139839/139839 [==============================] - 12s 88us/step - loss: 0.4434 - acc: 0.8480 - categorical_crossentropy: 0.4434 - val_loss: 0.5001 - val_acc: 0.8231 - val_categorical_crossentropy: 0.5001\n",
            "Epoch 33/1000\n",
            "139839/139839 [==============================] - 13s 90us/step - loss: 0.4448 - acc: 0.8477 - categorical_crossentropy: 0.4448 - val_loss: 0.4290 - val_acc: 0.8512 - val_categorical_crossentropy: 0.4290\n",
            "Epoch 34/1000\n",
            "139839/139839 [==============================] - 12s 85us/step - loss: 0.4445 - acc: 0.8471 - categorical_crossentropy: 0.4445 - val_loss: 0.5135 - val_acc: 0.8223 - val_categorical_crossentropy: 0.5135\n",
            "Epoch 35/1000\n",
            "139839/139839 [==============================] - 12s 85us/step - loss: 0.4406 - acc: 0.8493 - categorical_crossentropy: 0.4406 - val_loss: 0.4545 - val_acc: 0.8367 - val_categorical_crossentropy: 0.4545\n",
            "Epoch 36/1000\n",
            "139839/139839 [==============================] - 12s 86us/step - loss: 0.4401 - acc: 0.8492 - categorical_crossentropy: 0.4401 - val_loss: 0.4477 - val_acc: 0.8355 - val_categorical_crossentropy: 0.4477\n",
            "Epoch 37/1000\n",
            "139839/139839 [==============================] - 12s 87us/step - loss: 0.4391 - acc: 0.8496 - categorical_crossentropy: 0.4391 - val_loss: 0.4098 - val_acc: 0.8550 - val_categorical_crossentropy: 0.4098\n",
            "Epoch 38/1000\n",
            "139839/139839 [==============================] - 13s 90us/step - loss: 0.4381 - acc: 0.8497 - categorical_crossentropy: 0.4381 - val_loss: 0.5333 - val_acc: 0.8059 - val_categorical_crossentropy: 0.5333\n",
            "Epoch 39/1000\n",
            "139839/139839 [==============================] - 13s 90us/step - loss: 0.4373 - acc: 0.8490 - categorical_crossentropy: 0.4373 - val_loss: 0.5059 - val_acc: 0.8152 - val_categorical_crossentropy: 0.5059\n",
            "Epoch 40/1000\n",
            "139839/139839 [==============================] - 12s 86us/step - loss: 0.4373 - acc: 0.8492 - categorical_crossentropy: 0.4373 - val_loss: 0.4244 - val_acc: 0.8467 - val_categorical_crossentropy: 0.4244\n",
            "Epoch 41/1000\n",
            "139839/139839 [==============================] - 12s 86us/step - loss: 0.4341 - acc: 0.8510 - categorical_crossentropy: 0.4341 - val_loss: 0.4873 - val_acc: 0.8237 - val_categorical_crossentropy: 0.4873\n",
            "Epoch 42/1000\n",
            "139839/139839 [==============================] - 12s 88us/step - loss: 0.4341 - acc: 0.8500 - categorical_crossentropy: 0.4341 - val_loss: 0.8219 - val_acc: 0.7713 - val_categorical_crossentropy: 0.8219\n",
            "Epoch 43/1000\n",
            "139839/139839 [==============================] - 12s 88us/step - loss: 0.4343 - acc: 0.8503 - categorical_crossentropy: 0.4343 - val_loss: 1.2102 - val_acc: 0.7152 - val_categorical_crossentropy: 1.2102\n",
            "Epoch 44/1000\n",
            "139839/139839 [==============================] - 12s 85us/step - loss: 0.4308 - acc: 0.8534 - categorical_crossentropy: 0.4308 - val_loss: 0.6376 - val_acc: 0.7831 - val_categorical_crossentropy: 0.6376\n",
            "Epoch 45/1000\n",
            "139839/139839 [==============================] - 12s 86us/step - loss: 0.4337 - acc: 0.8510 - categorical_crossentropy: 0.4337 - val_loss: 0.4526 - val_acc: 0.8365 - val_categorical_crossentropy: 0.4526\n",
            "Epoch 46/1000\n",
            "139839/139839 [==============================] - 12s 87us/step - loss: 0.4304 - acc: 0.8521 - categorical_crossentropy: 0.4304 - val_loss: 0.4343 - val_acc: 0.8464 - val_categorical_crossentropy: 0.4343\n",
            "Epoch 47/1000\n",
            "139839/139839 [==============================] - 12s 87us/step - loss: 0.4305 - acc: 0.8520 - categorical_crossentropy: 0.4305 - val_loss: 0.4141 - val_acc: 0.8550 - val_categorical_crossentropy: 0.4141\n",
            "Epoch 48/1000\n",
            "139839/139839 [==============================] - 12s 87us/step - loss: 0.4289 - acc: 0.8519 - categorical_crossentropy: 0.4289 - val_loss: 0.4664 - val_acc: 0.8380 - val_categorical_crossentropy: 0.4664\n",
            "Epoch 49/1000\n",
            "139839/139839 [==============================] - 12s 85us/step - loss: 0.4281 - acc: 0.8529 - categorical_crossentropy: 0.4281 - val_loss: 0.6692 - val_acc: 0.7772 - val_categorical_crossentropy: 0.6692\n",
            "Epoch 50/1000\n",
            "139839/139839 [==============================] - 12s 86us/step - loss: 0.4274 - acc: 0.8527 - categorical_crossentropy: 0.4274 - val_loss: 0.4249 - val_acc: 0.8494 - val_categorical_crossentropy: 0.4249\n",
            "Epoch 51/1000\n",
            "139839/139839 [==============================] - 12s 85us/step - loss: 0.4283 - acc: 0.8528 - categorical_crossentropy: 0.4283 - val_loss: 0.5067 - val_acc: 0.8322 - val_categorical_crossentropy: 0.5067\n",
            "Epoch 52/1000\n",
            "139839/139839 [==============================] - 12s 88us/step - loss: 0.4261 - acc: 0.8528 - categorical_crossentropy: 0.4261 - val_loss: 0.4171 - val_acc: 0.8556 - val_categorical_crossentropy: 0.4171\n",
            "Epoch 53/1000\n",
            "139839/139839 [==============================] - 12s 88us/step - loss: 0.4236 - acc: 0.8543 - categorical_crossentropy: 0.4236 - val_loss: 0.4497 - val_acc: 0.8413 - val_categorical_crossentropy: 0.4497\n",
            "Epoch 54/1000\n",
            "139839/139839 [==============================] - 12s 85us/step - loss: 0.4258 - acc: 0.8528 - categorical_crossentropy: 0.4258 - val_loss: 0.7396 - val_acc: 0.7442 - val_categorical_crossentropy: 0.7396\n",
            "Epoch 55/1000\n",
            "139839/139839 [==============================] - 12s 86us/step - loss: 0.4238 - acc: 0.8539 - categorical_crossentropy: 0.4238 - val_loss: 0.7403 - val_acc: 0.7660 - val_categorical_crossentropy: 0.7403\n",
            "Epoch 56/1000\n",
            "139839/139839 [==============================] - 12s 86us/step - loss: 0.4244 - acc: 0.8538 - categorical_crossentropy: 0.4244 - val_loss: 0.8472 - val_acc: 0.7041 - val_categorical_crossentropy: 0.8472\n",
            "Epoch 57/1000\n",
            "139839/139839 [==============================] - 12s 85us/step - loss: 0.4260 - acc: 0.8541 - categorical_crossentropy: 0.4260 - val_loss: 0.9530 - val_acc: 0.7618 - val_categorical_crossentropy: 0.9530\n",
            "Epoch 58/1000\n",
            "139839/139839 [==============================] - 12s 87us/step - loss: 0.4222 - acc: 0.8551 - categorical_crossentropy: 0.4222 - val_loss: 0.4806 - val_acc: 0.8250 - val_categorical_crossentropy: 0.4806\n",
            "Epoch 59/1000\n",
            "139839/139839 [==============================] - 12s 85us/step - loss: 0.4223 - acc: 0.8548 - categorical_crossentropy: 0.4223 - val_loss: 0.5733 - val_acc: 0.7869 - val_categorical_crossentropy: 0.5733\n",
            "Epoch 60/1000\n",
            "139839/139839 [==============================] - 12s 85us/step - loss: 0.4226 - acc: 0.8543 - categorical_crossentropy: 0.4226 - val_loss: 0.4311 - val_acc: 0.8457 - val_categorical_crossentropy: 0.4311\n",
            "Epoch 61/1000\n",
            "139839/139839 [==============================] - 12s 85us/step - loss: 0.4209 - acc: 0.8551 - categorical_crossentropy: 0.4209 - val_loss: 0.5091 - val_acc: 0.8184 - val_categorical_crossentropy: 0.5091\n",
            "Epoch 62/1000\n",
            "139839/139839 [==============================] - 12s 87us/step - loss: 0.4196 - acc: 0.8549 - categorical_crossentropy: 0.4196 - val_loss: 0.8964 - val_acc: 0.6829 - val_categorical_crossentropy: 0.8964\n",
            "Epoch 63/1000\n",
            "139839/139839 [==============================] - 12s 87us/step - loss: 0.4191 - acc: 0.8553 - categorical_crossentropy: 0.4191 - val_loss: 0.7264 - val_acc: 0.7702 - val_categorical_crossentropy: 0.7264\n",
            "Epoch 64/1000\n",
            "139839/139839 [==============================] - 12s 87us/step - loss: 0.4204 - acc: 0.8548 - categorical_crossentropy: 0.4204 - val_loss: 0.4014 - val_acc: 0.8597 - val_categorical_crossentropy: 0.4014\n",
            "Epoch 65/1000\n",
            "139839/139839 [==============================] - 12s 87us/step - loss: 0.4228 - acc: 0.8541 - categorical_crossentropy: 0.4228 - val_loss: 0.5024 - val_acc: 0.8156 - val_categorical_crossentropy: 0.5024\n",
            "Epoch 66/1000\n",
            "139839/139839 [==============================] - 12s 86us/step - loss: 0.4168 - acc: 0.8564 - categorical_crossentropy: 0.4168 - val_loss: 0.4694 - val_acc: 0.8272 - val_categorical_crossentropy: 0.4694\n",
            "Epoch 67/1000\n",
            "139839/139839 [==============================] - 12s 86us/step - loss: 0.4176 - acc: 0.8557 - categorical_crossentropy: 0.4176 - val_loss: 0.4235 - val_acc: 0.8508 - val_categorical_crossentropy: 0.4235\n",
            "Epoch 68/1000\n",
            "139839/139839 [==============================] - 12s 86us/step - loss: 0.4179 - acc: 0.8560 - categorical_crossentropy: 0.4179 - val_loss: 0.5557 - val_acc: 0.8004 - val_categorical_crossentropy: 0.5557\n",
            "Epoch 69/1000\n",
            "139839/139839 [==============================] - 12s 85us/step - loss: 0.4173 - acc: 0.8557 - categorical_crossentropy: 0.4173 - val_loss: 0.5651 - val_acc: 0.8000 - val_categorical_crossentropy: 0.5651\n",
            "Epoch 70/1000\n",
            "139839/139839 [==============================] - 12s 86us/step - loss: 0.4170 - acc: 0.8561 - categorical_crossentropy: 0.4170 - val_loss: 0.4589 - val_acc: 0.8414 - val_categorical_crossentropy: 0.4589\n",
            "Epoch 71/1000\n",
            "139839/139839 [==============================] - 12s 85us/step - loss: 0.4167 - acc: 0.8558 - categorical_crossentropy: 0.4167 - val_loss: 0.4814 - val_acc: 0.8213 - val_categorical_crossentropy: 0.4814\n",
            "Epoch 72/1000\n",
            "139839/139839 [==============================] - 12s 86us/step - loss: 0.4149 - acc: 0.8569 - categorical_crossentropy: 0.4149 - val_loss: 0.4553 - val_acc: 0.8364 - val_categorical_crossentropy: 0.4553\n",
            "Epoch 73/1000\n",
            "139839/139839 [==============================] - 12s 88us/step - loss: 0.4159 - acc: 0.8562 - categorical_crossentropy: 0.4159 - val_loss: 1.3484 - val_acc: 0.6218 - val_categorical_crossentropy: 1.3484\n",
            "Epoch 74/1000\n",
            "139839/139839 [==============================] - 12s 85us/step - loss: 0.4144 - acc: 0.8568 - categorical_crossentropy: 0.4144 - val_loss: 0.4150 - val_acc: 0.8557 - val_categorical_crossentropy: 0.4150\n",
            "Epoch 75/1000\n",
            "139839/139839 [==============================] - 12s 85us/step - loss: 0.4156 - acc: 0.8564 - categorical_crossentropy: 0.4156 - val_loss: 0.4497 - val_acc: 0.8368 - val_categorical_crossentropy: 0.4497\n",
            "Epoch 76/1000\n",
            "139839/139839 [==============================] - 12s 86us/step - loss: 0.4144 - acc: 0.8568 - categorical_crossentropy: 0.4144 - val_loss: 0.3923 - val_acc: 0.8619 - val_categorical_crossentropy: 0.3923\n",
            "Epoch 77/1000\n",
            "139839/139839 [==============================] - 12s 87us/step - loss: 0.4146 - acc: 0.8574 - categorical_crossentropy: 0.4146 - val_loss: 0.7077 - val_acc: 0.7362 - val_categorical_crossentropy: 0.7077\n",
            "Epoch 78/1000\n",
            "139839/139839 [==============================] - 12s 87us/step - loss: 0.4128 - acc: 0.8574 - categorical_crossentropy: 0.4128 - val_loss: 1.0387 - val_acc: 0.6902 - val_categorical_crossentropy: 1.0387\n",
            "Epoch 79/1000\n",
            "139839/139839 [==============================] - 12s 86us/step - loss: 0.4150 - acc: 0.8570 - categorical_crossentropy: 0.4150 - val_loss: 0.5064 - val_acc: 0.8269 - val_categorical_crossentropy: 0.5064\n",
            "Epoch 80/1000\n",
            "139839/139839 [==============================] - 12s 87us/step - loss: 0.4108 - acc: 0.8585 - categorical_crossentropy: 0.4108 - val_loss: 0.4720 - val_acc: 0.8383 - val_categorical_crossentropy: 0.4720\n",
            "Epoch 81/1000\n",
            "139839/139839 [==============================] - 12s 85us/step - loss: 0.4096 - acc: 0.8582 - categorical_crossentropy: 0.4096 - val_loss: 0.3865 - val_acc: 0.8656 - val_categorical_crossentropy: 0.3865\n",
            "Epoch 82/1000\n",
            "139839/139839 [==============================] - 12s 88us/step - loss: 0.4102 - acc: 0.8572 - categorical_crossentropy: 0.4102 - val_loss: 0.4498 - val_acc: 0.8430 - val_categorical_crossentropy: 0.4498\n",
            "Epoch 83/1000\n",
            "139839/139839 [==============================] - 12s 86us/step - loss: 0.4116 - acc: 0.8574 - categorical_crossentropy: 0.4116 - val_loss: 0.4708 - val_acc: 0.8363 - val_categorical_crossentropy: 0.4708\n",
            "Epoch 84/1000\n",
            "139839/139839 [==============================] - 12s 85us/step - loss: 0.4071 - acc: 0.8601 - categorical_crossentropy: 0.4071 - val_loss: 0.4820 - val_acc: 0.8248 - val_categorical_crossentropy: 0.4820\n",
            "Epoch 85/1000\n",
            "139839/139839 [==============================] - 12s 86us/step - loss: 0.4098 - acc: 0.8580 - categorical_crossentropy: 0.4098 - val_loss: 0.4384 - val_acc: 0.8377 - val_categorical_crossentropy: 0.4384\n",
            "Epoch 86/1000\n",
            "139839/139839 [==============================] - 12s 86us/step - loss: 0.4080 - acc: 0.8586 - categorical_crossentropy: 0.4080 - val_loss: 0.5645 - val_acc: 0.7848 - val_categorical_crossentropy: 0.5645\n",
            "Epoch 87/1000\n",
            "139839/139839 [==============================] - 12s 88us/step - loss: 0.4110 - acc: 0.8587 - categorical_crossentropy: 0.4110 - val_loss: 0.7090 - val_acc: 0.7892 - val_categorical_crossentropy: 0.7090\n",
            "Epoch 88/1000\n",
            "139839/139839 [==============================] - 12s 86us/step - loss: 0.4091 - acc: 0.8584 - categorical_crossentropy: 0.4091 - val_loss: 0.4216 - val_acc: 0.8486 - val_categorical_crossentropy: 0.4216\n",
            "Epoch 89/1000\n",
            "139839/139839 [==============================] - 12s 84us/step - loss: 0.4068 - acc: 0.8596 - categorical_crossentropy: 0.4068 - val_loss: 0.4333 - val_acc: 0.8508 - val_categorical_crossentropy: 0.4333\n",
            "Epoch 90/1000\n",
            "139839/139839 [==============================] - 12s 88us/step - loss: 0.4103 - acc: 0.8586 - categorical_crossentropy: 0.4103 - val_loss: 0.6028 - val_acc: 0.7842 - val_categorical_crossentropy: 0.6028\n",
            "Epoch 91/1000\n",
            "139839/139839 [==============================] - 12s 87us/step - loss: 0.4098 - acc: 0.8579 - categorical_crossentropy: 0.4098 - val_loss: 0.8374 - val_acc: 0.7668 - val_categorical_crossentropy: 0.8374\n",
            "Epoch 92/1000\n",
            "139839/139839 [==============================] - 12s 88us/step - loss: 0.4083 - acc: 0.8586 - categorical_crossentropy: 0.4083 - val_loss: 0.4758 - val_acc: 0.8295 - val_categorical_crossentropy: 0.4758\n",
            "Epoch 93/1000\n",
            "139839/139839 [==============================] - 12s 85us/step - loss: 0.4070 - acc: 0.8586 - categorical_crossentropy: 0.4070 - val_loss: 0.7481 - val_acc: 0.7454 - val_categorical_crossentropy: 0.7481\n",
            "Epoch 94/1000\n",
            "139839/139839 [==============================] - 12s 85us/step - loss: 0.4071 - acc: 0.8586 - categorical_crossentropy: 0.4071 - val_loss: 0.3990 - val_acc: 0.8607 - val_categorical_crossentropy: 0.3990\n",
            "Epoch 95/1000\n",
            "139839/139839 [==============================] - 12s 84us/step - loss: 0.4055 - acc: 0.8598 - categorical_crossentropy: 0.4055 - val_loss: 0.5596 - val_acc: 0.8076 - val_categorical_crossentropy: 0.5596\n",
            "Epoch 96/1000\n",
            "139839/139839 [==============================] - 12s 85us/step - loss: 0.4053 - acc: 0.8598 - categorical_crossentropy: 0.4053 - val_loss: 0.4478 - val_acc: 0.8462 - val_categorical_crossentropy: 0.4478\n",
            "Epoch 97/1000\n",
            "139839/139839 [==============================] - 12s 88us/step - loss: 0.4051 - acc: 0.8593 - categorical_crossentropy: 0.4051 - val_loss: 0.5646 - val_acc: 0.8054 - val_categorical_crossentropy: 0.5646\n",
            "Epoch 98/1000\n",
            "139839/139839 [==============================] - 12s 85us/step - loss: 0.4061 - acc: 0.8595 - categorical_crossentropy: 0.4061 - val_loss: 0.6717 - val_acc: 0.7764 - val_categorical_crossentropy: 0.6717\n",
            "Epoch 99/1000\n",
            "139839/139839 [==============================] - 12s 85us/step - loss: 0.4043 - acc: 0.8604 - categorical_crossentropy: 0.4043 - val_loss: 0.3967 - val_acc: 0.8625 - val_categorical_crossentropy: 0.3967\n",
            "Epoch 100/1000\n",
            "139839/139839 [==============================] - 12s 85us/step - loss: 0.4020 - acc: 0.8610 - categorical_crossentropy: 0.4020 - val_loss: 0.3972 - val_acc: 0.8611 - val_categorical_crossentropy: 0.3972\n",
            "Epoch 101/1000\n",
            "139839/139839 [==============================] - 12s 85us/step - loss: 0.4058 - acc: 0.8581 - categorical_crossentropy: 0.4058 - val_loss: 0.3875 - val_acc: 0.8636 - val_categorical_crossentropy: 0.3875\n",
            "Epoch 102/1000\n",
            "139839/139839 [==============================] - 12s 86us/step - loss: 0.4058 - acc: 0.8592 - categorical_crossentropy: 0.4058 - val_loss: 0.5782 - val_acc: 0.8207 - val_categorical_crossentropy: 0.5782\n",
            "Epoch 103/1000\n",
            "139839/139839 [==============================] - 12s 86us/step - loss: 0.4036 - acc: 0.8599 - categorical_crossentropy: 0.4036 - val_loss: 0.8347 - val_acc: 0.7585 - val_categorical_crossentropy: 0.8347\n",
            "Epoch 104/1000\n",
            "139839/139839 [==============================] - 12s 84us/step - loss: 0.4041 - acc: 0.8600 - categorical_crossentropy: 0.4041 - val_loss: 0.4855 - val_acc: 0.8296 - val_categorical_crossentropy: 0.4855\n",
            "Epoch 105/1000\n",
            "139839/139839 [==============================] - 12s 86us/step - loss: 0.4035 - acc: 0.8608 - categorical_crossentropy: 0.4035 - val_loss: 0.4588 - val_acc: 0.8306 - val_categorical_crossentropy: 0.4588\n",
            "Epoch 106/1000\n",
            "139839/139839 [==============================] - 12s 85us/step - loss: 0.4033 - acc: 0.8606 - categorical_crossentropy: 0.4033 - val_loss: 0.4636 - val_acc: 0.8405 - val_categorical_crossentropy: 0.4636\n",
            "Epoch 107/1000\n",
            "139839/139839 [==============================] - 12s 86us/step - loss: 0.4024 - acc: 0.8606 - categorical_crossentropy: 0.4024 - val_loss: 0.3964 - val_acc: 0.8624 - val_categorical_crossentropy: 0.3964\n",
            "Epoch 108/1000\n",
            "139839/139839 [==============================] - 12s 86us/step - loss: 0.4025 - acc: 0.8612 - categorical_crossentropy: 0.4025 - val_loss: 0.3953 - val_acc: 0.8635 - val_categorical_crossentropy: 0.3953\n",
            "Epoch 109/1000\n",
            "139839/139839 [==============================] - 12s 84us/step - loss: 0.4032 - acc: 0.8595 - categorical_crossentropy: 0.4032 - val_loss: 0.4340 - val_acc: 0.8465 - val_categorical_crossentropy: 0.4340\n",
            "Epoch 110/1000\n",
            "139839/139839 [==============================] - 12s 84us/step - loss: 0.4018 - acc: 0.8606 - categorical_crossentropy: 0.4018 - val_loss: 0.4688 - val_acc: 0.8303 - val_categorical_crossentropy: 0.4688\n",
            "Epoch 111/1000\n",
            "139839/139839 [==============================] - 12s 84us/step - loss: 0.4017 - acc: 0.8604 - categorical_crossentropy: 0.4017 - val_loss: 0.4740 - val_acc: 0.8320 - val_categorical_crossentropy: 0.4740\n",
            "Epoch 112/1000\n",
            "139839/139839 [==============================] - 12s 87us/step - loss: 0.4017 - acc: 0.8606 - categorical_crossentropy: 0.4017 - val_loss: 0.4571 - val_acc: 0.8401 - val_categorical_crossentropy: 0.4571\n",
            "Epoch 113/1000\n",
            "139839/139839 [==============================] - 12s 87us/step - loss: 0.4010 - acc: 0.8607 - categorical_crossentropy: 0.4010 - val_loss: 1.1465 - val_acc: 0.7559 - val_categorical_crossentropy: 1.1465\n",
            "Epoch 114/1000\n",
            "139839/139839 [==============================] - 12s 85us/step - loss: 0.4031 - acc: 0.8590 - categorical_crossentropy: 0.4031 - val_loss: 0.5770 - val_acc: 0.7894 - val_categorical_crossentropy: 0.5770\n",
            "Epoch 115/1000\n",
            "139839/139839 [==============================] - 12s 84us/step - loss: 0.4006 - acc: 0.8611 - categorical_crossentropy: 0.4006 - val_loss: 0.5520 - val_acc: 0.8167 - val_categorical_crossentropy: 0.5520\n",
            "Epoch 116/1000\n",
            "139839/139839 [==============================] - 13s 90us/step - loss: 0.3999 - acc: 0.8614 - categorical_crossentropy: 0.3999 - val_loss: 0.3860 - val_acc: 0.8663 - val_categorical_crossentropy: 0.3860\n",
            "Epoch 117/1000\n",
            "139839/139839 [==============================] - 13s 90us/step - loss: 0.4015 - acc: 0.8601 - categorical_crossentropy: 0.4015 - val_loss: 0.4000 - val_acc: 0.8614 - val_categorical_crossentropy: 0.4000\n",
            "Epoch 118/1000\n",
            "139839/139839 [==============================] - 12s 86us/step - loss: 0.4000 - acc: 0.8617 - categorical_crossentropy: 0.4000 - val_loss: 0.4016 - val_acc: 0.8608 - val_categorical_crossentropy: 0.4016\n",
            "Epoch 119/1000\n",
            "139839/139839 [==============================] - 12s 85us/step - loss: 0.4011 - acc: 0.8604 - categorical_crossentropy: 0.4011 - val_loss: 0.4258 - val_acc: 0.8518 - val_categorical_crossentropy: 0.4258\n",
            "Epoch 120/1000\n",
            "139839/139839 [==============================] - 12s 86us/step - loss: 0.4001 - acc: 0.8611 - categorical_crossentropy: 0.4001 - val_loss: 0.3886 - val_acc: 0.8647 - val_categorical_crossentropy: 0.3886\n",
            "Epoch 121/1000\n",
            "139839/139839 [==============================] - 12s 86us/step - loss: 0.4003 - acc: 0.8602 - categorical_crossentropy: 0.4003 - val_loss: 0.7470 - val_acc: 0.7770 - val_categorical_crossentropy: 0.7470\n",
            "Epoch 122/1000\n",
            "139839/139839 [==============================] - 13s 91us/step - loss: 0.3996 - acc: 0.8610 - categorical_crossentropy: 0.3996 - val_loss: 0.5273 - val_acc: 0.8270 - val_categorical_crossentropy: 0.5273\n",
            "Epoch 123/1000\n",
            "139839/139839 [==============================] - 12s 87us/step - loss: 0.4011 - acc: 0.8602 - categorical_crossentropy: 0.4011 - val_loss: 0.3972 - val_acc: 0.8634 - val_categorical_crossentropy: 0.3972\n",
            "Epoch 124/1000\n",
            "139839/139839 [==============================] - 12s 86us/step - loss: 0.4000 - acc: 0.8616 - categorical_crossentropy: 0.4000 - val_loss: 0.4059 - val_acc: 0.8583 - val_categorical_crossentropy: 0.4059\n",
            "Epoch 125/1000\n",
            "139839/139839 [==============================] - 12s 87us/step - loss: 0.3980 - acc: 0.8613 - categorical_crossentropy: 0.3980 - val_loss: 0.5291 - val_acc: 0.8103 - val_categorical_crossentropy: 0.5291\n",
            "Epoch 126/1000\n",
            "139839/139839 [==============================] - 12s 89us/step - loss: 0.3975 - acc: 0.8624 - categorical_crossentropy: 0.3975 - val_loss: 0.6995 - val_acc: 0.8061 - val_categorical_crossentropy: 0.6995\n",
            "Epoch 127/1000\n",
            "139839/139839 [==============================] - 12s 89us/step - loss: 0.3989 - acc: 0.8615 - categorical_crossentropy: 0.3989 - val_loss: 0.6826 - val_acc: 0.7852 - val_categorical_crossentropy: 0.6826\n",
            "Epoch 128/1000\n",
            "139839/139839 [==============================] - 12s 85us/step - loss: 0.3979 - acc: 0.8612 - categorical_crossentropy: 0.3979 - val_loss: 0.4370 - val_acc: 0.8534 - val_categorical_crossentropy: 0.4370\n",
            "Epoch 129/1000\n",
            "139839/139839 [==============================] - 12s 83us/step - loss: 0.3971 - acc: 0.8620 - categorical_crossentropy: 0.3971 - val_loss: 0.4423 - val_acc: 0.8485 - val_categorical_crossentropy: 0.4423\n",
            "Epoch 130/1000\n",
            "139839/139839 [==============================] - 12s 84us/step - loss: 0.3988 - acc: 0.8620 - categorical_crossentropy: 0.3988 - val_loss: 0.4421 - val_acc: 0.8435 - val_categorical_crossentropy: 0.4421\n",
            "Epoch 131/1000\n",
            "139839/139839 [==============================] - 12s 84us/step - loss: 0.3981 - acc: 0.8618 - categorical_crossentropy: 0.3981 - val_loss: 0.4179 - val_acc: 0.8539 - val_categorical_crossentropy: 0.4179\n",
            "Epoch 132/1000\n",
            "139839/139839 [==============================] - 12s 86us/step - loss: 0.3999 - acc: 0.8616 - categorical_crossentropy: 0.3999 - val_loss: 0.4297 - val_acc: 0.8452 - val_categorical_crossentropy: 0.4297\n",
            "Epoch 133/1000\n",
            "139839/139839 [==============================] - 12s 86us/step - loss: 0.3990 - acc: 0.8616 - categorical_crossentropy: 0.3990 - val_loss: 0.4234 - val_acc: 0.8560 - val_categorical_crossentropy: 0.4234\n",
            "Epoch 134/1000\n",
            "139839/139839 [==============================] - 12s 84us/step - loss: 0.3953 - acc: 0.8633 - categorical_crossentropy: 0.3953 - val_loss: 0.3750 - val_acc: 0.8692 - val_categorical_crossentropy: 0.3750\n",
            "Epoch 135/1000\n",
            "139839/139839 [==============================] - 12s 85us/step - loss: 0.3971 - acc: 0.8633 - categorical_crossentropy: 0.3971 - val_loss: 0.3890 - val_acc: 0.8665 - val_categorical_crossentropy: 0.3890\n",
            "Epoch 136/1000\n",
            "139839/139839 [==============================] - 12s 86us/step - loss: 0.3974 - acc: 0.8626 - categorical_crossentropy: 0.3974 - val_loss: 0.4721 - val_acc: 0.8275 - val_categorical_crossentropy: 0.4721\n",
            "Epoch 137/1000\n",
            "139839/139839 [==============================] - 12s 85us/step - loss: 0.3969 - acc: 0.8623 - categorical_crossentropy: 0.3969 - val_loss: 0.7097 - val_acc: 0.7493 - val_categorical_crossentropy: 0.7097\n",
            "Epoch 138/1000\n",
            "139839/139839 [==============================] - 12s 83us/step - loss: 0.3959 - acc: 0.8632 - categorical_crossentropy: 0.3959 - val_loss: 0.4414 - val_acc: 0.8438 - val_categorical_crossentropy: 0.4414\n",
            "Epoch 139/1000\n",
            "139839/139839 [==============================] - 12s 85us/step - loss: 0.3962 - acc: 0.8634 - categorical_crossentropy: 0.3962 - val_loss: 0.4666 - val_acc: 0.8354 - val_categorical_crossentropy: 0.4666\n",
            "Epoch 140/1000\n",
            "139839/139839 [==============================] - 12s 84us/step - loss: 0.3955 - acc: 0.8622 - categorical_crossentropy: 0.3955 - val_loss: 0.9347 - val_acc: 0.7420 - val_categorical_crossentropy: 0.9347\n",
            "Epoch 141/1000\n",
            "139839/139839 [==============================] - 12s 86us/step - loss: 0.3937 - acc: 0.8635 - categorical_crossentropy: 0.3937 - val_loss: 0.4039 - val_acc: 0.8562 - val_categorical_crossentropy: 0.4039\n",
            "Epoch 142/1000\n",
            "139839/139839 [==============================] - 13s 91us/step - loss: 0.3949 - acc: 0.8630 - categorical_crossentropy: 0.3949 - val_loss: 0.6060 - val_acc: 0.8017 - val_categorical_crossentropy: 0.6060\n",
            "Epoch 143/1000\n",
            "139839/139839 [==============================] - 12s 84us/step - loss: 0.3956 - acc: 0.8628 - categorical_crossentropy: 0.3956 - val_loss: 0.4381 - val_acc: 0.8447 - val_categorical_crossentropy: 0.4381\n",
            "Epoch 144/1000\n",
            "139839/139839 [==============================] - 12s 84us/step - loss: 0.3963 - acc: 0.8629 - categorical_crossentropy: 0.3963 - val_loss: 0.4130 - val_acc: 0.8565 - val_categorical_crossentropy: 0.4130\n",
            "Epoch 145/1000\n",
            "139839/139839 [==============================] - 12s 86us/step - loss: 0.3944 - acc: 0.8633 - categorical_crossentropy: 0.3944 - val_loss: 0.4365 - val_acc: 0.8463 - val_categorical_crossentropy: 0.4365\n",
            "Epoch 146/1000\n",
            "139839/139839 [==============================] - 12s 87us/step - loss: 0.3947 - acc: 0.8632 - categorical_crossentropy: 0.3947 - val_loss: 0.4443 - val_acc: 0.8500 - val_categorical_crossentropy: 0.4443\n",
            "Epoch 147/1000\n",
            "139839/139839 [==============================] - 12s 88us/step - loss: 0.3930 - acc: 0.8632 - categorical_crossentropy: 0.3930 - val_loss: 0.3852 - val_acc: 0.8647 - val_categorical_crossentropy: 0.3852\n",
            "Epoch 148/1000\n",
            "139839/139839 [==============================] - 12s 84us/step - loss: 0.3943 - acc: 0.8630 - categorical_crossentropy: 0.3943 - val_loss: 0.4223 - val_acc: 0.8584 - val_categorical_crossentropy: 0.4223\n",
            "Epoch 149/1000\n",
            "139839/139839 [==============================] - 12s 83us/step - loss: 0.3923 - acc: 0.8635 - categorical_crossentropy: 0.3923 - val_loss: 0.4342 - val_acc: 0.8490 - val_categorical_crossentropy: 0.4342\n",
            "Epoch 150/1000\n",
            "139839/139839 [==============================] - 12s 85us/step - loss: 0.3937 - acc: 0.8645 - categorical_crossentropy: 0.3937 - val_loss: 0.5603 - val_acc: 0.7998 - val_categorical_crossentropy: 0.5603\n",
            "Epoch 151/1000\n",
            "139839/139839 [==============================] - 12s 85us/step - loss: 0.3940 - acc: 0.8629 - categorical_crossentropy: 0.3940 - val_loss: 0.5033 - val_acc: 0.8286 - val_categorical_crossentropy: 0.5033\n",
            "Epoch 152/1000\n",
            "139839/139839 [==============================] - 12s 86us/step - loss: 0.3944 - acc: 0.8632 - categorical_crossentropy: 0.3944 - val_loss: 0.4631 - val_acc: 0.8443 - val_categorical_crossentropy: 0.4631\n",
            "Epoch 153/1000\n",
            "139839/139839 [==============================] - 12s 85us/step - loss: 0.3935 - acc: 0.8636 - categorical_crossentropy: 0.3935 - val_loss: 0.4293 - val_acc: 0.8509 - val_categorical_crossentropy: 0.4293\n",
            "Epoch 154/1000\n",
            "139839/139839 [==============================] - 12s 83us/step - loss: 0.3943 - acc: 0.8627 - categorical_crossentropy: 0.3943 - val_loss: 0.5424 - val_acc: 0.7967 - val_categorical_crossentropy: 0.5424\n",
            "Epoch 155/1000\n",
            "139839/139839 [==============================] - 12s 84us/step - loss: 0.3934 - acc: 0.8641 - categorical_crossentropy: 0.3934 - val_loss: 0.4075 - val_acc: 0.8576 - val_categorical_crossentropy: 0.4075\n",
            "Epoch 156/1000\n",
            "139839/139839 [==============================] - 12s 85us/step - loss: 0.3914 - acc: 0.8638 - categorical_crossentropy: 0.3914 - val_loss: 0.4366 - val_acc: 0.8483 - val_categorical_crossentropy: 0.4366\n",
            "Epoch 157/1000\n",
            "139839/139839 [==============================] - 12s 84us/step - loss: 0.3923 - acc: 0.8641 - categorical_crossentropy: 0.3923 - val_loss: 0.7112 - val_acc: 0.7770 - val_categorical_crossentropy: 0.7112\n",
            "Epoch 158/1000\n",
            "139839/139839 [==============================] - 12s 84us/step - loss: 0.3923 - acc: 0.8632 - categorical_crossentropy: 0.3923 - val_loss: 0.4455 - val_acc: 0.8397 - val_categorical_crossentropy: 0.4455\n",
            "Epoch 159/1000\n",
            "139839/139839 [==============================] - 12s 85us/step - loss: 0.3915 - acc: 0.8640 - categorical_crossentropy: 0.3915 - val_loss: 0.4340 - val_acc: 0.8477 - val_categorical_crossentropy: 0.4340\n",
            "Epoch 160/1000\n",
            "139839/139839 [==============================] - 12s 84us/step - loss: 0.3921 - acc: 0.8637 - categorical_crossentropy: 0.3921 - val_loss: 0.4367 - val_acc: 0.8499 - val_categorical_crossentropy: 0.4367\n",
            "Epoch 161/1000\n",
            "139839/139839 [==============================] - 12s 84us/step - loss: 0.3904 - acc: 0.8651 - categorical_crossentropy: 0.3904 - val_loss: 0.3645 - val_acc: 0.8730 - val_categorical_crossentropy: 0.3645\n",
            "Epoch 162/1000\n",
            "139839/139839 [==============================] - 12s 86us/step - loss: 0.3911 - acc: 0.8641 - categorical_crossentropy: 0.3911 - val_loss: 0.5371 - val_acc: 0.8155 - val_categorical_crossentropy: 0.5371\n",
            "Epoch 163/1000\n",
            "139839/139839 [==============================] - 12s 85us/step - loss: 0.3928 - acc: 0.8624 - categorical_crossentropy: 0.3928 - val_loss: 0.3870 - val_acc: 0.8649 - val_categorical_crossentropy: 0.3870\n",
            "Epoch 164/1000\n",
            "139839/139839 [==============================] - 12s 83us/step - loss: 0.3912 - acc: 0.8639 - categorical_crossentropy: 0.3912 - val_loss: 0.4367 - val_acc: 0.8490 - val_categorical_crossentropy: 0.4367\n",
            "Epoch 165/1000\n",
            "139839/139839 [==============================] - 12s 84us/step - loss: 0.3919 - acc: 0.8640 - categorical_crossentropy: 0.3919 - val_loss: 0.3794 - val_acc: 0.8683 - val_categorical_crossentropy: 0.3794\n",
            "Epoch 166/1000\n",
            "139839/139839 [==============================] - 12s 85us/step - loss: 0.3911 - acc: 0.8641 - categorical_crossentropy: 0.3911 - val_loss: 0.3926 - val_acc: 0.8642 - val_categorical_crossentropy: 0.3926\n",
            "Epoch 167/1000\n",
            "139839/139839 [==============================] - 12s 85us/step - loss: 0.3917 - acc: 0.8634 - categorical_crossentropy: 0.3917 - val_loss: 0.4169 - val_acc: 0.8510 - val_categorical_crossentropy: 0.4169\n",
            "Epoch 168/1000\n",
            "139839/139839 [==============================] - 12s 88us/step - loss: 0.3914 - acc: 0.8637 - categorical_crossentropy: 0.3914 - val_loss: 0.3760 - val_acc: 0.8721 - val_categorical_crossentropy: 0.3760\n",
            "Epoch 169/1000\n",
            "139839/139839 [==============================] - 12s 83us/step - loss: 0.3930 - acc: 0.8630 - categorical_crossentropy: 0.3930 - val_loss: 0.4031 - val_acc: 0.8614 - val_categorical_crossentropy: 0.4031\n",
            "Epoch 170/1000\n",
            "139839/139839 [==============================] - 12s 83us/step - loss: 0.3910 - acc: 0.8647 - categorical_crossentropy: 0.3910 - val_loss: 0.3868 - val_acc: 0.8668 - val_categorical_crossentropy: 0.3868\n",
            "Epoch 171/1000\n",
            "139839/139839 [==============================] - 12s 84us/step - loss: 0.3907 - acc: 0.8639 - categorical_crossentropy: 0.3907 - val_loss: 0.3844 - val_acc: 0.8677 - val_categorical_crossentropy: 0.3844\n",
            "Epoch 172/1000\n",
            "139839/139839 [==============================] - 12s 86us/step - loss: 0.3910 - acc: 0.8641 - categorical_crossentropy: 0.3910 - val_loss: 0.6464 - val_acc: 0.7910 - val_categorical_crossentropy: 0.6464\n",
            "Epoch 173/1000\n",
            "139839/139839 [==============================] - 12s 87us/step - loss: 0.3895 - acc: 0.8648 - categorical_crossentropy: 0.3895 - val_loss: 0.4584 - val_acc: 0.8394 - val_categorical_crossentropy: 0.4584\n",
            "Epoch 174/1000\n",
            "139839/139839 [==============================] - 11s 82us/step - loss: 0.3886 - acc: 0.8652 - categorical_crossentropy: 0.3886 - val_loss: 0.4242 - val_acc: 0.8512 - val_categorical_crossentropy: 0.4242\n",
            "Epoch 175/1000\n",
            "139839/139839 [==============================] - 12s 86us/step - loss: 0.3906 - acc: 0.8633 - categorical_crossentropy: 0.3906 - val_loss: 0.4008 - val_acc: 0.8600 - val_categorical_crossentropy: 0.4008\n",
            "Epoch 176/1000\n",
            "139839/139839 [==============================] - 12s 86us/step - loss: 0.3903 - acc: 0.8641 - categorical_crossentropy: 0.3903 - val_loss: 0.3844 - val_acc: 0.8658 - val_categorical_crossentropy: 0.3844\n",
            "Epoch 177/1000\n",
            "139839/139839 [==============================] - 12s 88us/step - loss: 0.3881 - acc: 0.8654 - categorical_crossentropy: 0.3881 - val_loss: 0.4461 - val_acc: 0.8463 - val_categorical_crossentropy: 0.4461\n",
            "Epoch 178/1000\n",
            "139839/139839 [==============================] - 12s 88us/step - loss: 0.3905 - acc: 0.8649 - categorical_crossentropy: 0.3905 - val_loss: 0.3967 - val_acc: 0.8624 - val_categorical_crossentropy: 0.3967\n",
            "Epoch 179/1000\n",
            "139839/139839 [==============================] - 12s 86us/step - loss: 0.3905 - acc: 0.8635 - categorical_crossentropy: 0.3905 - val_loss: 0.5088 - val_acc: 0.8170 - val_categorical_crossentropy: 0.5088\n",
            "Epoch 180/1000\n",
            "139839/139839 [==============================] - 12s 89us/step - loss: 0.3901 - acc: 0.8642 - categorical_crossentropy: 0.3901 - val_loss: 0.4079 - val_acc: 0.8546 - val_categorical_crossentropy: 0.4079\n",
            "Epoch 181/1000\n",
            "139839/139839 [==============================] - 12s 89us/step - loss: 0.3893 - acc: 0.8646 - categorical_crossentropy: 0.3893 - val_loss: 0.5608 - val_acc: 0.8209 - val_categorical_crossentropy: 0.5608\n",
            "Epoch 182/1000\n",
            "139839/139839 [==============================] - 13s 92us/step - loss: 0.3883 - acc: 0.8644 - categorical_crossentropy: 0.3883 - val_loss: 0.4250 - val_acc: 0.8537 - val_categorical_crossentropy: 0.4250\n",
            "Epoch 183/1000\n",
            "139839/139839 [==============================] - 13s 92us/step - loss: 0.3874 - acc: 0.8652 - categorical_crossentropy: 0.3874 - val_loss: 0.6235 - val_acc: 0.7693 - val_categorical_crossentropy: 0.6235\n",
            "Epoch 184/1000\n",
            "139839/139839 [==============================] - 13s 90us/step - loss: 0.3866 - acc: 0.8652 - categorical_crossentropy: 0.3866 - val_loss: 0.5247 - val_acc: 0.8167 - val_categorical_crossentropy: 0.5247\n",
            "Epoch 185/1000\n",
            "139839/139839 [==============================] - 12s 87us/step - loss: 0.3894 - acc: 0.8649 - categorical_crossentropy: 0.3894 - val_loss: 0.3926 - val_acc: 0.8635 - val_categorical_crossentropy: 0.3926\n",
            "Epoch 186/1000\n",
            "139839/139839 [==============================] - 12s 88us/step - loss: 0.3874 - acc: 0.8650 - categorical_crossentropy: 0.3874 - val_loss: 0.3877 - val_acc: 0.8670 - val_categorical_crossentropy: 0.3877\n",
            "Epoch 187/1000\n",
            "139839/139839 [==============================] - 12s 85us/step - loss: 0.3885 - acc: 0.8651 - categorical_crossentropy: 0.3885 - val_loss: 0.4001 - val_acc: 0.8619 - val_categorical_crossentropy: 0.4001\n",
            "Epoch 188/1000\n",
            "139839/139839 [==============================] - 12s 84us/step - loss: 0.3885 - acc: 0.8643 - categorical_crossentropy: 0.3885 - val_loss: 0.3807 - val_acc: 0.8692 - val_categorical_crossentropy: 0.3807\n",
            "Epoch 189/1000\n",
            "139839/139839 [==============================] - 12s 84us/step - loss: 0.3889 - acc: 0.8649 - categorical_crossentropy: 0.3889 - val_loss: 0.3793 - val_acc: 0.8661 - val_categorical_crossentropy: 0.3793\n",
            "Epoch 190/1000\n",
            "139839/139839 [==============================] - 12s 84us/step - loss: 0.3898 - acc: 0.8643 - categorical_crossentropy: 0.3898 - val_loss: 0.4933 - val_acc: 0.8237 - val_categorical_crossentropy: 0.4933\n",
            "Epoch 191/1000\n",
            "139839/139839 [==============================] - 12s 85us/step - loss: 0.3875 - acc: 0.8654 - categorical_crossentropy: 0.3875 - val_loss: 1.4105 - val_acc: 0.6533 - val_categorical_crossentropy: 1.4105\n",
            "Epoch 192/1000\n",
            "139839/139839 [==============================] - 12s 86us/step - loss: 0.3883 - acc: 0.8651 - categorical_crossentropy: 0.3883 - val_loss: 0.3806 - val_acc: 0.8683 - val_categorical_crossentropy: 0.3806\n",
            "Epoch 193/1000\n",
            "139839/139839 [==============================] - 12s 87us/step - loss: 0.3867 - acc: 0.8653 - categorical_crossentropy: 0.3867 - val_loss: 0.5696 - val_acc: 0.8151 - val_categorical_crossentropy: 0.5696\n",
            "Epoch 194/1000\n",
            "139839/139839 [==============================] - 12s 84us/step - loss: 0.3859 - acc: 0.8651 - categorical_crossentropy: 0.3859 - val_loss: 0.4065 - val_acc: 0.8585 - val_categorical_crossentropy: 0.4065\n",
            "Epoch 195/1000\n",
            "139839/139839 [==============================] - 12s 84us/step - loss: 0.3885 - acc: 0.8645 - categorical_crossentropy: 0.3885 - val_loss: 0.4216 - val_acc: 0.8535 - val_categorical_crossentropy: 0.4216\n",
            "Epoch 196/1000\n",
            "139839/139839 [==============================] - 12s 85us/step - loss: 0.3877 - acc: 0.8652 - categorical_crossentropy: 0.3877 - val_loss: 0.4049 - val_acc: 0.8632 - val_categorical_crossentropy: 0.4049\n",
            "Epoch 197/1000\n",
            "139839/139839 [==============================] - 12s 87us/step - loss: 0.3866 - acc: 0.8653 - categorical_crossentropy: 0.3866 - val_loss: 0.3716 - val_acc: 0.8723 - val_categorical_crossentropy: 0.3716\n",
            "Epoch 198/1000\n",
            "139839/139839 [==============================] - 12s 85us/step - loss: 0.3854 - acc: 0.8663 - categorical_crossentropy: 0.3854 - val_loss: 0.3822 - val_acc: 0.8697 - val_categorical_crossentropy: 0.3822\n",
            "Epoch 199/1000\n",
            "139839/139839 [==============================] - 12s 85us/step - loss: 0.3860 - acc: 0.8663 - categorical_crossentropy: 0.3860 - val_loss: 0.3805 - val_acc: 0.8683 - val_categorical_crossentropy: 0.3805\n",
            "Epoch 200/1000\n",
            "139839/139839 [==============================] - 12s 85us/step - loss: 0.3868 - acc: 0.8653 - categorical_crossentropy: 0.3868 - val_loss: 0.3783 - val_acc: 0.8697 - val_categorical_crossentropy: 0.3783\n",
            "Epoch 201/1000\n",
            "139839/139839 [==============================] - 12s 85us/step - loss: 0.3861 - acc: 0.8655 - categorical_crossentropy: 0.3861 - val_loss: 0.3971 - val_acc: 0.8606 - val_categorical_crossentropy: 0.3971\n",
            "Epoch 202/1000\n",
            "139839/139839 [==============================] - 12s 86us/step - loss: 0.3865 - acc: 0.8655 - categorical_crossentropy: 0.3865 - val_loss: 0.3631 - val_acc: 0.8738 - val_categorical_crossentropy: 0.3631\n",
            "Epoch 203/1000\n",
            "139839/139839 [==============================] - 12s 86us/step - loss: 0.3857 - acc: 0.8657 - categorical_crossentropy: 0.3857 - val_loss: 0.4548 - val_acc: 0.8390 - val_categorical_crossentropy: 0.4548\n",
            "Epoch 204/1000\n",
            "139839/139839 [==============================] - 12s 83us/step - loss: 0.3855 - acc: 0.8666 - categorical_crossentropy: 0.3855 - val_loss: 0.3975 - val_acc: 0.8615 - val_categorical_crossentropy: 0.3975\n",
            "Epoch 205/1000\n",
            "139839/139839 [==============================] - 12s 84us/step - loss: 0.3868 - acc: 0.8655 - categorical_crossentropy: 0.3868 - val_loss: 0.3845 - val_acc: 0.8668 - val_categorical_crossentropy: 0.3845\n",
            "Epoch 206/1000\n",
            "139839/139839 [==============================] - 12s 86us/step - loss: 0.3862 - acc: 0.8658 - categorical_crossentropy: 0.3862 - val_loss: 0.4367 - val_acc: 0.8442 - val_categorical_crossentropy: 0.4367\n",
            "Epoch 207/1000\n",
            "139839/139839 [==============================] - 12s 87us/step - loss: 0.3854 - acc: 0.8660 - categorical_crossentropy: 0.3854 - val_loss: 0.5308 - val_acc: 0.8221 - val_categorical_crossentropy: 0.5308\n",
            "Epoch 208/1000\n",
            "139839/139839 [==============================] - 12s 85us/step - loss: 0.3840 - acc: 0.8666 - categorical_crossentropy: 0.3840 - val_loss: 0.3867 - val_acc: 0.8673 - val_categorical_crossentropy: 0.3867\n",
            "Epoch 209/1000\n",
            "139839/139839 [==============================] - 12s 84us/step - loss: 0.3861 - acc: 0.8648 - categorical_crossentropy: 0.3861 - val_loss: 0.3823 - val_acc: 0.8666 - val_categorical_crossentropy: 0.3823\n",
            "Epoch 210/1000\n",
            "139839/139839 [==============================] - 12s 85us/step - loss: 0.3854 - acc: 0.8665 - categorical_crossentropy: 0.3854 - val_loss: 0.5065 - val_acc: 0.8335 - val_categorical_crossentropy: 0.5065\n",
            "Epoch 211/1000\n",
            "139839/139839 [==============================] - 12s 85us/step - loss: 0.3861 - acc: 0.8649 - categorical_crossentropy: 0.3861 - val_loss: 0.3631 - val_acc: 0.8745 - val_categorical_crossentropy: 0.3631\n",
            "Epoch 212/1000\n",
            "139839/139839 [==============================] - 12s 85us/step - loss: 0.3856 - acc: 0.8655 - categorical_crossentropy: 0.3856 - val_loss: 0.3982 - val_acc: 0.8635 - val_categorical_crossentropy: 0.3982\n",
            "Epoch 213/1000\n",
            "139839/139839 [==============================] - 12s 89us/step - loss: 0.3857 - acc: 0.8662 - categorical_crossentropy: 0.3857 - val_loss: 0.4250 - val_acc: 0.8483 - val_categorical_crossentropy: 0.4250\n",
            "Epoch 214/1000\n",
            "139839/139839 [==============================] - 12s 85us/step - loss: 0.3837 - acc: 0.8660 - categorical_crossentropy: 0.3837 - val_loss: 0.4242 - val_acc: 0.8511 - val_categorical_crossentropy: 0.4242\n",
            "Epoch 215/1000\n",
            "139839/139839 [==============================] - 12s 89us/step - loss: 0.3846 - acc: 0.8664 - categorical_crossentropy: 0.3846 - val_loss: 0.4024 - val_acc: 0.8605 - val_categorical_crossentropy: 0.4024\n",
            "Epoch 216/1000\n",
            "139839/139839 [==============================] - 12s 88us/step - loss: 0.3830 - acc: 0.8667 - categorical_crossentropy: 0.3830 - val_loss: 0.3772 - val_acc: 0.8675 - val_categorical_crossentropy: 0.3772\n",
            "Epoch 217/1000\n",
            "139839/139839 [==============================] - 12s 85us/step - loss: 0.3839 - acc: 0.8655 - categorical_crossentropy: 0.3839 - val_loss: 0.3965 - val_acc: 0.8617 - val_categorical_crossentropy: 0.3965\n",
            "Epoch 218/1000\n",
            "139839/139839 [==============================] - 13s 90us/step - loss: 0.3852 - acc: 0.8662 - categorical_crossentropy: 0.3852 - val_loss: 0.6054 - val_acc: 0.7857 - val_categorical_crossentropy: 0.6054\n",
            "Epoch 219/1000\n",
            "139839/139839 [==============================] - 13s 89us/step - loss: 0.3843 - acc: 0.8660 - categorical_crossentropy: 0.3843 - val_loss: 0.5598 - val_acc: 0.8220 - val_categorical_crossentropy: 0.5598\n",
            "Epoch 220/1000\n",
            "139839/139839 [==============================] - 12s 88us/step - loss: 0.3834 - acc: 0.8672 - categorical_crossentropy: 0.3834 - val_loss: 0.3708 - val_acc: 0.8726 - val_categorical_crossentropy: 0.3708\n",
            "Epoch 221/1000\n",
            "139839/139839 [==============================] - 12s 86us/step - loss: 0.3845 - acc: 0.8662 - categorical_crossentropy: 0.3845 - val_loss: 0.3983 - val_acc: 0.8590 - val_categorical_crossentropy: 0.3983\n",
            "Epoch 222/1000\n",
            "139839/139839 [==============================] - 12s 86us/step - loss: 0.3837 - acc: 0.8669 - categorical_crossentropy: 0.3837 - val_loss: 0.4999 - val_acc: 0.8247 - val_categorical_crossentropy: 0.4999\n",
            "Epoch 223/1000\n",
            "139839/139839 [==============================] - 12s 87us/step - loss: 0.3829 - acc: 0.8659 - categorical_crossentropy: 0.3829 - val_loss: 0.4554 - val_acc: 0.8450 - val_categorical_crossentropy: 0.4554\n",
            "Epoch 224/1000\n",
            "139839/139839 [==============================] - 12s 85us/step - loss: 0.3842 - acc: 0.8660 - categorical_crossentropy: 0.3842 - val_loss: 0.5471 - val_acc: 0.8151 - val_categorical_crossentropy: 0.5471\n",
            "Epoch 225/1000\n",
            "139839/139839 [==============================] - 12s 86us/step - loss: 0.3834 - acc: 0.8667 - categorical_crossentropy: 0.3834 - val_loss: 0.3736 - val_acc: 0.8715 - val_categorical_crossentropy: 0.3736\n",
            "Epoch 226/1000\n",
            "139839/139839 [==============================] - 12s 89us/step - loss: 0.3841 - acc: 0.8666 - categorical_crossentropy: 0.3841 - val_loss: 0.3812 - val_acc: 0.8656 - val_categorical_crossentropy: 0.3812\n",
            "Epoch 227/1000\n",
            "139839/139839 [==============================] - 12s 86us/step - loss: 0.3845 - acc: 0.8665 - categorical_crossentropy: 0.3845 - val_loss: 0.3699 - val_acc: 0.8736 - val_categorical_crossentropy: 0.3699\n",
            "Epoch 228/1000\n",
            "139839/139839 [==============================] - 12s 86us/step - loss: 0.3831 - acc: 0.8660 - categorical_crossentropy: 0.3831 - val_loss: 0.3852 - val_acc: 0.8683 - val_categorical_crossentropy: 0.3852\n",
            "Epoch 229/1000\n",
            "139839/139839 [==============================] - 12s 84us/step - loss: 0.3838 - acc: 0.8661 - categorical_crossentropy: 0.3838 - val_loss: 0.5413 - val_acc: 0.8278 - val_categorical_crossentropy: 0.5413\n",
            "Epoch 230/1000\n",
            "139839/139839 [==============================] - 12s 85us/step - loss: 0.3811 - acc: 0.8672 - categorical_crossentropy: 0.3811 - val_loss: 0.4473 - val_acc: 0.8508 - val_categorical_crossentropy: 0.4473\n",
            "Epoch 231/1000\n",
            "139839/139839 [==============================] - 12s 86us/step - loss: 0.3826 - acc: 0.8670 - categorical_crossentropy: 0.3826 - val_loss: 0.4436 - val_acc: 0.8415 - val_categorical_crossentropy: 0.4436\n",
            "Epoch 232/1000\n",
            "139839/139839 [==============================] - 12s 87us/step - loss: 0.3824 - acc: 0.8662 - categorical_crossentropy: 0.3824 - val_loss: 0.4041 - val_acc: 0.8610 - val_categorical_crossentropy: 0.4041\n",
            "Epoch 233/1000\n",
            "139839/139839 [==============================] - 12s 88us/step - loss: 0.3819 - acc: 0.8669 - categorical_crossentropy: 0.3819 - val_loss: 0.3804 - val_acc: 0.8700 - val_categorical_crossentropy: 0.3804\n",
            "Epoch 234/1000\n",
            "139839/139839 [==============================] - 12s 84us/step - loss: 0.3823 - acc: 0.8675 - categorical_crossentropy: 0.3823 - val_loss: 0.3751 - val_acc: 0.8704 - val_categorical_crossentropy: 0.3751\n",
            "Epoch 235/1000\n",
            "139839/139839 [==============================] - 12s 85us/step - loss: 0.3821 - acc: 0.8670 - categorical_crossentropy: 0.3821 - val_loss: 0.4010 - val_acc: 0.8604 - val_categorical_crossentropy: 0.4010\n",
            "Epoch 236/1000\n",
            "139839/139839 [==============================] - 12s 86us/step - loss: 0.3819 - acc: 0.8671 - categorical_crossentropy: 0.3819 - val_loss: 0.4809 - val_acc: 0.8266 - val_categorical_crossentropy: 0.4809\n",
            "Epoch 237/1000\n",
            "139839/139839 [==============================] - 12s 85us/step - loss: 0.3826 - acc: 0.8665 - categorical_crossentropy: 0.3826 - val_loss: 0.3705 - val_acc: 0.8707 - val_categorical_crossentropy: 0.3705\n",
            "Epoch 238/1000\n",
            "139839/139839 [==============================] - 12s 86us/step - loss: 0.3826 - acc: 0.8669 - categorical_crossentropy: 0.3826 - val_loss: 0.4372 - val_acc: 0.8458 - val_categorical_crossentropy: 0.4372\n",
            "Epoch 239/1000\n",
            "139839/139839 [==============================] - 12s 85us/step - loss: 0.3802 - acc: 0.8681 - categorical_crossentropy: 0.3802 - val_loss: 0.3974 - val_acc: 0.8603 - val_categorical_crossentropy: 0.3974\n",
            "Epoch 240/1000\n",
            "139839/139839 [==============================] - 12s 87us/step - loss: 0.3829 - acc: 0.8671 - categorical_crossentropy: 0.3829 - val_loss: 0.4173 - val_acc: 0.8559 - val_categorical_crossentropy: 0.4173\n",
            "Epoch 241/1000\n",
            "139839/139839 [==============================] - 12s 86us/step - loss: 0.3812 - acc: 0.8675 - categorical_crossentropy: 0.3812 - val_loss: 0.4450 - val_acc: 0.8522 - val_categorical_crossentropy: 0.4450\n",
            "Epoch 242/1000\n",
            "139839/139839 [==============================] - 12s 86us/step - loss: 0.3808 - acc: 0.8673 - categorical_crossentropy: 0.3808 - val_loss: 0.4031 - val_acc: 0.8605 - val_categorical_crossentropy: 0.4031\n",
            "Epoch 243/1000\n",
            "139839/139839 [==============================] - 12s 87us/step - loss: 0.3805 - acc: 0.8669 - categorical_crossentropy: 0.3805 - val_loss: 0.4646 - val_acc: 0.8450 - val_categorical_crossentropy: 0.4646\n",
            "Epoch 244/1000\n",
            "139839/139839 [==============================] - 12s 84us/step - loss: 0.3820 - acc: 0.8667 - categorical_crossentropy: 0.3820 - val_loss: 0.3902 - val_acc: 0.8648 - val_categorical_crossentropy: 0.3902\n",
            "Epoch 245/1000\n",
            "139839/139839 [==============================] - 12s 88us/step - loss: 0.3822 - acc: 0.8668 - categorical_crossentropy: 0.3822 - val_loss: 0.4125 - val_acc: 0.8579 - val_categorical_crossentropy: 0.4125\n",
            "Epoch 246/1000\n",
            "139839/139839 [==============================] - 12s 87us/step - loss: 0.3803 - acc: 0.8667 - categorical_crossentropy: 0.3803 - val_loss: 0.5588 - val_acc: 0.8222 - val_categorical_crossentropy: 0.5588\n",
            "Epoch 247/1000\n",
            "139839/139839 [==============================] - 12s 86us/step - loss: 0.3813 - acc: 0.8669 - categorical_crossentropy: 0.3813 - val_loss: 0.3910 - val_acc: 0.8637 - val_categorical_crossentropy: 0.3910\n",
            "Epoch 248/1000\n",
            "139839/139839 [==============================] - 12s 84us/step - loss: 0.3816 - acc: 0.8675 - categorical_crossentropy: 0.3816 - val_loss: 0.3947 - val_acc: 0.8622 - val_categorical_crossentropy: 0.3947\n",
            "Epoch 249/1000\n",
            "139839/139839 [==============================] - 12s 85us/step - loss: 0.3805 - acc: 0.8668 - categorical_crossentropy: 0.3805 - val_loss: 0.4006 - val_acc: 0.8608 - val_categorical_crossentropy: 0.4006\n",
            "Epoch 250/1000\n",
            "139839/139839 [==============================] - 12s 86us/step - loss: 0.3812 - acc: 0.8666 - categorical_crossentropy: 0.3812 - val_loss: 0.3732 - val_acc: 0.8702 - val_categorical_crossentropy: 0.3732\n",
            "Epoch 251/1000\n",
            "139839/139839 [==============================] - 13s 90us/step - loss: 0.3816 - acc: 0.8672 - categorical_crossentropy: 0.3816 - val_loss: 0.5494 - val_acc: 0.8037 - val_categorical_crossentropy: 0.5494\n",
            "Epoch 252/1000\n",
            "139839/139839 [==============================] - 12s 88us/step - loss: 0.3815 - acc: 0.8670 - categorical_crossentropy: 0.3815 - val_loss: 0.3620 - val_acc: 0.8746 - val_categorical_crossentropy: 0.3620\n",
            "Epoch 253/1000\n",
            "139839/139839 [==============================] - 12s 89us/step - loss: 0.3797 - acc: 0.8678 - categorical_crossentropy: 0.3797 - val_loss: 0.4383 - val_acc: 0.8486 - val_categorical_crossentropy: 0.4383\n",
            "Epoch 254/1000\n",
            "139839/139839 [==============================] - 12s 86us/step - loss: 0.3800 - acc: 0.8672 - categorical_crossentropy: 0.3800 - val_loss: 0.5557 - val_acc: 0.8319 - val_categorical_crossentropy: 0.5557\n",
            "Epoch 255/1000\n",
            "139839/139839 [==============================] - 12s 86us/step - loss: 0.3807 - acc: 0.8672 - categorical_crossentropy: 0.3807 - val_loss: 0.3691 - val_acc: 0.8720 - val_categorical_crossentropy: 0.3691\n",
            "Epoch 256/1000\n",
            "139839/139839 [==============================] - 12s 86us/step - loss: 0.3798 - acc: 0.8674 - categorical_crossentropy: 0.3798 - val_loss: 0.3666 - val_acc: 0.8745 - val_categorical_crossentropy: 0.3666\n",
            "Epoch 257/1000\n",
            "139839/139839 [==============================] - 12s 88us/step - loss: 0.3793 - acc: 0.8677 - categorical_crossentropy: 0.3793 - val_loss: 0.3787 - val_acc: 0.8684 - val_categorical_crossentropy: 0.3787\n",
            "Epoch 258/1000\n",
            "139839/139839 [==============================] - 12s 88us/step - loss: 0.3803 - acc: 0.8681 - categorical_crossentropy: 0.3803 - val_loss: 1.8380 - val_acc: 0.6908 - val_categorical_crossentropy: 1.8380\n",
            "Epoch 259/1000\n",
            "139839/139839 [==============================] - 12s 86us/step - loss: 0.3812 - acc: 0.8668 - categorical_crossentropy: 0.3812 - val_loss: 0.3860 - val_acc: 0.8684 - val_categorical_crossentropy: 0.3860\n",
            "Epoch 260/1000\n",
            "139839/139839 [==============================] - 12s 86us/step - loss: 0.3803 - acc: 0.8679 - categorical_crossentropy: 0.3803 - val_loss: 0.3658 - val_acc: 0.8733 - val_categorical_crossentropy: 0.3658\n",
            "Epoch 261/1000\n",
            "139839/139839 [==============================] - 12s 86us/step - loss: 0.3786 - acc: 0.8673 - categorical_crossentropy: 0.3786 - val_loss: 0.3790 - val_acc: 0.8718 - val_categorical_crossentropy: 0.3790\n",
            "Epoch 262/1000\n",
            "139839/139839 [==============================] - 12s 87us/step - loss: 0.3803 - acc: 0.8673 - categorical_crossentropy: 0.3803 - val_loss: 0.3923 - val_acc: 0.8655 - val_categorical_crossentropy: 0.3923\n",
            "Epoch 263/1000\n",
            "139839/139839 [==============================] - 12s 88us/step - loss: 0.3810 - acc: 0.8669 - categorical_crossentropy: 0.3810 - val_loss: 0.3975 - val_acc: 0.8629 - val_categorical_crossentropy: 0.3975\n",
            "Epoch 264/1000\n",
            "139839/139839 [==============================] - 12s 85us/step - loss: 0.3798 - acc: 0.8676 - categorical_crossentropy: 0.3798 - val_loss: 0.3775 - val_acc: 0.8672 - val_categorical_crossentropy: 0.3775\n",
            "Epoch 265/1000\n",
            "139839/139839 [==============================] - 12s 86us/step - loss: 0.3801 - acc: 0.8677 - categorical_crossentropy: 0.3801 - val_loss: 0.3756 - val_acc: 0.8704 - val_categorical_crossentropy: 0.3756\n",
            "Epoch 266/1000\n",
            "139839/139839 [==============================] - 12s 87us/step - loss: 0.3800 - acc: 0.8665 - categorical_crossentropy: 0.3800 - val_loss: 0.4059 - val_acc: 0.8581 - val_categorical_crossentropy: 0.4059\n",
            "Epoch 267/1000\n",
            "139839/139839 [==============================] - 12s 86us/step - loss: 0.3797 - acc: 0.8682 - categorical_crossentropy: 0.3797 - val_loss: 0.4924 - val_acc: 0.8250 - val_categorical_crossentropy: 0.4924\n",
            "Epoch 268/1000\n",
            "139839/139839 [==============================] - 12s 88us/step - loss: 0.3790 - acc: 0.8680 - categorical_crossentropy: 0.3790 - val_loss: 0.4065 - val_acc: 0.8572 - val_categorical_crossentropy: 0.4065\n",
            "Epoch 269/1000\n",
            "139839/139839 [==============================] - 12s 86us/step - loss: 0.3785 - acc: 0.8682 - categorical_crossentropy: 0.3785 - val_loss: 0.3793 - val_acc: 0.8671 - val_categorical_crossentropy: 0.3793\n",
            "Epoch 270/1000\n",
            "139839/139839 [==============================] - 12s 89us/step - loss: 0.3796 - acc: 0.8680 - categorical_crossentropy: 0.3796 - val_loss: 0.5296 - val_acc: 0.8329 - val_categorical_crossentropy: 0.5296\n",
            "Epoch 271/1000\n",
            "139839/139839 [==============================] - 13s 90us/step - loss: 0.3784 - acc: 0.8677 - categorical_crossentropy: 0.3784 - val_loss: 0.3891 - val_acc: 0.8648 - val_categorical_crossentropy: 0.3891\n",
            "Epoch 272/1000\n",
            "139839/139839 [==============================] - 13s 90us/step - loss: 0.3791 - acc: 0.8669 - categorical_crossentropy: 0.3791 - val_loss: 0.3774 - val_acc: 0.8700 - val_categorical_crossentropy: 0.3774\n",
            "Epoch 273/1000\n",
            "139839/139839 [==============================] - 13s 90us/step - loss: 0.3793 - acc: 0.8669 - categorical_crossentropy: 0.3793 - val_loss: 0.4226 - val_acc: 0.8589 - val_categorical_crossentropy: 0.4226\n",
            "Epoch 274/1000\n",
            "139839/139839 [==============================] - 12s 87us/step - loss: 0.3784 - acc: 0.8674 - categorical_crossentropy: 0.3784 - val_loss: 0.3940 - val_acc: 0.8640 - val_categorical_crossentropy: 0.3940\n",
            "Epoch 275/1000\n",
            "139839/139839 [==============================] - 12s 88us/step - loss: 0.3794 - acc: 0.8667 - categorical_crossentropy: 0.3794 - val_loss: 0.4670 - val_acc: 0.8246 - val_categorical_crossentropy: 0.4670\n",
            "Epoch 276/1000\n",
            "139839/139839 [==============================] - 12s 88us/step - loss: 0.3810 - acc: 0.8668 - categorical_crossentropy: 0.3810 - val_loss: 0.3831 - val_acc: 0.8664 - val_categorical_crossentropy: 0.3831\n",
            "Epoch 277/1000\n",
            "139839/139839 [==============================] - 13s 90us/step - loss: 0.3797 - acc: 0.8677 - categorical_crossentropy: 0.3797 - val_loss: 0.3638 - val_acc: 0.8725 - val_categorical_crossentropy: 0.3638\n",
            "Epoch 278/1000\n",
            "139839/139839 [==============================] - 12s 88us/step - loss: 0.3797 - acc: 0.8676 - categorical_crossentropy: 0.3797 - val_loss: 0.3757 - val_acc: 0.8704 - val_categorical_crossentropy: 0.3757\n",
            "Epoch 279/1000\n",
            "139839/139839 [==============================] - 12s 88us/step - loss: 0.3778 - acc: 0.8685 - categorical_crossentropy: 0.3778 - val_loss: 0.5038 - val_acc: 0.8181 - val_categorical_crossentropy: 0.5038\n",
            "Epoch 280/1000\n",
            "139839/139839 [==============================] - 12s 88us/step - loss: 0.3773 - acc: 0.8679 - categorical_crossentropy: 0.3773 - val_loss: 0.3994 - val_acc: 0.8621 - val_categorical_crossentropy: 0.3994\n",
            "Epoch 281/1000\n",
            "139839/139839 [==============================] - 12s 87us/step - loss: 0.3790 - acc: 0.8677 - categorical_crossentropy: 0.3790 - val_loss: 0.5498 - val_acc: 0.8312 - val_categorical_crossentropy: 0.5498\n",
            "Epoch 282/1000\n",
            "139839/139839 [==============================] - 13s 90us/step - loss: 0.3797 - acc: 0.8670 - categorical_crossentropy: 0.3797 - val_loss: 0.5618 - val_acc: 0.8167 - val_categorical_crossentropy: 0.5618\n",
            "Epoch 283/1000\n",
            "139839/139839 [==============================] - 12s 87us/step - loss: 0.3786 - acc: 0.8684 - categorical_crossentropy: 0.3786 - val_loss: 0.3813 - val_acc: 0.8685 - val_categorical_crossentropy: 0.3813\n",
            "Epoch 284/1000\n",
            "139839/139839 [==============================] - 12s 88us/step - loss: 0.3793 - acc: 0.8675 - categorical_crossentropy: 0.3793 - val_loss: 0.3824 - val_acc: 0.8639 - val_categorical_crossentropy: 0.3824\n",
            "Epoch 285/1000\n",
            "139839/139839 [==============================] - 13s 90us/step - loss: 0.3774 - acc: 0.8685 - categorical_crossentropy: 0.3774 - val_loss: 0.4190 - val_acc: 0.8525 - val_categorical_crossentropy: 0.4190\n",
            "Epoch 286/1000\n",
            "139839/139839 [==============================] - 13s 89us/step - loss: 0.3776 - acc: 0.8687 - categorical_crossentropy: 0.3776 - val_loss: 0.3835 - val_acc: 0.8688 - val_categorical_crossentropy: 0.3835\n",
            "Epoch 287/1000\n",
            "139839/139839 [==============================] - 13s 92us/step - loss: 0.3771 - acc: 0.8682 - categorical_crossentropy: 0.3771 - val_loss: 0.3633 - val_acc: 0.8757 - val_categorical_crossentropy: 0.3633\n",
            "Epoch 288/1000\n",
            "139839/139839 [==============================] - 13s 91us/step - loss: 0.3789 - acc: 0.8677 - categorical_crossentropy: 0.3789 - val_loss: 0.3762 - val_acc: 0.8710 - val_categorical_crossentropy: 0.3762\n",
            "Epoch 289/1000\n",
            "139839/139839 [==============================] - 12s 89us/step - loss: 0.3783 - acc: 0.8677 - categorical_crossentropy: 0.3783 - val_loss: 0.3881 - val_acc: 0.8657 - val_categorical_crossentropy: 0.3881\n",
            "Epoch 290/1000\n",
            "139839/139839 [==============================] - 12s 88us/step - loss: 0.3777 - acc: 0.8683 - categorical_crossentropy: 0.3777 - val_loss: 0.3630 - val_acc: 0.8735 - val_categorical_crossentropy: 0.3630\n",
            "Epoch 291/1000\n",
            "139839/139839 [==============================] - 12s 88us/step - loss: 0.3784 - acc: 0.8680 - categorical_crossentropy: 0.3784 - val_loss: 0.3856 - val_acc: 0.8676 - val_categorical_crossentropy: 0.3856\n",
            "Epoch 292/1000\n",
            "139839/139839 [==============================] - 12s 89us/step - loss: 0.3764 - acc: 0.8684 - categorical_crossentropy: 0.3764 - val_loss: 0.3696 - val_acc: 0.8701 - val_categorical_crossentropy: 0.3696\n",
            "Epoch 293/1000\n",
            "139839/139839 [==============================] - 12s 87us/step - loss: 0.3776 - acc: 0.8674 - categorical_crossentropy: 0.3776 - val_loss: 0.3894 - val_acc: 0.8667 - val_categorical_crossentropy: 0.3894\n",
            "Epoch 294/1000\n",
            "139839/139839 [==============================] - 12s 86us/step - loss: 0.3766 - acc: 0.8690 - categorical_crossentropy: 0.3766 - val_loss: 0.5051 - val_acc: 0.8439 - val_categorical_crossentropy: 0.5051\n",
            "Epoch 295/1000\n",
            "139839/139839 [==============================] - 12s 88us/step - loss: 0.3772 - acc: 0.8684 - categorical_crossentropy: 0.3772 - val_loss: 0.3779 - val_acc: 0.8698 - val_categorical_crossentropy: 0.3779\n",
            "Epoch 296/1000\n",
            "139839/139839 [==============================] - 12s 89us/step - loss: 0.3757 - acc: 0.8694 - categorical_crossentropy: 0.3757 - val_loss: 0.3602 - val_acc: 0.8741 - val_categorical_crossentropy: 0.3602\n",
            "Epoch 297/1000\n",
            "139839/139839 [==============================] - 12s 88us/step - loss: 0.3765 - acc: 0.8682 - categorical_crossentropy: 0.3765 - val_loss: 0.4111 - val_acc: 0.8581 - val_categorical_crossentropy: 0.4111\n",
            "Epoch 298/1000\n",
            "139839/139839 [==============================] - 12s 87us/step - loss: 0.3763 - acc: 0.8685 - categorical_crossentropy: 0.3763 - val_loss: 0.3915 - val_acc: 0.8629 - val_categorical_crossentropy: 0.3915\n",
            "Epoch 299/1000\n",
            "139839/139839 [==============================] - 12s 88us/step - loss: 0.3767 - acc: 0.8687 - categorical_crossentropy: 0.3767 - val_loss: 0.7230 - val_acc: 0.8000 - val_categorical_crossentropy: 0.7230\n",
            "Epoch 300/1000\n",
            "139839/139839 [==============================] - 12s 86us/step - loss: 0.3750 - acc: 0.8684 - categorical_crossentropy: 0.3750 - val_loss: 0.3768 - val_acc: 0.8693 - val_categorical_crossentropy: 0.3768\n",
            "Epoch 301/1000\n",
            "139839/139839 [==============================] - 12s 87us/step - loss: 0.3773 - acc: 0.8684 - categorical_crossentropy: 0.3773 - val_loss: 0.3843 - val_acc: 0.8666 - val_categorical_crossentropy: 0.3843\n",
            "Epoch 302/1000\n",
            "139839/139839 [==============================] - 12s 86us/step - loss: 0.3778 - acc: 0.8674 - categorical_crossentropy: 0.3778 - val_loss: 0.3662 - val_acc: 0.8745 - val_categorical_crossentropy: 0.3662\n",
            "Epoch 303/1000\n",
            "139839/139839 [==============================] - 12s 87us/step - loss: 0.3776 - acc: 0.8682 - categorical_crossentropy: 0.3776 - val_loss: 0.3908 - val_acc: 0.8663 - val_categorical_crossentropy: 0.3908\n",
            "Epoch 304/1000\n",
            "139839/139839 [==============================] - 12s 86us/step - loss: 0.3762 - acc: 0.8684 - categorical_crossentropy: 0.3762 - val_loss: 0.3775 - val_acc: 0.8698 - val_categorical_crossentropy: 0.3775\n",
            "Epoch 305/1000\n",
            "139839/139839 [==============================] - 12s 87us/step - loss: 0.3760 - acc: 0.8688 - categorical_crossentropy: 0.3760 - val_loss: 0.3999 - val_acc: 0.8574 - val_categorical_crossentropy: 0.3999\n",
            "Epoch 306/1000\n",
            "139839/139839 [==============================] - 12s 86us/step - loss: 0.3776 - acc: 0.8676 - categorical_crossentropy: 0.3776 - val_loss: 0.4272 - val_acc: 0.8466 - val_categorical_crossentropy: 0.4272\n",
            "Epoch 307/1000\n",
            "139839/139839 [==============================] - 12s 88us/step - loss: 0.3764 - acc: 0.8678 - categorical_crossentropy: 0.3764 - val_loss: 0.3771 - val_acc: 0.8686 - val_categorical_crossentropy: 0.3771\n",
            "Epoch 308/1000\n",
            "139839/139839 [==============================] - 12s 89us/step - loss: 0.3770 - acc: 0.8684 - categorical_crossentropy: 0.3770 - val_loss: 0.3694 - val_acc: 0.8713 - val_categorical_crossentropy: 0.3694\n",
            "Epoch 309/1000\n",
            "139839/139839 [==============================] - 12s 88us/step - loss: 0.3771 - acc: 0.8686 - categorical_crossentropy: 0.3771 - val_loss: 0.3716 - val_acc: 0.8709 - val_categorical_crossentropy: 0.3716\n",
            "Epoch 310/1000\n",
            "139839/139839 [==============================] - 12s 89us/step - loss: 0.3760 - acc: 0.8677 - categorical_crossentropy: 0.3760 - val_loss: 0.3990 - val_acc: 0.8628 - val_categorical_crossentropy: 0.3990\n",
            "Epoch 311/1000\n",
            "139839/139839 [==============================] - 13s 93us/step - loss: 0.3759 - acc: 0.8689 - categorical_crossentropy: 0.3759 - val_loss: 0.3687 - val_acc: 0.8740 - val_categorical_crossentropy: 0.3687\n",
            "Epoch 312/1000\n",
            "139839/139839 [==============================] - 12s 88us/step - loss: 0.3771 - acc: 0.8681 - categorical_crossentropy: 0.3771 - val_loss: 0.3640 - val_acc: 0.8765 - val_categorical_crossentropy: 0.3640\n",
            "Epoch 313/1000\n",
            "139839/139839 [==============================] - 12s 86us/step - loss: 0.3749 - acc: 0.8687 - categorical_crossentropy: 0.3749 - val_loss: 0.3668 - val_acc: 0.8739 - val_categorical_crossentropy: 0.3668\n",
            "Epoch 314/1000\n",
            "139839/139839 [==============================] - 12s 86us/step - loss: 0.3754 - acc: 0.8690 - categorical_crossentropy: 0.3754 - val_loss: 0.3816 - val_acc: 0.8664 - val_categorical_crossentropy: 0.3816\n",
            "Epoch 315/1000\n",
            "139839/139839 [==============================] - 12s 87us/step - loss: 0.3757 - acc: 0.8685 - categorical_crossentropy: 0.3757 - val_loss: 0.3800 - val_acc: 0.8687 - val_categorical_crossentropy: 0.3800\n",
            "Epoch 316/1000\n",
            "139839/139839 [==============================] - 12s 88us/step - loss: 0.3762 - acc: 0.8680 - categorical_crossentropy: 0.3762 - val_loss: 0.4014 - val_acc: 0.8601 - val_categorical_crossentropy: 0.4014\n",
            "Epoch 317/1000\n",
            "139839/139839 [==============================] - 12s 86us/step - loss: 0.3758 - acc: 0.8689 - categorical_crossentropy: 0.3758 - val_loss: 0.3961 - val_acc: 0.8644 - val_categorical_crossentropy: 0.3961\n",
            "Epoch 318/1000\n",
            "139839/139839 [==============================] - 12s 88us/step - loss: 0.3778 - acc: 0.8678 - categorical_crossentropy: 0.3778 - val_loss: 0.3794 - val_acc: 0.8685 - val_categorical_crossentropy: 0.3794\n",
            "Epoch 319/1000\n",
            "139839/139839 [==============================] - 12s 85us/step - loss: 0.3761 - acc: 0.8689 - categorical_crossentropy: 0.3761 - val_loss: 0.3691 - val_acc: 0.8735 - val_categorical_crossentropy: 0.3691\n",
            "Epoch 320/1000\n",
            "139839/139839 [==============================] - 12s 87us/step - loss: 0.3746 - acc: 0.8691 - categorical_crossentropy: 0.3746 - val_loss: 0.3724 - val_acc: 0.8717 - val_categorical_crossentropy: 0.3724\n",
            "Epoch 321/1000\n",
            "139839/139839 [==============================] - 13s 91us/step - loss: 0.3761 - acc: 0.8685 - categorical_crossentropy: 0.3761 - val_loss: 0.4237 - val_acc: 0.8482 - val_categorical_crossentropy: 0.4237\n",
            "Epoch 322/1000\n",
            "139839/139839 [==============================] - 12s 85us/step - loss: 0.3751 - acc: 0.8699 - categorical_crossentropy: 0.3751 - val_loss: 0.3847 - val_acc: 0.8671 - val_categorical_crossentropy: 0.3847\n",
            "Epoch 323/1000\n",
            "139839/139839 [==============================] - 12s 87us/step - loss: 0.3757 - acc: 0.8687 - categorical_crossentropy: 0.3757 - val_loss: 0.4022 - val_acc: 0.8613 - val_categorical_crossentropy: 0.4022\n",
            "Epoch 324/1000\n",
            "139839/139839 [==============================] - 12s 86us/step - loss: 0.3778 - acc: 0.8684 - categorical_crossentropy: 0.3778 - val_loss: 0.3844 - val_acc: 0.8664 - val_categorical_crossentropy: 0.3844\n",
            "Epoch 325/1000\n",
            "139839/139839 [==============================] - 12s 88us/step - loss: 0.3761 - acc: 0.8684 - categorical_crossentropy: 0.3761 - val_loss: 0.4149 - val_acc: 0.8559 - val_categorical_crossentropy: 0.4149\n",
            "Epoch 326/1000\n",
            "139839/139839 [==============================] - 12s 88us/step - loss: 0.3753 - acc: 0.8694 - categorical_crossentropy: 0.3753 - val_loss: 0.4191 - val_acc: 0.8572 - val_categorical_crossentropy: 0.4191\n",
            "Epoch 327/1000\n",
            "139839/139839 [==============================] - 12s 85us/step - loss: 0.3743 - acc: 0.8698 - categorical_crossentropy: 0.3743 - val_loss: 0.3906 - val_acc: 0.8624 - val_categorical_crossentropy: 0.3906\n",
            "Epoch 328/1000\n",
            "139839/139839 [==============================] - 12s 87us/step - loss: 0.3742 - acc: 0.8684 - categorical_crossentropy: 0.3742 - val_loss: 0.3886 - val_acc: 0.8664 - val_categorical_crossentropy: 0.3886\n",
            "Epoch 329/1000\n",
            "139839/139839 [==============================] - 12s 86us/step - loss: 0.3752 - acc: 0.8691 - categorical_crossentropy: 0.3752 - val_loss: 0.3780 - val_acc: 0.8709 - val_categorical_crossentropy: 0.3780\n",
            "Epoch 330/1000\n",
            "139839/139839 [==============================] - 12s 85us/step - loss: 0.3763 - acc: 0.8681 - categorical_crossentropy: 0.3763 - val_loss: 0.3873 - val_acc: 0.8682 - val_categorical_crossentropy: 0.3873\n",
            "Epoch 331/1000\n",
            "139839/139839 [==============================] - 13s 90us/step - loss: 0.3751 - acc: 0.8690 - categorical_crossentropy: 0.3751 - val_loss: 0.4084 - val_acc: 0.8578 - val_categorical_crossentropy: 0.4084\n",
            "Epoch 332/1000\n",
            "139839/139839 [==============================] - 13s 91us/step - loss: 0.3748 - acc: 0.8688 - categorical_crossentropy: 0.3748 - val_loss: 0.3800 - val_acc: 0.8701 - val_categorical_crossentropy: 0.3800\n",
            "Epoch 333/1000\n",
            "139839/139839 [==============================] - 12s 87us/step - loss: 0.3751 - acc: 0.8694 - categorical_crossentropy: 0.3751 - val_loss: 0.3703 - val_acc: 0.8727 - val_categorical_crossentropy: 0.3703\n",
            "Epoch 334/1000\n",
            "139839/139839 [==============================] - 12s 88us/step - loss: 0.3749 - acc: 0.8695 - categorical_crossentropy: 0.3749 - val_loss: 0.3939 - val_acc: 0.8636 - val_categorical_crossentropy: 0.3939\n",
            "Epoch 335/1000\n",
            "139839/139839 [==============================] - 12s 88us/step - loss: 0.3740 - acc: 0.8693 - categorical_crossentropy: 0.3740 - val_loss: 0.3651 - val_acc: 0.8758 - val_categorical_crossentropy: 0.3651\n",
            "Epoch 336/1000\n",
            "139839/139839 [==============================] - 12s 89us/step - loss: 0.3728 - acc: 0.8705 - categorical_crossentropy: 0.3728 - val_loss: 0.3676 - val_acc: 0.8731 - val_categorical_crossentropy: 0.3676\n",
            "Epoch 337/1000\n",
            "139839/139839 [==============================] - 13s 90us/step - loss: 0.3745 - acc: 0.8688 - categorical_crossentropy: 0.3745 - val_loss: 0.3696 - val_acc: 0.8720 - val_categorical_crossentropy: 0.3696\n",
            "Epoch 338/1000\n",
            "139839/139839 [==============================] - 13s 93us/step - loss: 0.3758 - acc: 0.8685 - categorical_crossentropy: 0.3758 - val_loss: 0.3967 - val_acc: 0.8627 - val_categorical_crossentropy: 0.3967\n",
            "Epoch 339/1000\n",
            "139839/139839 [==============================] - 13s 91us/step - loss: 0.3750 - acc: 0.8683 - categorical_crossentropy: 0.3750 - val_loss: 0.3799 - val_acc: 0.8681 - val_categorical_crossentropy: 0.3799\n",
            "Epoch 340/1000\n",
            "139839/139839 [==============================] - 12s 89us/step - loss: 0.3753 - acc: 0.8694 - categorical_crossentropy: 0.3753 - val_loss: 0.4003 - val_acc: 0.8603 - val_categorical_crossentropy: 0.4003\n",
            "Epoch 341/1000\n",
            "139839/139839 [==============================] - 13s 90us/step - loss: 0.3748 - acc: 0.8682 - categorical_crossentropy: 0.3748 - val_loss: 0.4915 - val_acc: 0.8399 - val_categorical_crossentropy: 0.4915\n",
            "Epoch 342/1000\n",
            "139839/139839 [==============================] - 12s 87us/step - loss: 0.3752 - acc: 0.8694 - categorical_crossentropy: 0.3752 - val_loss: 0.3658 - val_acc: 0.8759 - val_categorical_crossentropy: 0.3658\n",
            "Epoch 343/1000\n",
            "139839/139839 [==============================] - 12s 88us/step - loss: 0.3736 - acc: 0.8699 - categorical_crossentropy: 0.3736 - val_loss: 0.3879 - val_acc: 0.8689 - val_categorical_crossentropy: 0.3879\n",
            "Epoch 344/1000\n",
            "139839/139839 [==============================] - 13s 91us/step - loss: 0.3759 - acc: 0.8690 - categorical_crossentropy: 0.3759 - val_loss: 0.4895 - val_acc: 0.8340 - val_categorical_crossentropy: 0.4895\n",
            "Epoch 345/1000\n",
            "139839/139839 [==============================] - 13s 91us/step - loss: 0.3737 - acc: 0.8688 - categorical_crossentropy: 0.3737 - val_loss: 0.3716 - val_acc: 0.8718 - val_categorical_crossentropy: 0.3716\n",
            "Epoch 346/1000\n",
            "139839/139839 [==============================] - 13s 93us/step - loss: 0.3727 - acc: 0.8699 - categorical_crossentropy: 0.3727 - val_loss: 0.3849 - val_acc: 0.8672 - val_categorical_crossentropy: 0.3849\n",
            "Epoch 347/1000\n",
            "139839/139839 [==============================] - 13s 90us/step - loss: 0.3752 - acc: 0.8685 - categorical_crossentropy: 0.3752 - val_loss: 0.3823 - val_acc: 0.8662 - val_categorical_crossentropy: 0.3823\n",
            "Epoch 348/1000\n",
            "139839/139839 [==============================] - 13s 90us/step - loss: 0.3738 - acc: 0.8696 - categorical_crossentropy: 0.3738 - val_loss: 0.3700 - val_acc: 0.8730 - val_categorical_crossentropy: 0.3700\n",
            "Epoch 349/1000\n",
            "139839/139839 [==============================] - 13s 90us/step - loss: 0.3735 - acc: 0.8700 - categorical_crossentropy: 0.3735 - val_loss: 0.3732 - val_acc: 0.8714 - val_categorical_crossentropy: 0.3732\n",
            "Epoch 350/1000\n",
            "139839/139839 [==============================] - 13s 91us/step - loss: 0.3746 - acc: 0.8692 - categorical_crossentropy: 0.3746 - val_loss: 0.3915 - val_acc: 0.8643 - val_categorical_crossentropy: 0.3915\n",
            "Epoch 351/1000\n",
            "139839/139839 [==============================] - 13s 91us/step - loss: 0.3717 - acc: 0.8702 - categorical_crossentropy: 0.3717 - val_loss: 0.4039 - val_acc: 0.8615 - val_categorical_crossentropy: 0.4039\n",
            "Epoch 352/1000\n",
            "139839/139839 [==============================] - 13s 91us/step - loss: 0.3727 - acc: 0.8700 - categorical_crossentropy: 0.3727 - val_loss: 0.3725 - val_acc: 0.8691 - val_categorical_crossentropy: 0.3725\n",
            "Epoch 353/1000\n",
            "139839/139839 [==============================] - 13s 90us/step - loss: 0.3717 - acc: 0.8703 - categorical_crossentropy: 0.3717 - val_loss: 0.3594 - val_acc: 0.8772 - val_categorical_crossentropy: 0.3594\n",
            "Epoch 354/1000\n",
            "139839/139839 [==============================] - 12s 88us/step - loss: 0.3718 - acc: 0.8700 - categorical_crossentropy: 0.3718 - val_loss: 0.3691 - val_acc: 0.8721 - val_categorical_crossentropy: 0.3691\n",
            "Epoch 355/1000\n",
            "139839/139839 [==============================] - 12s 86us/step - loss: 0.3720 - acc: 0.8698 - categorical_crossentropy: 0.3720 - val_loss: 0.3968 - val_acc: 0.8603 - val_categorical_crossentropy: 0.3968\n",
            "Epoch 356/1000\n",
            "139839/139839 [==============================] - 12s 88us/step - loss: 0.3736 - acc: 0.8694 - categorical_crossentropy: 0.3736 - val_loss: 0.4309 - val_acc: 0.8420 - val_categorical_crossentropy: 0.4309\n",
            "Epoch 357/1000\n",
            "139839/139839 [==============================] - 12s 87us/step - loss: 0.3742 - acc: 0.8685 - categorical_crossentropy: 0.3742 - val_loss: 0.3637 - val_acc: 0.8744 - val_categorical_crossentropy: 0.3637\n",
            "Epoch 358/1000\n",
            "139839/139839 [==============================] - 12s 85us/step - loss: 0.3730 - acc: 0.8691 - categorical_crossentropy: 0.3730 - val_loss: 0.4119 - val_acc: 0.8545 - val_categorical_crossentropy: 0.4119\n",
            "Epoch 359/1000\n",
            "139839/139839 [==============================] - 12s 87us/step - loss: 0.3729 - acc: 0.8698 - categorical_crossentropy: 0.3729 - val_loss: 0.4621 - val_acc: 0.8464 - val_categorical_crossentropy: 0.4621\n",
            "Epoch 360/1000\n",
            "139839/139839 [==============================] - 12s 86us/step - loss: 0.3741 - acc: 0.8698 - categorical_crossentropy: 0.3741 - val_loss: 0.4003 - val_acc: 0.8601 - val_categorical_crossentropy: 0.4003\n",
            "Epoch 361/1000\n",
            "139839/139839 [==============================] - 12s 85us/step - loss: 0.3721 - acc: 0.8698 - categorical_crossentropy: 0.3721 - val_loss: 0.3662 - val_acc: 0.8740 - val_categorical_crossentropy: 0.3662\n",
            "Epoch 362/1000\n",
            "139839/139839 [==============================] - 12s 85us/step - loss: 0.3729 - acc: 0.8696 - categorical_crossentropy: 0.3729 - val_loss: 0.3876 - val_acc: 0.8652 - val_categorical_crossentropy: 0.3876\n",
            "Epoch 363/1000\n",
            "139839/139839 [==============================] - 12s 87us/step - loss: 0.3753 - acc: 0.8694 - categorical_crossentropy: 0.3753 - val_loss: 0.3918 - val_acc: 0.8631 - val_categorical_crossentropy: 0.3918\n",
            "Epoch 364/1000\n",
            "139839/139839 [==============================] - 12s 87us/step - loss: 0.3716 - acc: 0.8711 - categorical_crossentropy: 0.3716 - val_loss: 0.3902 - val_acc: 0.8625 - val_categorical_crossentropy: 0.3902\n",
            "Epoch 365/1000\n",
            "139839/139839 [==============================] - 12s 86us/step - loss: 0.3718 - acc: 0.8705 - categorical_crossentropy: 0.3718 - val_loss: 0.3706 - val_acc: 0.8717 - val_categorical_crossentropy: 0.3706\n",
            "Epoch 366/1000\n",
            "139839/139839 [==============================] - 12s 86us/step - loss: 0.3724 - acc: 0.8691 - categorical_crossentropy: 0.3724 - val_loss: 0.4663 - val_acc: 0.8467 - val_categorical_crossentropy: 0.4663\n",
            "Epoch 367/1000\n",
            "139839/139839 [==============================] - 12s 86us/step - loss: 0.3717 - acc: 0.8701 - categorical_crossentropy: 0.3717 - val_loss: 0.4516 - val_acc: 0.8458 - val_categorical_crossentropy: 0.4516\n",
            "Epoch 368/1000\n",
            "139839/139839 [==============================] - 12s 85us/step - loss: 0.3730 - acc: 0.8690 - categorical_crossentropy: 0.3730 - val_loss: 0.5582 - val_acc: 0.8295 - val_categorical_crossentropy: 0.5582\n",
            "Epoch 369/1000\n",
            "139839/139839 [==============================] - 12s 86us/step - loss: 0.3731 - acc: 0.8702 - categorical_crossentropy: 0.3731 - val_loss: 0.3621 - val_acc: 0.8739 - val_categorical_crossentropy: 0.3621\n",
            "Epoch 370/1000\n",
            "139839/139839 [==============================] - 12s 87us/step - loss: 0.3720 - acc: 0.8695 - categorical_crossentropy: 0.3720 - val_loss: 0.3747 - val_acc: 0.8716 - val_categorical_crossentropy: 0.3747\n",
            "Epoch 371/1000\n",
            "139839/139839 [==============================] - 12s 89us/step - loss: 0.3714 - acc: 0.8695 - categorical_crossentropy: 0.3714 - val_loss: 0.3855 - val_acc: 0.8676 - val_categorical_crossentropy: 0.3855\n",
            "Epoch 372/1000\n",
            "139839/139839 [==============================] - 12s 87us/step - loss: 0.3742 - acc: 0.8705 - categorical_crossentropy: 0.3742 - val_loss: 0.3839 - val_acc: 0.8671 - val_categorical_crossentropy: 0.3839\n",
            "Epoch 373/1000\n",
            "139839/139839 [==============================] - 12s 87us/step - loss: 0.3730 - acc: 0.8699 - categorical_crossentropy: 0.3730 - val_loss: 0.4047 - val_acc: 0.8596 - val_categorical_crossentropy: 0.4047\n",
            "Epoch 374/1000\n",
            "139839/139839 [==============================] - 12s 86us/step - loss: 0.3723 - acc: 0.8704 - categorical_crossentropy: 0.3723 - val_loss: 0.3721 - val_acc: 0.8716 - val_categorical_crossentropy: 0.3721\n",
            "Epoch 375/1000\n",
            "139839/139839 [==============================] - 12s 86us/step - loss: 0.3719 - acc: 0.8697 - categorical_crossentropy: 0.3719 - val_loss: 0.3806 - val_acc: 0.8706 - val_categorical_crossentropy: 0.3806\n",
            "Epoch 376/1000\n",
            "139839/139839 [==============================] - 12s 86us/step - loss: 0.3735 - acc: 0.8698 - categorical_crossentropy: 0.3735 - val_loss: 0.3719 - val_acc: 0.8701 - val_categorical_crossentropy: 0.3719\n",
            "Epoch 377/1000\n",
            "139839/139839 [==============================] - 12s 88us/step - loss: 0.3712 - acc: 0.8713 - categorical_crossentropy: 0.3712 - val_loss: 0.3690 - val_acc: 0.8746 - val_categorical_crossentropy: 0.3690\n",
            "Epoch 378/1000\n",
            "139839/139839 [==============================] - 12s 86us/step - loss: 0.3728 - acc: 0.8695 - categorical_crossentropy: 0.3728 - val_loss: 0.3915 - val_acc: 0.8645 - val_categorical_crossentropy: 0.3915\n",
            "Epoch 379/1000\n",
            "139839/139839 [==============================] - 12s 87us/step - loss: 0.3724 - acc: 0.8702 - categorical_crossentropy: 0.3724 - val_loss: 0.3829 - val_acc: 0.8674 - val_categorical_crossentropy: 0.3829\n",
            "Epoch 380/1000\n",
            "139839/139839 [==============================] - 12s 87us/step - loss: 0.3722 - acc: 0.8700 - categorical_crossentropy: 0.3722 - val_loss: 0.3673 - val_acc: 0.8727 - val_categorical_crossentropy: 0.3673\n",
            "Epoch 381/1000\n",
            "139839/139839 [==============================] - 12s 88us/step - loss: 0.3705 - acc: 0.8713 - categorical_crossentropy: 0.3705 - val_loss: 0.3722 - val_acc: 0.8720 - val_categorical_crossentropy: 0.3722\n",
            "Epoch 382/1000\n",
            "139839/139839 [==============================] - 12s 87us/step - loss: 0.3729 - acc: 0.8705 - categorical_crossentropy: 0.3729 - val_loss: 0.3605 - val_acc: 0.8756 - val_categorical_crossentropy: 0.3605\n",
            "Epoch 383/1000\n",
            "139839/139839 [==============================] - 12s 87us/step - loss: 0.3710 - acc: 0.8700 - categorical_crossentropy: 0.3710 - val_loss: 0.3816 - val_acc: 0.8682 - val_categorical_crossentropy: 0.3816\n",
            "Epoch 384/1000\n",
            "139839/139839 [==============================] - 12s 87us/step - loss: 0.3723 - acc: 0.8699 - categorical_crossentropy: 0.3723 - val_loss: 0.3909 - val_acc: 0.8653 - val_categorical_crossentropy: 0.3909\n",
            "Epoch 385/1000\n",
            "139839/139839 [==============================] - 12s 86us/step - loss: 0.3723 - acc: 0.8703 - categorical_crossentropy: 0.3723 - val_loss: 0.3875 - val_acc: 0.8634 - val_categorical_crossentropy: 0.3875\n",
            "Epoch 386/1000\n",
            "139839/139839 [==============================] - 12s 86us/step - loss: 0.3708 - acc: 0.8707 - categorical_crossentropy: 0.3708 - val_loss: 0.4288 - val_acc: 0.8599 - val_categorical_crossentropy: 0.4288\n",
            "Epoch 387/1000\n",
            "139839/139839 [==============================] - 12s 85us/step - loss: 0.3713 - acc: 0.8699 - categorical_crossentropy: 0.3713 - val_loss: 0.3860 - val_acc: 0.8677 - val_categorical_crossentropy: 0.3860\n",
            "Epoch 388/1000\n",
            "139839/139839 [==============================] - 12s 86us/step - loss: 0.3701 - acc: 0.8706 - categorical_crossentropy: 0.3701 - val_loss: 0.4014 - val_acc: 0.8581 - val_categorical_crossentropy: 0.4014\n",
            "Epoch 389/1000\n",
            "139839/139839 [==============================] - 12s 87us/step - loss: 0.3705 - acc: 0.8702 - categorical_crossentropy: 0.3705 - val_loss: 0.3730 - val_acc: 0.8723 - val_categorical_crossentropy: 0.3730\n",
            "Epoch 390/1000\n",
            "139839/139839 [==============================] - 12s 87us/step - loss: 0.3708 - acc: 0.8705 - categorical_crossentropy: 0.3708 - val_loss: 0.3629 - val_acc: 0.8753 - val_categorical_crossentropy: 0.3629\n",
            "Epoch 391/1000\n",
            "139839/139839 [==============================] - 12s 86us/step - loss: 0.3701 - acc: 0.8708 - categorical_crossentropy: 0.3701 - val_loss: 0.3652 - val_acc: 0.8727 - val_categorical_crossentropy: 0.3652\n",
            "Epoch 392/1000\n",
            "139839/139839 [==============================] - 12s 86us/step - loss: 0.3711 - acc: 0.8704 - categorical_crossentropy: 0.3711 - val_loss: 0.3757 - val_acc: 0.8712 - val_categorical_crossentropy: 0.3757\n",
            "Epoch 393/1000\n",
            "139839/139839 [==============================] - 12s 85us/step - loss: 0.3702 - acc: 0.8711 - categorical_crossentropy: 0.3702 - val_loss: 0.3618 - val_acc: 0.8752 - val_categorical_crossentropy: 0.3618\n",
            "Epoch 394/1000\n",
            "139839/139839 [==============================] - 12s 86us/step - loss: 0.3709 - acc: 0.8708 - categorical_crossentropy: 0.3709 - val_loss: 0.3934 - val_acc: 0.8665 - val_categorical_crossentropy: 0.3934\n",
            "Epoch 395/1000\n",
            "139839/139839 [==============================] - 12s 86us/step - loss: 0.3713 - acc: 0.8709 - categorical_crossentropy: 0.3713 - val_loss: 0.3689 - val_acc: 0.8716 - val_categorical_crossentropy: 0.3689\n",
            "Epoch 396/1000\n",
            "139839/139839 [==============================] - 12s 85us/step - loss: 0.3720 - acc: 0.8694 - categorical_crossentropy: 0.3720 - val_loss: 0.4310 - val_acc: 0.8524 - val_categorical_crossentropy: 0.4310\n",
            "Epoch 397/1000\n",
            "139839/139839 [==============================] - 13s 90us/step - loss: 0.3705 - acc: 0.8702 - categorical_crossentropy: 0.3705 - val_loss: 0.3997 - val_acc: 0.8621 - val_categorical_crossentropy: 0.3997\n",
            "Epoch 398/1000\n",
            "139839/139839 [==============================] - 12s 86us/step - loss: 0.3709 - acc: 0.8697 - categorical_crossentropy: 0.3709 - val_loss: 0.4234 - val_acc: 0.8543 - val_categorical_crossentropy: 0.4234\n",
            "Epoch 399/1000\n",
            "139839/139839 [==============================] - 12s 87us/step - loss: 0.3700 - acc: 0.8707 - categorical_crossentropy: 0.3700 - val_loss: 0.3760 - val_acc: 0.8721 - val_categorical_crossentropy: 0.3760\n",
            "Epoch 400/1000\n",
            "139839/139839 [==============================] - 12s 86us/step - loss: 0.3722 - acc: 0.8697 - categorical_crossentropy: 0.3722 - val_loss: 0.3730 - val_acc: 0.8701 - val_categorical_crossentropy: 0.3730\n",
            "Epoch 401/1000\n",
            "139839/139839 [==============================] - 12s 85us/step - loss: 0.3716 - acc: 0.8696 - categorical_crossentropy: 0.3716 - val_loss: 0.3817 - val_acc: 0.8674 - val_categorical_crossentropy: 0.3817\n",
            "Epoch 402/1000\n",
            "139839/139839 [==============================] - 12s 85us/step - loss: 0.3709 - acc: 0.8703 - categorical_crossentropy: 0.3709 - val_loss: 0.3688 - val_acc: 0.8710 - val_categorical_crossentropy: 0.3688\n",
            "Epoch 403/1000\n",
            "139839/139839 [==============================] - 12s 87us/step - loss: 0.3698 - acc: 0.8708 - categorical_crossentropy: 0.3698 - val_loss: 0.3668 - val_acc: 0.8747 - val_categorical_crossentropy: 0.3668\n",
            "Epoch 404/1000\n",
            "139839/139839 [==============================] - 12s 88us/step - loss: 0.3702 - acc: 0.8712 - categorical_crossentropy: 0.3702 - val_loss: 0.3753 - val_acc: 0.8703 - val_categorical_crossentropy: 0.3753\n",
            "Epoch 405/1000\n",
            "139839/139839 [==============================] - 12s 86us/step - loss: 0.3696 - acc: 0.8701 - categorical_crossentropy: 0.3696 - val_loss: 0.3735 - val_acc: 0.8742 - val_categorical_crossentropy: 0.3735\n",
            "Epoch 406/1000\n",
            "139839/139839 [==============================] - 12s 85us/step - loss: 0.3702 - acc: 0.8705 - categorical_crossentropy: 0.3702 - val_loss: 0.4094 - val_acc: 0.8581 - val_categorical_crossentropy: 0.4094\n",
            "Epoch 407/1000\n",
            "139839/139839 [==============================] - 12s 86us/step - loss: 0.3701 - acc: 0.8710 - categorical_crossentropy: 0.3701 - val_loss: 0.3721 - val_acc: 0.8706 - val_categorical_crossentropy: 0.3721\n",
            "Epoch 408/1000\n",
            "139839/139839 [==============================] - 12s 85us/step - loss: 0.3690 - acc: 0.8709 - categorical_crossentropy: 0.3690 - val_loss: 0.3662 - val_acc: 0.8747 - val_categorical_crossentropy: 0.3662\n",
            "Epoch 409/1000\n",
            "139839/139839 [==============================] - 12s 86us/step - loss: 0.3686 - acc: 0.8708 - categorical_crossentropy: 0.3686 - val_loss: 0.5854 - val_acc: 0.8335 - val_categorical_crossentropy: 0.5854\n",
            "Epoch 410/1000\n",
            "139839/139839 [==============================] - 12s 86us/step - loss: 0.3688 - acc: 0.8710 - categorical_crossentropy: 0.3688 - val_loss: 0.3656 - val_acc: 0.8749 - val_categorical_crossentropy: 0.3656\n",
            "Epoch 411/1000\n",
            "139839/139839 [==============================] - 12s 87us/step - loss: 0.3695 - acc: 0.8711 - categorical_crossentropy: 0.3695 - val_loss: 0.3791 - val_acc: 0.8700 - val_categorical_crossentropy: 0.3791\n",
            "Epoch 412/1000\n",
            "139839/139839 [==============================] - 12s 87us/step - loss: 0.3697 - acc: 0.8712 - categorical_crossentropy: 0.3697 - val_loss: 0.3841 - val_acc: 0.8689 - val_categorical_crossentropy: 0.3841\n",
            "Epoch 413/1000\n",
            "139839/139839 [==============================] - 12s 88us/step - loss: 0.3700 - acc: 0.8703 - categorical_crossentropy: 0.3700 - val_loss: 0.3621 - val_acc: 0.8749 - val_categorical_crossentropy: 0.3621\n",
            "Epoch 414/1000\n",
            "139839/139839 [==============================] - 12s 88us/step - loss: 0.3686 - acc: 0.8704 - categorical_crossentropy: 0.3686 - val_loss: 0.3685 - val_acc: 0.8743 - val_categorical_crossentropy: 0.3685\n",
            "Epoch 415/1000\n",
            "139839/139839 [==============================] - 12s 87us/step - loss: 0.3704 - acc: 0.8705 - categorical_crossentropy: 0.3704 - val_loss: 0.3607 - val_acc: 0.8753 - val_categorical_crossentropy: 0.3607\n",
            "Epoch 416/1000\n",
            "139839/139839 [==============================] - 12s 87us/step - loss: 0.3702 - acc: 0.8701 - categorical_crossentropy: 0.3702 - val_loss: 0.3636 - val_acc: 0.8749 - val_categorical_crossentropy: 0.3636\n",
            "Epoch 417/1000\n",
            "139839/139839 [==============================] - 12s 89us/step - loss: 0.3682 - acc: 0.8709 - categorical_crossentropy: 0.3682 - val_loss: 0.4083 - val_acc: 0.8633 - val_categorical_crossentropy: 0.4083\n",
            "Epoch 418/1000\n",
            "139839/139839 [==============================] - 13s 90us/step - loss: 0.3696 - acc: 0.8712 - categorical_crossentropy: 0.3696 - val_loss: 0.3669 - val_acc: 0.8742 - val_categorical_crossentropy: 0.3669\n",
            "Epoch 419/1000\n",
            "139839/139839 [==============================] - 12s 89us/step - loss: 0.3689 - acc: 0.8713 - categorical_crossentropy: 0.3689 - val_loss: 0.3762 - val_acc: 0.8685 - val_categorical_crossentropy: 0.3762\n",
            "Epoch 420/1000\n",
            "139839/139839 [==============================] - 12s 84us/step - loss: 0.3711 - acc: 0.8698 - categorical_crossentropy: 0.3711 - val_loss: 0.3677 - val_acc: 0.8722 - val_categorical_crossentropy: 0.3677\n",
            "Epoch 421/1000\n",
            "139839/139839 [==============================] - 12s 86us/step - loss: 0.3701 - acc: 0.8704 - categorical_crossentropy: 0.3701 - val_loss: 0.4207 - val_acc: 0.8601 - val_categorical_crossentropy: 0.4207\n",
            "Epoch 422/1000\n",
            "139839/139839 [==============================] - 12s 87us/step - loss: 0.3693 - acc: 0.8708 - categorical_crossentropy: 0.3693 - val_loss: 0.4018 - val_acc: 0.8646 - val_categorical_crossentropy: 0.4018\n",
            "Epoch 423/1000\n",
            "139839/139839 [==============================] - 12s 89us/step - loss: 0.3685 - acc: 0.8708 - categorical_crossentropy: 0.3685 - val_loss: 0.3647 - val_acc: 0.8749 - val_categorical_crossentropy: 0.3647\n",
            "Epoch 424/1000\n",
            "139839/139839 [==============================] - 12s 86us/step - loss: 0.3700 - acc: 0.8705 - categorical_crossentropy: 0.3700 - val_loss: 0.3936 - val_acc: 0.8615 - val_categorical_crossentropy: 0.3936\n",
            "Epoch 425/1000\n",
            "139839/139839 [==============================] - 12s 84us/step - loss: 0.3676 - acc: 0.8715 - categorical_crossentropy: 0.3676 - val_loss: 0.3741 - val_acc: 0.8726 - val_categorical_crossentropy: 0.3741\n",
            "Epoch 426/1000\n",
            "139839/139839 [==============================] - 12s 85us/step - loss: 0.3685 - acc: 0.8718 - categorical_crossentropy: 0.3685 - val_loss: 0.3767 - val_acc: 0.8694 - val_categorical_crossentropy: 0.3767\n",
            "Epoch 427/1000\n",
            "139839/139839 [==============================] - 12s 84us/step - loss: 0.3676 - acc: 0.8712 - categorical_crossentropy: 0.3676 - val_loss: 0.3757 - val_acc: 0.8716 - val_categorical_crossentropy: 0.3757\n",
            "Epoch 428/1000\n",
            "139839/139839 [==============================] - 12s 85us/step - loss: 0.3686 - acc: 0.8715 - categorical_crossentropy: 0.3686 - val_loss: 0.3669 - val_acc: 0.8719 - val_categorical_crossentropy: 0.3669\n",
            "Epoch 429/1000\n",
            "139839/139839 [==============================] - 12s 85us/step - loss: 0.3693 - acc: 0.8703 - categorical_crossentropy: 0.3693 - val_loss: 0.4310 - val_acc: 0.8501 - val_categorical_crossentropy: 0.4310\n",
            "Epoch 430/1000\n",
            "139839/139839 [==============================] - 12s 86us/step - loss: 0.3704 - acc: 0.8708 - categorical_crossentropy: 0.3704 - val_loss: 0.3773 - val_acc: 0.8684 - val_categorical_crossentropy: 0.3773\n",
            "Epoch 431/1000\n",
            "139839/139839 [==============================] - 12s 86us/step - loss: 0.3685 - acc: 0.8715 - categorical_crossentropy: 0.3685 - val_loss: 0.3585 - val_acc: 0.8761 - val_categorical_crossentropy: 0.3585\n",
            "Epoch 432/1000\n",
            "139839/139839 [==============================] - 12s 87us/step - loss: 0.3688 - acc: 0.8707 - categorical_crossentropy: 0.3688 - val_loss: 0.3847 - val_acc: 0.8636 - val_categorical_crossentropy: 0.3847\n",
            "Epoch 433/1000\n",
            "139839/139839 [==============================] - 12s 84us/step - loss: 0.3705 - acc: 0.8697 - categorical_crossentropy: 0.3705 - val_loss: 0.3679 - val_acc: 0.8736 - val_categorical_crossentropy: 0.3679\n",
            "Epoch 434/1000\n",
            "139839/139839 [==============================] - 12s 85us/step - loss: 0.3690 - acc: 0.8710 - categorical_crossentropy: 0.3690 - val_loss: 0.3995 - val_acc: 0.8631 - val_categorical_crossentropy: 0.3995\n",
            "Epoch 435/1000\n",
            "139839/139839 [==============================] - 12s 84us/step - loss: 0.3688 - acc: 0.8703 - categorical_crossentropy: 0.3688 - val_loss: 0.3770 - val_acc: 0.8686 - val_categorical_crossentropy: 0.3770\n",
            "Epoch 436/1000\n",
            "139839/139839 [==============================] - 12s 86us/step - loss: 0.3686 - acc: 0.8714 - categorical_crossentropy: 0.3686 - val_loss: 0.3899 - val_acc: 0.8651 - val_categorical_crossentropy: 0.3899\n",
            "Epoch 437/1000\n",
            "139839/139839 [==============================] - 12s 84us/step - loss: 0.3681 - acc: 0.8705 - categorical_crossentropy: 0.3681 - val_loss: 0.3636 - val_acc: 0.8753 - val_categorical_crossentropy: 0.3636\n",
            "Epoch 438/1000\n",
            "139839/139839 [==============================] - 12s 85us/step - loss: 0.3685 - acc: 0.8710 - categorical_crossentropy: 0.3685 - val_loss: 0.3615 - val_acc: 0.8742 - val_categorical_crossentropy: 0.3615\n",
            "Epoch 439/1000\n",
            "139839/139839 [==============================] - 12s 85us/step - loss: 0.3692 - acc: 0.8709 - categorical_crossentropy: 0.3692 - val_loss: 0.4132 - val_acc: 0.8560 - val_categorical_crossentropy: 0.4132\n",
            "Epoch 440/1000\n",
            "139839/139839 [==============================] - 12s 84us/step - loss: 0.3680 - acc: 0.8714 - categorical_crossentropy: 0.3680 - val_loss: 0.3758 - val_acc: 0.8712 - val_categorical_crossentropy: 0.3758\n",
            "Epoch 441/1000\n",
            "139839/139839 [==============================] - 12s 86us/step - loss: 0.3673 - acc: 0.8725 - categorical_crossentropy: 0.3673 - val_loss: 0.3767 - val_acc: 0.8678 - val_categorical_crossentropy: 0.3767\n",
            "Epoch 442/1000\n",
            "139839/139839 [==============================] - 12s 85us/step - loss: 0.3682 - acc: 0.8716 - categorical_crossentropy: 0.3682 - val_loss: 0.3998 - val_acc: 0.8608 - val_categorical_crossentropy: 0.3998\n",
            "Epoch 443/1000\n",
            "139839/139839 [==============================] - 12s 85us/step - loss: 0.3679 - acc: 0.8716 - categorical_crossentropy: 0.3679 - val_loss: 0.3701 - val_acc: 0.8720 - val_categorical_crossentropy: 0.3701\n",
            "Epoch 444/1000\n",
            "139839/139839 [==============================] - 12s 86us/step - loss: 0.3688 - acc: 0.8710 - categorical_crossentropy: 0.3688 - val_loss: 0.3626 - val_acc: 0.8747 - val_categorical_crossentropy: 0.3626\n",
            "Epoch 445/1000\n",
            "139839/139839 [==============================] - 12s 84us/step - loss: 0.3676 - acc: 0.8719 - categorical_crossentropy: 0.3676 - val_loss: 0.3764 - val_acc: 0.8694 - val_categorical_crossentropy: 0.3764\n",
            "Epoch 446/1000\n",
            "139839/139839 [==============================] - 12s 84us/step - loss: 0.3692 - acc: 0.8707 - categorical_crossentropy: 0.3692 - val_loss: 0.3698 - val_acc: 0.8721 - val_categorical_crossentropy: 0.3698\n",
            "Epoch 447/1000\n",
            "139839/139839 [==============================] - 12s 83us/step - loss: 0.3677 - acc: 0.8712 - categorical_crossentropy: 0.3677 - val_loss: 0.4001 - val_acc: 0.8600 - val_categorical_crossentropy: 0.4001\n",
            "Epoch 448/1000\n",
            "139839/139839 [==============================] - 12s 85us/step - loss: 0.3695 - acc: 0.8707 - categorical_crossentropy: 0.3695 - val_loss: 0.4021 - val_acc: 0.8648 - val_categorical_crossentropy: 0.4021\n",
            "Epoch 449/1000\n",
            "139839/139839 [==============================] - 12s 88us/step - loss: 0.3685 - acc: 0.8714 - categorical_crossentropy: 0.3685 - val_loss: 0.3551 - val_acc: 0.8785 - val_categorical_crossentropy: 0.3551\n",
            "Epoch 450/1000\n",
            "139839/139839 [==============================] - 12s 86us/step - loss: 0.3696 - acc: 0.8699 - categorical_crossentropy: 0.3696 - val_loss: 0.3551 - val_acc: 0.8767 - val_categorical_crossentropy: 0.3551\n",
            "Epoch 451/1000\n",
            "139839/139839 [==============================] - 12s 85us/step - loss: 0.3685 - acc: 0.8714 - categorical_crossentropy: 0.3685 - val_loss: 0.4000 - val_acc: 0.8650 - val_categorical_crossentropy: 0.4000\n",
            "Epoch 452/1000\n",
            "139839/139839 [==============================] - 12s 83us/step - loss: 0.3676 - acc: 0.8718 - categorical_crossentropy: 0.3676 - val_loss: 0.4114 - val_acc: 0.8576 - val_categorical_crossentropy: 0.4114\n",
            "Epoch 453/1000\n",
            "139839/139839 [==============================] - 12s 83us/step - loss: 0.3671 - acc: 0.8712 - categorical_crossentropy: 0.3671 - val_loss: 0.3755 - val_acc: 0.8711 - val_categorical_crossentropy: 0.3755\n",
            "Epoch 454/1000\n",
            "139839/139839 [==============================] - 12s 85us/step - loss: 0.3691 - acc: 0.8707 - categorical_crossentropy: 0.3691 - val_loss: 0.3827 - val_acc: 0.8684 - val_categorical_crossentropy: 0.3827\n",
            "Epoch 455/1000\n",
            "139839/139839 [==============================] - 12s 83us/step - loss: 0.3679 - acc: 0.8712 - categorical_crossentropy: 0.3679 - val_loss: 0.3821 - val_acc: 0.8667 - val_categorical_crossentropy: 0.3821\n",
            "Epoch 456/1000\n",
            "139839/139839 [==============================] - 12s 84us/step - loss: 0.3670 - acc: 0.8718 - categorical_crossentropy: 0.3670 - val_loss: 0.3887 - val_acc: 0.8662 - val_categorical_crossentropy: 0.3887\n",
            "Epoch 457/1000\n",
            "139839/139839 [==============================] - 12s 84us/step - loss: 0.3685 - acc: 0.8708 - categorical_crossentropy: 0.3685 - val_loss: 0.3827 - val_acc: 0.8691 - val_categorical_crossentropy: 0.3827\n",
            "Epoch 458/1000\n",
            "139839/139839 [==============================] - 12s 85us/step - loss: 0.3669 - acc: 0.8718 - categorical_crossentropy: 0.3669 - val_loss: 0.3670 - val_acc: 0.8740 - val_categorical_crossentropy: 0.3670\n",
            "Epoch 459/1000\n",
            "139839/139839 [==============================] - 12s 85us/step - loss: 0.3682 - acc: 0.8715 - categorical_crossentropy: 0.3682 - val_loss: 0.3657 - val_acc: 0.8740 - val_categorical_crossentropy: 0.3657\n",
            "Epoch 460/1000\n",
            "139839/139839 [==============================] - 12s 84us/step - loss: 0.3677 - acc: 0.8708 - categorical_crossentropy: 0.3677 - val_loss: 0.3630 - val_acc: 0.8752 - val_categorical_crossentropy: 0.3630\n",
            "Epoch 461/1000\n",
            "139839/139839 [==============================] - 12s 86us/step - loss: 0.3680 - acc: 0.8715 - categorical_crossentropy: 0.3680 - val_loss: 0.3627 - val_acc: 0.8751 - val_categorical_crossentropy: 0.3627\n",
            "Epoch 462/1000\n",
            "139839/139839 [==============================] - 12s 86us/step - loss: 0.3680 - acc: 0.8707 - categorical_crossentropy: 0.3680 - val_loss: 0.3781 - val_acc: 0.8666 - val_categorical_crossentropy: 0.3781\n",
            "Epoch 463/1000\n",
            "139839/139839 [==============================] - 12s 87us/step - loss: 0.3677 - acc: 0.8709 - categorical_crossentropy: 0.3677 - val_loss: 0.3786 - val_acc: 0.8716 - val_categorical_crossentropy: 0.3786\n",
            "Epoch 464/1000\n",
            "139839/139839 [==============================] - 12s 88us/step - loss: 0.3660 - acc: 0.8723 - categorical_crossentropy: 0.3660 - val_loss: 0.3576 - val_acc: 0.8762 - val_categorical_crossentropy: 0.3576\n",
            "Epoch 465/1000\n",
            "139839/139839 [==============================] - 12s 86us/step - loss: 0.3665 - acc: 0.8713 - categorical_crossentropy: 0.3665 - val_loss: 0.3578 - val_acc: 0.8762 - val_categorical_crossentropy: 0.3578\n",
            "Epoch 466/1000\n",
            "139839/139839 [==============================] - 12s 86us/step - loss: 0.3656 - acc: 0.8721 - categorical_crossentropy: 0.3656 - val_loss: 0.4226 - val_acc: 0.8539 - val_categorical_crossentropy: 0.4226\n",
            "Epoch 467/1000\n",
            "139839/139839 [==============================] - 12s 85us/step - loss: 0.3688 - acc: 0.8713 - categorical_crossentropy: 0.3688 - val_loss: 0.3728 - val_acc: 0.8711 - val_categorical_crossentropy: 0.3728\n",
            "Epoch 468/1000\n",
            "139839/139839 [==============================] - 12s 83us/step - loss: 0.3677 - acc: 0.8714 - categorical_crossentropy: 0.3677 - val_loss: 0.3664 - val_acc: 0.8736 - val_categorical_crossentropy: 0.3664\n",
            "Epoch 469/1000\n",
            "139839/139839 [==============================] - 12s 85us/step - loss: 0.3655 - acc: 0.8717 - categorical_crossentropy: 0.3655 - val_loss: 0.3949 - val_acc: 0.8628 - val_categorical_crossentropy: 0.3949\n",
            "Epoch 470/1000\n",
            "139839/139839 [==============================] - 12s 84us/step - loss: 0.3661 - acc: 0.8722 - categorical_crossentropy: 0.3661 - val_loss: 0.3683 - val_acc: 0.8722 - val_categorical_crossentropy: 0.3683\n",
            "Epoch 471/1000\n",
            "139839/139839 [==============================] - 12s 88us/step - loss: 0.3690 - acc: 0.8706 - categorical_crossentropy: 0.3690 - val_loss: 0.3710 - val_acc: 0.8717 - val_categorical_crossentropy: 0.3710\n",
            "Epoch 472/1000\n",
            "139839/139839 [==============================] - 12s 85us/step - loss: 0.3665 - acc: 0.8715 - categorical_crossentropy: 0.3665 - val_loss: 0.3522 - val_acc: 0.8780 - val_categorical_crossentropy: 0.3522\n",
            "Epoch 473/1000\n",
            "139839/139839 [==============================] - 12s 87us/step - loss: 0.3655 - acc: 0.8722 - categorical_crossentropy: 0.3655 - val_loss: 0.3770 - val_acc: 0.8696 - val_categorical_crossentropy: 0.3770\n",
            "Epoch 474/1000\n",
            "139839/139839 [==============================] - 13s 90us/step - loss: 0.3679 - acc: 0.8717 - categorical_crossentropy: 0.3679 - val_loss: 0.3728 - val_acc: 0.8724 - val_categorical_crossentropy: 0.3728\n",
            "Epoch 475/1000\n",
            "139839/139839 [==============================] - 12s 88us/step - loss: 0.3661 - acc: 0.8713 - categorical_crossentropy: 0.3661 - val_loss: 0.3847 - val_acc: 0.8690 - val_categorical_crossentropy: 0.3847\n",
            "Epoch 476/1000\n",
            "139839/139839 [==============================] - 12s 83us/step - loss: 0.3665 - acc: 0.8719 - categorical_crossentropy: 0.3665 - val_loss: 0.3886 - val_acc: 0.8642 - val_categorical_crossentropy: 0.3886\n",
            "Epoch 477/1000\n",
            "139839/139839 [==============================] - 12s 84us/step - loss: 0.3659 - acc: 0.8718 - categorical_crossentropy: 0.3659 - val_loss: 0.3765 - val_acc: 0.8703 - val_categorical_crossentropy: 0.3765\n",
            "Epoch 478/1000\n",
            "139839/139839 [==============================] - 12s 84us/step - loss: 0.3667 - acc: 0.8715 - categorical_crossentropy: 0.3667 - val_loss: 0.3550 - val_acc: 0.8770 - val_categorical_crossentropy: 0.3550\n",
            "Epoch 479/1000\n",
            "139839/139839 [==============================] - 12s 85us/step - loss: 0.3670 - acc: 0.8715 - categorical_crossentropy: 0.3670 - val_loss: 0.3716 - val_acc: 0.8742 - val_categorical_crossentropy: 0.3716\n",
            "Epoch 480/1000\n",
            "139839/139839 [==============================] - 12s 84us/step - loss: 0.3682 - acc: 0.8709 - categorical_crossentropy: 0.3682 - val_loss: 0.3659 - val_acc: 0.8719 - val_categorical_crossentropy: 0.3659\n",
            "Epoch 481/1000\n",
            "139839/139839 [==============================] - 12s 84us/step - loss: 0.3659 - acc: 0.8718 - categorical_crossentropy: 0.3659 - val_loss: 0.3855 - val_acc: 0.8643 - val_categorical_crossentropy: 0.3855\n",
            "Epoch 482/1000\n",
            "139839/139839 [==============================] - 11s 82us/step - loss: 0.3677 - acc: 0.8710 - categorical_crossentropy: 0.3677 - val_loss: 0.3604 - val_acc: 0.8760 - val_categorical_crossentropy: 0.3604\n",
            "Epoch 483/1000\n",
            "139839/139839 [==============================] - 12s 85us/step - loss: 0.3668 - acc: 0.8716 - categorical_crossentropy: 0.3668 - val_loss: 0.3874 - val_acc: 0.8649 - val_categorical_crossentropy: 0.3874\n",
            "Epoch 484/1000\n",
            "139839/139839 [==============================] - 12s 86us/step - loss: 0.3679 - acc: 0.8711 - categorical_crossentropy: 0.3679 - val_loss: 0.3774 - val_acc: 0.8685 - val_categorical_crossentropy: 0.3774\n",
            "Epoch 485/1000\n",
            "139839/139839 [==============================] - 12s 84us/step - loss: 0.3675 - acc: 0.8717 - categorical_crossentropy: 0.3675 - val_loss: 0.3665 - val_acc: 0.8743 - val_categorical_crossentropy: 0.3665\n",
            "Epoch 486/1000\n",
            "139839/139839 [==============================] - 12s 84us/step - loss: 0.3672 - acc: 0.8713 - categorical_crossentropy: 0.3672 - val_loss: 0.3743 - val_acc: 0.8711 - val_categorical_crossentropy: 0.3743\n",
            "Epoch 487/1000\n",
            "139839/139839 [==============================] - 12s 83us/step - loss: 0.3673 - acc: 0.8714 - categorical_crossentropy: 0.3673 - val_loss: 0.3722 - val_acc: 0.8726 - val_categorical_crossentropy: 0.3722\n",
            "Epoch 488/1000\n",
            "139839/139839 [==============================] - 12s 84us/step - loss: 0.3672 - acc: 0.8715 - categorical_crossentropy: 0.3672 - val_loss: 0.3720 - val_acc: 0.8730 - val_categorical_crossentropy: 0.3720\n",
            "Epoch 489/1000\n",
            "139839/139839 [==============================] - 12s 84us/step - loss: 0.3661 - acc: 0.8719 - categorical_crossentropy: 0.3661 - val_loss: 0.3815 - val_acc: 0.8687 - val_categorical_crossentropy: 0.3815\n",
            "Epoch 490/1000\n",
            "139839/139839 [==============================] - 12s 84us/step - loss: 0.3662 - acc: 0.8717 - categorical_crossentropy: 0.3662 - val_loss: 0.3859 - val_acc: 0.8672 - val_categorical_crossentropy: 0.3859\n",
            "Epoch 491/1000\n",
            "139839/139839 [==============================] - 12s 86us/step - loss: 0.3660 - acc: 0.8715 - categorical_crossentropy: 0.3660 - val_loss: 0.3610 - val_acc: 0.8743 - val_categorical_crossentropy: 0.3610\n",
            "Epoch 492/1000\n",
            "139839/139839 [==============================] - 12s 83us/step - loss: 0.3661 - acc: 0.8714 - categorical_crossentropy: 0.3661 - val_loss: 0.3669 - val_acc: 0.8742 - val_categorical_crossentropy: 0.3669\n",
            "Epoch 493/1000\n",
            "139839/139839 [==============================] - 12s 84us/step - loss: 0.3644 - acc: 0.8727 - categorical_crossentropy: 0.3644 - val_loss: 0.3733 - val_acc: 0.8720 - val_categorical_crossentropy: 0.3733\n",
            "Epoch 494/1000\n",
            "139839/139839 [==============================] - 12s 84us/step - loss: 0.3673 - acc: 0.8710 - categorical_crossentropy: 0.3673 - val_loss: 0.3578 - val_acc: 0.8759 - val_categorical_crossentropy: 0.3578\n",
            "Epoch 495/1000\n",
            "139839/139839 [==============================] - 12s 83us/step - loss: 0.3667 - acc: 0.8721 - categorical_crossentropy: 0.3667 - val_loss: 0.3772 - val_acc: 0.8705 - val_categorical_crossentropy: 0.3772\n",
            "Epoch 496/1000\n",
            "139839/139839 [==============================] - 12s 85us/step - loss: 0.3662 - acc: 0.8725 - categorical_crossentropy: 0.3662 - val_loss: 0.3907 - val_acc: 0.8642 - val_categorical_crossentropy: 0.3907\n",
            "Epoch 497/1000\n",
            "139839/139839 [==============================] - 12s 83us/step - loss: 0.3683 - acc: 0.8714 - categorical_crossentropy: 0.3683 - val_loss: 0.3768 - val_acc: 0.8718 - val_categorical_crossentropy: 0.3768\n",
            "Epoch 498/1000\n",
            "139839/139839 [==============================] - 12s 84us/step - loss: 0.3660 - acc: 0.8712 - categorical_crossentropy: 0.3660 - val_loss: 0.3619 - val_acc: 0.8761 - val_categorical_crossentropy: 0.3619\n",
            "Epoch 499/1000\n",
            "139839/139839 [==============================] - 12s 85us/step - loss: 0.3672 - acc: 0.8716 - categorical_crossentropy: 0.3672 - val_loss: 0.4748 - val_acc: 0.8460 - val_categorical_crossentropy: 0.4748\n",
            "Epoch 500/1000\n",
            "139839/139839 [==============================] - 12s 83us/step - loss: 0.3658 - acc: 0.8720 - categorical_crossentropy: 0.3658 - val_loss: 0.3772 - val_acc: 0.8710 - val_categorical_crossentropy: 0.3772\n",
            "Epoch 501/1000\n",
            "139839/139839 [==============================] - 12s 88us/step - loss: 0.3657 - acc: 0.8724 - categorical_crossentropy: 0.3657 - val_loss: 0.3921 - val_acc: 0.8626 - val_categorical_crossentropy: 0.3921\n",
            "Epoch 502/1000\n",
            "139839/139839 [==============================] - 11s 82us/step - loss: 0.3664 - acc: 0.8723 - categorical_crossentropy: 0.3664 - val_loss: 0.3702 - val_acc: 0.8725 - val_categorical_crossentropy: 0.3702\n",
            "Epoch 503/1000\n",
            "139839/139839 [==============================] - 12s 84us/step - loss: 0.3666 - acc: 0.8723 - categorical_crossentropy: 0.3666 - val_loss: 0.3772 - val_acc: 0.8714 - val_categorical_crossentropy: 0.3772\n",
            "Epoch 504/1000\n",
            "139839/139839 [==============================] - 12s 85us/step - loss: 0.3664 - acc: 0.8718 - categorical_crossentropy: 0.3664 - val_loss: 0.3635 - val_acc: 0.8749 - val_categorical_crossentropy: 0.3635\n",
            "Epoch 505/1000\n",
            "139839/139839 [==============================] - 12s 83us/step - loss: 0.3665 - acc: 0.8721 - categorical_crossentropy: 0.3665 - val_loss: 0.3604 - val_acc: 0.8763 - val_categorical_crossentropy: 0.3604\n",
            "Epoch 506/1000\n",
            "139839/139839 [==============================] - 12s 83us/step - loss: 0.3669 - acc: 0.8721 - categorical_crossentropy: 0.3669 - val_loss: 0.3662 - val_acc: 0.8747 - val_categorical_crossentropy: 0.3662\n",
            "Epoch 507/1000\n",
            "139839/139839 [==============================] - 12s 85us/step - loss: 0.3663 - acc: 0.8724 - categorical_crossentropy: 0.3663 - val_loss: 0.3913 - val_acc: 0.8609 - val_categorical_crossentropy: 0.3913\n",
            "Epoch 508/1000\n",
            "139839/139839 [==============================] - 12s 83us/step - loss: 0.3659 - acc: 0.8714 - categorical_crossentropy: 0.3659 - val_loss: 0.4066 - val_acc: 0.8612 - val_categorical_crossentropy: 0.4066\n",
            "Epoch 509/1000\n",
            "139839/139839 [==============================] - 12s 85us/step - loss: 0.3664 - acc: 0.8715 - categorical_crossentropy: 0.3664 - val_loss: 0.3663 - val_acc: 0.8735 - val_categorical_crossentropy: 0.3663\n",
            "Epoch 510/1000\n",
            "139839/139839 [==============================] - 12s 85us/step - loss: 0.3647 - acc: 0.8724 - categorical_crossentropy: 0.3647 - val_loss: 0.3561 - val_acc: 0.8784 - val_categorical_crossentropy: 0.3561\n",
            "Epoch 511/1000\n",
            "139839/139839 [==============================] - 12s 84us/step - loss: 0.3651 - acc: 0.8725 - categorical_crossentropy: 0.3651 - val_loss: 0.3717 - val_acc: 0.8723 - val_categorical_crossentropy: 0.3717\n",
            "Epoch 512/1000\n",
            "139839/139839 [==============================] - 12s 84us/step - loss: 0.3664 - acc: 0.8715 - categorical_crossentropy: 0.3664 - val_loss: 0.3712 - val_acc: 0.8699 - val_categorical_crossentropy: 0.3712\n",
            "Epoch 513/1000\n",
            "139839/139839 [==============================] - 11s 82us/step - loss: 0.3651 - acc: 0.8723 - categorical_crossentropy: 0.3651 - val_loss: 0.3817 - val_acc: 0.8692 - val_categorical_crossentropy: 0.3817\n",
            "Epoch 514/1000\n",
            "139839/139839 [==============================] - 12s 84us/step - loss: 0.3657 - acc: 0.8715 - categorical_crossentropy: 0.3657 - val_loss: 0.3481 - val_acc: 0.8809 - val_categorical_crossentropy: 0.3481\n",
            "Epoch 515/1000\n",
            "139839/139839 [==============================] - 12s 84us/step - loss: 0.3651 - acc: 0.8726 - categorical_crossentropy: 0.3651 - val_loss: 0.3734 - val_acc: 0.8707 - val_categorical_crossentropy: 0.3734\n",
            "Epoch 516/1000\n",
            "139839/139839 [==============================] - 12s 84us/step - loss: 0.3645 - acc: 0.8719 - categorical_crossentropy: 0.3645 - val_loss: 0.3643 - val_acc: 0.8742 - val_categorical_crossentropy: 0.3643\n",
            "Epoch 517/1000\n",
            "139839/139839 [==============================] - 12s 83us/step - loss: 0.3643 - acc: 0.8722 - categorical_crossentropy: 0.3643 - val_loss: 0.3649 - val_acc: 0.8751 - val_categorical_crossentropy: 0.3649\n",
            "Epoch 518/1000\n",
            "139839/139839 [==============================] - 12s 84us/step - loss: 0.3643 - acc: 0.8726 - categorical_crossentropy: 0.3643 - val_loss: 0.3715 - val_acc: 0.8726 - val_categorical_crossentropy: 0.3715\n",
            "Epoch 519/1000\n",
            "139839/139839 [==============================] - 12s 84us/step - loss: 0.3629 - acc: 0.8730 - categorical_crossentropy: 0.3629 - val_loss: 0.3877 - val_acc: 0.8648 - val_categorical_crossentropy: 0.3877\n",
            "Epoch 520/1000\n",
            "139839/139839 [==============================] - 12s 84us/step - loss: 0.3662 - acc: 0.8713 - categorical_crossentropy: 0.3662 - val_loss: 0.3804 - val_acc: 0.8693 - val_categorical_crossentropy: 0.3804\n",
            "Epoch 521/1000\n",
            "139839/139839 [==============================] - 12s 83us/step - loss: 0.3643 - acc: 0.8724 - categorical_crossentropy: 0.3643 - val_loss: 0.3598 - val_acc: 0.8776 - val_categorical_crossentropy: 0.3598\n",
            "Epoch 522/1000\n",
            "139839/139839 [==============================] - 12s 84us/step - loss: 0.3661 - acc: 0.8719 - categorical_crossentropy: 0.3661 - val_loss: 0.3701 - val_acc: 0.8726 - val_categorical_crossentropy: 0.3701\n",
            "Epoch 523/1000\n",
            "139839/139839 [==============================] - 12s 83us/step - loss: 0.3647 - acc: 0.8731 - categorical_crossentropy: 0.3647 - val_loss: 0.3708 - val_acc: 0.8742 - val_categorical_crossentropy: 0.3708\n",
            "Epoch 524/1000\n",
            "139839/139839 [==============================] - 12s 83us/step - loss: 0.3660 - acc: 0.8713 - categorical_crossentropy: 0.3660 - val_loss: 0.3732 - val_acc: 0.8707 - val_categorical_crossentropy: 0.3732\n",
            "Epoch 525/1000\n",
            "139839/139839 [==============================] - 12s 85us/step - loss: 0.3649 - acc: 0.8721 - categorical_crossentropy: 0.3649 - val_loss: 0.3945 - val_acc: 0.8642 - val_categorical_crossentropy: 0.3945\n",
            "Epoch 526/1000\n",
            "139839/139839 [==============================] - 12s 84us/step - loss: 0.3659 - acc: 0.8712 - categorical_crossentropy: 0.3659 - val_loss: 0.3739 - val_acc: 0.8716 - val_categorical_crossentropy: 0.3739\n",
            "Epoch 527/1000\n",
            "139839/139839 [==============================] - 12s 85us/step - loss: 0.3649 - acc: 0.8717 - categorical_crossentropy: 0.3649 - val_loss: 0.3684 - val_acc: 0.8725 - val_categorical_crossentropy: 0.3684\n",
            "Epoch 528/1000\n",
            "139839/139839 [==============================] - 12s 85us/step - loss: 0.3665 - acc: 0.8715 - categorical_crossentropy: 0.3665 - val_loss: 0.3905 - val_acc: 0.8665 - val_categorical_crossentropy: 0.3905\n",
            "Epoch 529/1000\n",
            "139839/139839 [==============================] - 12s 83us/step - loss: 0.3627 - acc: 0.8726 - categorical_crossentropy: 0.3627 - val_loss: 0.4619 - val_acc: 0.8311 - val_categorical_crossentropy: 0.4619\n",
            "Epoch 530/1000\n",
            "139839/139839 [==============================] - 12s 84us/step - loss: 0.3651 - acc: 0.8724 - categorical_crossentropy: 0.3651 - val_loss: 0.3788 - val_acc: 0.8671 - val_categorical_crossentropy: 0.3788\n",
            "Epoch 531/1000\n",
            "139839/139839 [==============================] - 12s 84us/step - loss: 0.3639 - acc: 0.8725 - categorical_crossentropy: 0.3639 - val_loss: 0.3568 - val_acc: 0.8773 - val_categorical_crossentropy: 0.3568\n",
            "Epoch 532/1000\n",
            "139839/139839 [==============================] - 12s 84us/step - loss: 0.3641 - acc: 0.8723 - categorical_crossentropy: 0.3641 - val_loss: 0.3880 - val_acc: 0.8699 - val_categorical_crossentropy: 0.3880\n",
            "Epoch 533/1000\n",
            "139839/139839 [==============================] - 12s 83us/step - loss: 0.3653 - acc: 0.8719 - categorical_crossentropy: 0.3653 - val_loss: 0.3689 - val_acc: 0.8728 - val_categorical_crossentropy: 0.3689\n",
            "Epoch 534/1000\n",
            "139839/139839 [==============================] - 12s 83us/step - loss: 0.3659 - acc: 0.8712 - categorical_crossentropy: 0.3659 - val_loss: 0.3621 - val_acc: 0.8755 - val_categorical_crossentropy: 0.3621\n",
            "Epoch 535/1000\n",
            "139839/139839 [==============================] - 12s 84us/step - loss: 0.3646 - acc: 0.8722 - categorical_crossentropy: 0.3646 - val_loss: 0.3681 - val_acc: 0.8724 - val_categorical_crossentropy: 0.3681\n",
            "Epoch 536/1000\n",
            "139839/139839 [==============================] - 12s 82us/step - loss: 0.3656 - acc: 0.8717 - categorical_crossentropy: 0.3656 - val_loss: 0.3747 - val_acc: 0.8717 - val_categorical_crossentropy: 0.3747\n",
            "Epoch 537/1000\n",
            "139839/139839 [==============================] - 12s 85us/step - loss: 0.3650 - acc: 0.8723 - categorical_crossentropy: 0.3650 - val_loss: 0.3615 - val_acc: 0.8752 - val_categorical_crossentropy: 0.3615\n",
            "Epoch 538/1000\n",
            "139839/139839 [==============================] - 12s 84us/step - loss: 0.3654 - acc: 0.8718 - categorical_crossentropy: 0.3654 - val_loss: 0.3579 - val_acc: 0.8789 - val_categorical_crossentropy: 0.3579\n",
            "Epoch 539/1000\n",
            "139839/139839 [==============================] - 12s 84us/step - loss: 0.3640 - acc: 0.8730 - categorical_crossentropy: 0.3640 - val_loss: 0.3732 - val_acc: 0.8718 - val_categorical_crossentropy: 0.3732\n",
            "Epoch 540/1000\n",
            "139839/139839 [==============================] - 12s 84us/step - loss: 0.3647 - acc: 0.8718 - categorical_crossentropy: 0.3647 - val_loss: 0.3853 - val_acc: 0.8678 - val_categorical_crossentropy: 0.3853\n",
            "Epoch 541/1000\n",
            "139839/139839 [==============================] - 12s 83us/step - loss: 0.3663 - acc: 0.8718 - categorical_crossentropy: 0.3663 - val_loss: 0.3654 - val_acc: 0.8744 - val_categorical_crossentropy: 0.3654\n",
            "Epoch 542/1000\n",
            "139839/139839 [==============================] - 12s 84us/step - loss: 0.3646 - acc: 0.8724 - categorical_crossentropy: 0.3646 - val_loss: 0.3648 - val_acc: 0.8748 - val_categorical_crossentropy: 0.3648\n",
            "Epoch 543/1000\n",
            "139839/139839 [==============================] - 12s 84us/step - loss: 0.3639 - acc: 0.8721 - categorical_crossentropy: 0.3639 - val_loss: 0.3769 - val_acc: 0.8717 - val_categorical_crossentropy: 0.3769\n",
            "Epoch 544/1000\n",
            "139839/139839 [==============================] - 12s 84us/step - loss: 0.3652 - acc: 0.8724 - categorical_crossentropy: 0.3652 - val_loss: 0.3696 - val_acc: 0.8737 - val_categorical_crossentropy: 0.3696\n",
            "Epoch 545/1000\n",
            "139839/139839 [==============================] - 12s 84us/step - loss: 0.3642 - acc: 0.8726 - categorical_crossentropy: 0.3642 - val_loss: 0.4082 - val_acc: 0.8626 - val_categorical_crossentropy: 0.4082\n",
            "Epoch 546/1000\n",
            "139839/139839 [==============================] - 12s 83us/step - loss: 0.3631 - acc: 0.8732 - categorical_crossentropy: 0.3631 - val_loss: 0.3726 - val_acc: 0.8709 - val_categorical_crossentropy: 0.3726\n",
            "Epoch 547/1000\n",
            "139839/139839 [==============================] - 12s 85us/step - loss: 0.3648 - acc: 0.8724 - categorical_crossentropy: 0.3648 - val_loss: 0.3703 - val_acc: 0.8710 - val_categorical_crossentropy: 0.3703\n",
            "Epoch 548/1000\n",
            "139839/139839 [==============================] - 11s 82us/step - loss: 0.3644 - acc: 0.8720 - categorical_crossentropy: 0.3644 - val_loss: 0.3589 - val_acc: 0.8772 - val_categorical_crossentropy: 0.3589\n",
            "Epoch 549/1000\n",
            "139839/139839 [==============================] - 12s 83us/step - loss: 0.3623 - acc: 0.8725 - categorical_crossentropy: 0.3623 - val_loss: 0.3629 - val_acc: 0.8749 - val_categorical_crossentropy: 0.3629\n",
            "Epoch 550/1000\n",
            "139839/139839 [==============================] - 12s 83us/step - loss: 0.3636 - acc: 0.8726 - categorical_crossentropy: 0.3636 - val_loss: 0.3863 - val_acc: 0.8662 - val_categorical_crossentropy: 0.3863\n",
            "Epoch 551/1000\n",
            "139839/139839 [==============================] - 12s 85us/step - loss: 0.3632 - acc: 0.8726 - categorical_crossentropy: 0.3632 - val_loss: 0.3516 - val_acc: 0.8796 - val_categorical_crossentropy: 0.3516\n",
            "Epoch 552/1000\n",
            "139839/139839 [==============================] - 12s 84us/step - loss: 0.3669 - acc: 0.8715 - categorical_crossentropy: 0.3669 - val_loss: 0.3606 - val_acc: 0.8772 - val_categorical_crossentropy: 0.3606\n",
            "Epoch 553/1000\n",
            "139839/139839 [==============================] - 12s 84us/step - loss: 0.3636 - acc: 0.8729 - categorical_crossentropy: 0.3636 - val_loss: 0.3762 - val_acc: 0.8699 - val_categorical_crossentropy: 0.3762\n",
            "Epoch 554/1000\n",
            "139839/139839 [==============================] - 12s 85us/step - loss: 0.3641 - acc: 0.8726 - categorical_crossentropy: 0.3641 - val_loss: 0.3520 - val_acc: 0.8783 - val_categorical_crossentropy: 0.3520\n",
            "Epoch 555/1000\n",
            "139839/139839 [==============================] - 12s 84us/step - loss: 0.3632 - acc: 0.8719 - categorical_crossentropy: 0.3632 - val_loss: 0.3557 - val_acc: 0.8767 - val_categorical_crossentropy: 0.3557\n",
            "Epoch 556/1000\n",
            "139839/139839 [==============================] - 12s 84us/step - loss: 0.3641 - acc: 0.8729 - categorical_crossentropy: 0.3641 - val_loss: 0.3694 - val_acc: 0.8748 - val_categorical_crossentropy: 0.3694\n",
            "Epoch 557/1000\n",
            "139839/139839 [==============================] - 12s 84us/step - loss: 0.3628 - acc: 0.8730 - categorical_crossentropy: 0.3628 - val_loss: 0.3589 - val_acc: 0.8760 - val_categorical_crossentropy: 0.3589\n",
            "Epoch 558/1000\n",
            "139839/139839 [==============================] - 12s 83us/step - loss: 0.3616 - acc: 0.8736 - categorical_crossentropy: 0.3616 - val_loss: 0.3828 - val_acc: 0.8675 - val_categorical_crossentropy: 0.3828\n",
            "Epoch 559/1000\n",
            "139839/139839 [==============================] - 12s 84us/step - loss: 0.3645 - acc: 0.8721 - categorical_crossentropy: 0.3645 - val_loss: 0.3582 - val_acc: 0.8766 - val_categorical_crossentropy: 0.3582\n",
            "Epoch 560/1000\n",
            "139839/139839 [==============================] - 12s 84us/step - loss: 0.3649 - acc: 0.8727 - categorical_crossentropy: 0.3649 - val_loss: 0.3812 - val_acc: 0.8694 - val_categorical_crossentropy: 0.3812\n",
            "Epoch 561/1000\n",
            "139839/139839 [==============================] - 12s 85us/step - loss: 0.3645 - acc: 0.8728 - categorical_crossentropy: 0.3645 - val_loss: 0.3565 - val_acc: 0.8774 - val_categorical_crossentropy: 0.3565\n",
            "Epoch 562/1000\n",
            "139839/139839 [==============================] - 12s 83us/step - loss: 0.3638 - acc: 0.8731 - categorical_crossentropy: 0.3638 - val_loss: 0.3631 - val_acc: 0.8740 - val_categorical_crossentropy: 0.3631\n",
            "Epoch 563/1000\n",
            "139839/139839 [==============================] - 12s 85us/step - loss: 0.3629 - acc: 0.8739 - categorical_crossentropy: 0.3629 - val_loss: 0.3784 - val_acc: 0.8690 - val_categorical_crossentropy: 0.3784\n",
            "Epoch 564/1000\n",
            "139839/139839 [==============================] - 11s 82us/step - loss: 0.3632 - acc: 0.8731 - categorical_crossentropy: 0.3632 - val_loss: 0.3538 - val_acc: 0.8784 - val_categorical_crossentropy: 0.3538\n",
            "Epoch 565/1000\n",
            "139839/139839 [==============================] - 12s 84us/step - loss: 0.3629 - acc: 0.8733 - categorical_crossentropy: 0.3629 - val_loss: 0.3612 - val_acc: 0.8762 - val_categorical_crossentropy: 0.3612\n",
            "Epoch 566/1000\n",
            "139839/139839 [==============================] - 12s 86us/step - loss: 0.3618 - acc: 0.8736 - categorical_crossentropy: 0.3618 - val_loss: 0.3628 - val_acc: 0.8747 - val_categorical_crossentropy: 0.3628\n",
            "Epoch 567/1000\n",
            "139839/139839 [==============================] - 12s 85us/step - loss: 0.3634 - acc: 0.8729 - categorical_crossentropy: 0.3634 - val_loss: 0.3617 - val_acc: 0.8768 - val_categorical_crossentropy: 0.3617\n",
            "Epoch 568/1000\n",
            "139839/139839 [==============================] - 12s 84us/step - loss: 0.3623 - acc: 0.8735 - categorical_crossentropy: 0.3623 - val_loss: 0.3735 - val_acc: 0.8728 - val_categorical_crossentropy: 0.3735\n",
            "Epoch 569/1000\n",
            "139839/139839 [==============================] - 12s 83us/step - loss: 0.3632 - acc: 0.8730 - categorical_crossentropy: 0.3632 - val_loss: 0.3770 - val_acc: 0.8720 - val_categorical_crossentropy: 0.3770\n",
            "Epoch 570/1000\n",
            "139839/139839 [==============================] - 12s 85us/step - loss: 0.3640 - acc: 0.8725 - categorical_crossentropy: 0.3640 - val_loss: 0.3713 - val_acc: 0.8704 - val_categorical_crossentropy: 0.3713\n",
            "Epoch 571/1000\n",
            "139839/139839 [==============================] - 12s 84us/step - loss: 0.3633 - acc: 0.8722 - categorical_crossentropy: 0.3633 - val_loss: 0.3570 - val_acc: 0.8782 - val_categorical_crossentropy: 0.3570\n",
            "Epoch 572/1000\n",
            "139839/139839 [==============================] - 12s 84us/step - loss: 0.3637 - acc: 0.8725 - categorical_crossentropy: 0.3637 - val_loss: 0.3815 - val_acc: 0.8675 - val_categorical_crossentropy: 0.3815\n",
            "Epoch 573/1000\n",
            "139839/139839 [==============================] - 12s 86us/step - loss: 0.3635 - acc: 0.8728 - categorical_crossentropy: 0.3635 - val_loss: 0.3726 - val_acc: 0.8715 - val_categorical_crossentropy: 0.3726\n",
            "Epoch 574/1000\n",
            "139839/139839 [==============================] - 12s 83us/step - loss: 0.3624 - acc: 0.8734 - categorical_crossentropy: 0.3624 - val_loss: 0.3773 - val_acc: 0.8700 - val_categorical_crossentropy: 0.3773\n",
            "Epoch 575/1000\n",
            "139839/139839 [==============================] - 12s 85us/step - loss: 0.3640 - acc: 0.8724 - categorical_crossentropy: 0.3640 - val_loss: 0.3606 - val_acc: 0.8773 - val_categorical_crossentropy: 0.3606\n",
            "Epoch 576/1000\n",
            "139839/139839 [==============================] - 12s 87us/step - loss: 0.3634 - acc: 0.8731 - categorical_crossentropy: 0.3634 - val_loss: 0.3680 - val_acc: 0.8732 - val_categorical_crossentropy: 0.3680\n",
            "Epoch 577/1000\n",
            "139839/139839 [==============================] - 12s 83us/step - loss: 0.3615 - acc: 0.8729 - categorical_crossentropy: 0.3615 - val_loss: 0.3785 - val_acc: 0.8689 - val_categorical_crossentropy: 0.3785\n",
            "Epoch 578/1000\n",
            "139839/139839 [==============================] - 12s 84us/step - loss: 0.3614 - acc: 0.8737 - categorical_crossentropy: 0.3614 - val_loss: 0.3643 - val_acc: 0.8745 - val_categorical_crossentropy: 0.3643\n",
            "Epoch 579/1000\n",
            "139839/139839 [==============================] - 12s 82us/step - loss: 0.3634 - acc: 0.8726 - categorical_crossentropy: 0.3634 - val_loss: 0.4150 - val_acc: 0.8483 - val_categorical_crossentropy: 0.4150\n",
            "Epoch 580/1000\n",
            "139839/139839 [==============================] - 12s 86us/step - loss: 0.3633 - acc: 0.8724 - categorical_crossentropy: 0.3633 - val_loss: 0.3636 - val_acc: 0.8756 - val_categorical_crossentropy: 0.3636\n",
            "Epoch 581/1000\n",
            "139839/139839 [==============================] - 12s 84us/step - loss: 0.3622 - acc: 0.8732 - categorical_crossentropy: 0.3622 - val_loss: 0.3554 - val_acc: 0.8764 - val_categorical_crossentropy: 0.3554\n",
            "Epoch 582/1000\n",
            "139839/139839 [==============================] - 12s 82us/step - loss: 0.3637 - acc: 0.8729 - categorical_crossentropy: 0.3637 - val_loss: 0.3626 - val_acc: 0.8755 - val_categorical_crossentropy: 0.3626\n",
            "Epoch 583/1000\n",
            "139839/139839 [==============================] - 12s 84us/step - loss: 0.3617 - acc: 0.8729 - categorical_crossentropy: 0.3617 - val_loss: 0.3831 - val_acc: 0.8699 - val_categorical_crossentropy: 0.3831\n",
            "Epoch 584/1000\n",
            "139839/139839 [==============================] - 11s 80us/step - loss: 0.3628 - acc: 0.8728 - categorical_crossentropy: 0.3628 - val_loss: 0.3602 - val_acc: 0.8750 - val_categorical_crossentropy: 0.3602\n",
            "Epoch 585/1000\n",
            "139839/139839 [==============================] - 12s 83us/step - loss: 0.3618 - acc: 0.8733 - categorical_crossentropy: 0.3618 - val_loss: 0.3597 - val_acc: 0.8776 - val_categorical_crossentropy: 0.3597\n",
            "Epoch 586/1000\n",
            "139839/139839 [==============================] - 12s 83us/step - loss: 0.3620 - acc: 0.8726 - categorical_crossentropy: 0.3620 - val_loss: 0.3752 - val_acc: 0.8723 - val_categorical_crossentropy: 0.3752\n",
            "Epoch 587/1000\n",
            "139839/139839 [==============================] - 12s 84us/step - loss: 0.3629 - acc: 0.8723 - categorical_crossentropy: 0.3629 - val_loss: 0.3678 - val_acc: 0.8729 - val_categorical_crossentropy: 0.3678\n",
            "Epoch 588/1000\n",
            "139839/139839 [==============================] - 12s 84us/step - loss: 0.3649 - acc: 0.8716 - categorical_crossentropy: 0.3649 - val_loss: 0.3835 - val_acc: 0.8664 - val_categorical_crossentropy: 0.3835\n",
            "Epoch 589/1000\n",
            "139839/139839 [==============================] - 12s 83us/step - loss: 0.3603 - acc: 0.8737 - categorical_crossentropy: 0.3603 - val_loss: 0.3764 - val_acc: 0.8703 - val_categorical_crossentropy: 0.3764\n",
            "Epoch 590/1000\n",
            "139839/139839 [==============================] - 12s 83us/step - loss: 0.3633 - acc: 0.8725 - categorical_crossentropy: 0.3633 - val_loss: 0.3952 - val_acc: 0.8683 - val_categorical_crossentropy: 0.3952\n",
            "Epoch 591/1000\n",
            "139839/139839 [==============================] - 12s 82us/step - loss: 0.3633 - acc: 0.8731 - categorical_crossentropy: 0.3633 - val_loss: 0.3735 - val_acc: 0.8723 - val_categorical_crossentropy: 0.3735\n",
            "Epoch 592/1000\n",
            "139839/139839 [==============================] - 12s 83us/step - loss: 0.3634 - acc: 0.8724 - categorical_crossentropy: 0.3634 - val_loss: 0.3829 - val_acc: 0.8690 - val_categorical_crossentropy: 0.3829\n",
            "Epoch 593/1000\n",
            "139839/139839 [==============================] - 12s 83us/step - loss: 0.3633 - acc: 0.8721 - categorical_crossentropy: 0.3633 - val_loss: 0.3533 - val_acc: 0.8780 - val_categorical_crossentropy: 0.3533\n",
            "Epoch 594/1000\n",
            "139839/139839 [==============================] - 12s 83us/step - loss: 0.3625 - acc: 0.8727 - categorical_crossentropy: 0.3625 - val_loss: 0.3766 - val_acc: 0.8691 - val_categorical_crossentropy: 0.3766\n",
            "Epoch 595/1000\n",
            "139839/139839 [==============================] - 11s 82us/step - loss: 0.3613 - acc: 0.8735 - categorical_crossentropy: 0.3613 - val_loss: 0.3547 - val_acc: 0.8784 - val_categorical_crossentropy: 0.3547\n",
            "Epoch 596/1000\n",
            "139839/139839 [==============================] - 12s 83us/step - loss: 0.3625 - acc: 0.8727 - categorical_crossentropy: 0.3625 - val_loss: 0.3809 - val_acc: 0.8689 - val_categorical_crossentropy: 0.3809\n",
            "Epoch 597/1000\n",
            "139839/139839 [==============================] - 12s 83us/step - loss: 0.3628 - acc: 0.8729 - categorical_crossentropy: 0.3628 - val_loss: 0.3573 - val_acc: 0.8794 - val_categorical_crossentropy: 0.3573\n",
            "Epoch 598/1000\n",
            "139839/139839 [==============================] - 12s 84us/step - loss: 0.3627 - acc: 0.8730 - categorical_crossentropy: 0.3627 - val_loss: 0.3592 - val_acc: 0.8774 - val_categorical_crossentropy: 0.3592\n",
            "Epoch 599/1000\n",
            "139839/139839 [==============================] - 12s 86us/step - loss: 0.3618 - acc: 0.8731 - categorical_crossentropy: 0.3618 - val_loss: 0.3614 - val_acc: 0.8763 - val_categorical_crossentropy: 0.3614\n",
            "Epoch 600/1000\n",
            "139839/139839 [==============================] - 12s 85us/step - loss: 0.3629 - acc: 0.8729 - categorical_crossentropy: 0.3629 - val_loss: 0.3536 - val_acc: 0.8786 - val_categorical_crossentropy: 0.3536\n",
            "Epoch 601/1000\n",
            "139839/139839 [==============================] - 12s 86us/step - loss: 0.3635 - acc: 0.8726 - categorical_crossentropy: 0.3635 - val_loss: 0.3714 - val_acc: 0.8735 - val_categorical_crossentropy: 0.3714\n",
            "Epoch 602/1000\n",
            "139839/139839 [==============================] - 12s 86us/step - loss: 0.3631 - acc: 0.8726 - categorical_crossentropy: 0.3631 - val_loss: 0.3712 - val_acc: 0.8734 - val_categorical_crossentropy: 0.3712\n",
            "Epoch 603/1000\n",
            "139839/139839 [==============================] - 12s 85us/step - loss: 0.3608 - acc: 0.8738 - categorical_crossentropy: 0.3608 - val_loss: 0.3662 - val_acc: 0.8739 - val_categorical_crossentropy: 0.3662\n",
            "Epoch 604/1000\n",
            "139839/139839 [==============================] - 12s 86us/step - loss: 0.3604 - acc: 0.8740 - categorical_crossentropy: 0.3604 - val_loss: 0.3537 - val_acc: 0.8788 - val_categorical_crossentropy: 0.3537\n",
            "Epoch 605/1000\n",
            "139839/139839 [==============================] - 12s 83us/step - loss: 0.3596 - acc: 0.8745 - categorical_crossentropy: 0.3596 - val_loss: 0.3651 - val_acc: 0.8756 - val_categorical_crossentropy: 0.3651\n",
            "Epoch 606/1000\n",
            "139839/139839 [==============================] - 12s 86us/step - loss: 0.3626 - acc: 0.8731 - categorical_crossentropy: 0.3626 - val_loss: 0.3725 - val_acc: 0.8720 - val_categorical_crossentropy: 0.3725\n",
            "Epoch 607/1000\n",
            "139839/139839 [==============================] - 13s 90us/step - loss: 0.3609 - acc: 0.8733 - categorical_crossentropy: 0.3609 - val_loss: 0.3735 - val_acc: 0.8724 - val_categorical_crossentropy: 0.3735\n",
            "Epoch 608/1000\n",
            "139839/139839 [==============================] - 12s 84us/step - loss: 0.3638 - acc: 0.8729 - categorical_crossentropy: 0.3638 - val_loss: 0.3713 - val_acc: 0.8719 - val_categorical_crossentropy: 0.3713\n",
            "Epoch 609/1000\n",
            "139839/139839 [==============================] - 12s 83us/step - loss: 0.3623 - acc: 0.8726 - categorical_crossentropy: 0.3623 - val_loss: 0.3618 - val_acc: 0.8755 - val_categorical_crossentropy: 0.3618\n",
            "Epoch 610/1000\n",
            "139839/139839 [==============================] - 11s 81us/step - loss: 0.3628 - acc: 0.8721 - categorical_crossentropy: 0.3628 - val_loss: 0.3699 - val_acc: 0.8722 - val_categorical_crossentropy: 0.3699\n",
            "Epoch 611/1000\n",
            "139839/139839 [==============================] - 12s 84us/step - loss: 0.3621 - acc: 0.8730 - categorical_crossentropy: 0.3621 - val_loss: 0.3547 - val_acc: 0.8782 - val_categorical_crossentropy: 0.3547\n",
            "Epoch 612/1000\n",
            "139839/139839 [==============================] - 12s 84us/step - loss: 0.3614 - acc: 0.8724 - categorical_crossentropy: 0.3614 - val_loss: 0.3633 - val_acc: 0.8750 - val_categorical_crossentropy: 0.3633\n",
            "Epoch 613/1000\n",
            "139839/139839 [==============================] - 12s 85us/step - loss: 0.3613 - acc: 0.8742 - categorical_crossentropy: 0.3613 - val_loss: 0.3585 - val_acc: 0.8772 - val_categorical_crossentropy: 0.3585\n",
            "Epoch 614/1000\n",
            "139839/139839 [==============================] - 12s 84us/step - loss: 0.3611 - acc: 0.8735 - categorical_crossentropy: 0.3611 - val_loss: 0.3578 - val_acc: 0.8786 - val_categorical_crossentropy: 0.3578\n",
            "Epoch 615/1000\n",
            "139839/139839 [==============================] - 11s 81us/step - loss: 0.3627 - acc: 0.8725 - categorical_crossentropy: 0.3627 - val_loss: 0.3675 - val_acc: 0.8728 - val_categorical_crossentropy: 0.3675\n",
            "Epoch 616/1000\n",
            "139839/139839 [==============================] - 12s 83us/step - loss: 0.3630 - acc: 0.8730 - categorical_crossentropy: 0.3630 - val_loss: 0.3550 - val_acc: 0.8788 - val_categorical_crossentropy: 0.3550\n",
            "Epoch 617/1000\n",
            "139839/139839 [==============================] - 12s 83us/step - loss: 0.3644 - acc: 0.8728 - categorical_crossentropy: 0.3644 - val_loss: 0.3759 - val_acc: 0.8709 - val_categorical_crossentropy: 0.3759\n",
            "Epoch 618/1000\n",
            "139839/139839 [==============================] - 12s 83us/step - loss: 0.3618 - acc: 0.8731 - categorical_crossentropy: 0.3618 - val_loss: 0.3628 - val_acc: 0.8762 - val_categorical_crossentropy: 0.3628\n",
            "Epoch 619/1000\n",
            "139839/139839 [==============================] - 12s 84us/step - loss: 0.3612 - acc: 0.8731 - categorical_crossentropy: 0.3612 - val_loss: 0.3890 - val_acc: 0.8622 - val_categorical_crossentropy: 0.3890\n",
            "Epoch 620/1000\n",
            "139839/139839 [==============================] - 11s 81us/step - loss: 0.3612 - acc: 0.8738 - categorical_crossentropy: 0.3612 - val_loss: 0.3743 - val_acc: 0.8689 - val_categorical_crossentropy: 0.3743\n",
            "Epoch 621/1000\n",
            "139839/139839 [==============================] - 12s 83us/step - loss: 0.3619 - acc: 0.8729 - categorical_crossentropy: 0.3619 - val_loss: 0.3752 - val_acc: 0.8709 - val_categorical_crossentropy: 0.3752\n",
            "Epoch 622/1000\n",
            "139839/139839 [==============================] - 12s 84us/step - loss: 0.3615 - acc: 0.8736 - categorical_crossentropy: 0.3615 - val_loss: 0.3654 - val_acc: 0.8745 - val_categorical_crossentropy: 0.3654\n",
            "Epoch 623/1000\n",
            "139839/139839 [==============================] - 12s 82us/step - loss: 0.3610 - acc: 0.8734 - categorical_crossentropy: 0.3610 - val_loss: 0.3670 - val_acc: 0.8750 - val_categorical_crossentropy: 0.3670\n",
            "Epoch 624/1000\n",
            "139839/139839 [==============================] - 12s 83us/step - loss: 0.3613 - acc: 0.8731 - categorical_crossentropy: 0.3613 - val_loss: 0.3631 - val_acc: 0.8754 - val_categorical_crossentropy: 0.3631\n",
            "Epoch 00624: early stopping\n",
            "59931/59931 [==============================] - 6s 96us/step\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.36305248505106735, 0.8753733460106052, 0.36305248505106735]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 109
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "04uzx-RuIdI-",
        "outputId": "273a533f-9fed-4d57-a849-920d9da11270",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "### 최적 모델 불러오기\n",
        "best_model = keras.models.load_model('best_model.h5')\n",
        "val_loss, val_acc, val_category = best_model.evaluate(X_test, y_test)"
      ],
      "execution_count": 110,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "59931/59931 [==============================] - 7s 118us/sample - loss: 0.3481 - acc: 0.8809 - categorical_crossentropy: 0.3481\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iv59_h-y2G_L",
        "colab_type": "code",
        "outputId": "08c6fe7b-124b-4202-84c2-c43fdb4976bf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 542
        }
      },
      "source": [
        "## 그래프로 수치 명확하게 나타내주기\n",
        "import plotly.graph_objects as go\n",
        "fig = go.Figure()\n",
        "fig.add_trace(go.Scatter(y=history.history['loss'],\n",
        "                    mode='lines',\n",
        "                    name='loss'))\n",
        "fig.add_trace(go.Scatter(y=history.history['val_loss'],\n",
        "                    mode='lines',\n",
        "                    name='val_loss'))\n",
        "fig.add_trace(go.Scatter(y=history.history['val_acc'],\n",
        "                    mode='lines',\n",
        "                    name='val_acc'))\n",
        "fig.show()"
      ],
      "execution_count": 111,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<html>\n",
              "<head><meta charset=\"utf-8\" /></head>\n",
              "<body>\n",
              "    <div>\n",
              "            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>\n",
              "                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
              "        <script src=\"https://cdn.plot.ly/plotly-latest.min.js\"></script>    \n",
              "            <div id=\"7753077e-8867-4cad-834d-ede8909d60d8\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>\n",
              "            <script type=\"text/javascript\">\n",
              "                \n",
              "                    window.PLOTLYENV=window.PLOTLYENV || {};\n",
              "                    \n",
              "                if (document.getElementById(\"7753077e-8867-4cad-834d-ede8909d60d8\")) {\n",
              "                    Plotly.newPlot(\n",
              "                        '7753077e-8867-4cad-834d-ede8909d60d8',\n",
              "                        [{\"mode\": \"lines\", \"name\": \"loss\", \"type\": \"scatter\", \"y\": [1.1479969594993997, 0.6710858273709395, 0.6041518917118794, 0.572993267971086, 0.5546690976955851, 0.5362471164631277, 0.5267369427826759, 0.5172107903274653, 0.5084340534485964, 0.5018704878759122, 0.4976482798094686, 0.4899156571000614, 0.4892778811791739, 0.48321912417692164, 0.4775045290979873, 0.4770905863232903, 0.47424388301030773, 0.4711490244380666, 0.4667343340258886, 0.46485075025627215, 0.4630784680401873, 0.46316164861939224, 0.4594524952294259, 0.456651308099653, 0.4549967841483188, 0.4539706383089966, 0.4522552778486101, 0.4502306884672596, 0.4493990390669139, 0.446360863959024, 0.4453826840679203, 0.44343597764792037, 0.44479060818806, 0.44447048299061404, 0.44060332707288774, 0.4400521295508002, 0.4390776154284665, 0.43813619977296364, 0.4372863373488288, 0.43733063331001654, 0.43406235028723567, 0.43407756731523955, 0.43430047791247767, 0.4307511163898997, 0.43374630891754795, 0.4304325809552601, 0.4305033184128311, 0.4288698926179409, 0.4280544221055962, 0.4274058977785875, 0.4283075238805386, 0.4260985456489494, 0.4235796920450036, 0.4257909850796346, 0.42376773637463583, 0.42436972056243394, 0.4259677119181463, 0.4221767651220987, 0.42225189124576534, 0.42264624390449584, 0.4209148325802054, 0.4196194768455352, 0.41905465003809694, 0.42035401341246603, 0.4227842270276444, 0.41682839243111214, 0.41759793481862145, 0.4178942285562244, 0.4173414458233353, 0.41696886284011603, 0.4166779015384412, 0.4148731456785549, 0.41591551432753526, 0.4143825415540641, 0.41557759672143546, 0.4143977693283713, 0.4145623607052797, 0.41282172728282507, 0.414978579664823, 0.41080918464533694, 0.409556072632262, 0.4102065639091384, 0.41155360610356234, 0.4071309533138314, 0.40982570136128516, 0.40803834590910226, 0.4109597442929091, 0.40914629596303975, 0.40679135482405654, 0.41028540743216624, 0.40979282462305944, 0.40828759594843345, 0.40701848843951033, 0.40708986158490795, 0.4055125080021066, 0.40526804766840363, 0.4050997592232431, 0.40605092655095926, 0.4042755835366896, 0.4020254027618507, 0.40581852846828326, 0.40576645953249857, 0.4035721169919263, 0.40414738719793203, 0.40354418017293087, 0.4032747639711079, 0.40238396967932744, 0.40251457226849346, 0.40324181727726954, 0.40182007400718567, 0.40169550502061313, 0.401679564439517, 0.4009621309462921, 0.40314659312519713, 0.4006158249347123, 0.39989917525797464, 0.40153128428759205, 0.3999539591659564, 0.40109978832883575, 0.40014148111792264, 0.4003428059085491, 0.3996038022094362, 0.4011206485692348, 0.3999982609386811, 0.3980473781306497, 0.3974629920390379, 0.39893053668271233, 0.39793753002593174, 0.39707545765047814, 0.39877026583397734, 0.39814105550342394, 0.39985014750918124, 0.39898373682675614, 0.39526998895673676, 0.397134197354662, 0.39738991523640793, 0.39689333870276927, 0.39592812890751206, 0.3962161841676579, 0.3955123230376655, 0.39371534901513533, 0.3948830356708398, 0.3955920561497549, 0.39634569392465724, 0.3943968074238238, 0.39474968350217754, 0.3929640923982449, 0.394305000808247, 0.39226386783803957, 0.39368296928789515, 0.3939979251667201, 0.3944346529522729, 0.3934613083509945, 0.3943114423903742, 0.3933952871084372, 0.39141379551680394, 0.39234398445765506, 0.39232676437916064, 0.39152257001586943, 0.3921195105767712, 0.3903809844015808, 0.39110711766069833, 0.3928237566202345, 0.3912127000733541, 0.3919483791866783, 0.3910671188153032, 0.39170706900271646, 0.3914043300111622, 0.39304856337097394, 0.3910383253543498, 0.3907003831215181, 0.39102947547629974, 0.3895380792510625, 0.3885727400605018, 0.3906073798819266, 0.3903064519080207, 0.38808591220774064, 0.3904843335163556, 0.39046003659180073, 0.3900523981609419, 0.38933867651874277, 0.38831414862058394, 0.38743903493115533, 0.3866141930477508, 0.3894172410903366, 0.38742486588424974, 0.3885366749038544, 0.38851830881685145, 0.3888525239757933, 0.3897785582021574, 0.38754081880095187, 0.38829218381358954, 0.38668999606150517, 0.38587992138239585, 0.388465574348294, 0.38773976075696065, 0.3865502400399925, 0.38543929780893277, 0.3859705218064149, 0.38675809025944335, 0.38609120760466165, 0.38652003078384517, 0.3856875325188866, 0.38553596891395725, 0.3867754839722323, 0.3861743242916974, 0.38538741021019607, 0.3840248435508731, 0.386119161723364, 0.3853636849709031, 0.38612821868001856, 0.3855769622921692, 0.38569008428341406, 0.38368500022295404, 0.38464846199081326, 0.3829569417183379, 0.38388679606243165, 0.38517902168628376, 0.3843105175553986, 0.38342479575511407, 0.3845430948741973, 0.3836666915152092, 0.38290768439390444, 0.3841904761687841, 0.38341277166173277, 0.38413609649690406, 0.3845164603098537, 0.3830705756084095, 0.38384886449066963, 0.38110193303875667, 0.3825789521560062, 0.3823715193171863, 0.3819065948225512, 0.38232110623874704, 0.38207505556511195, 0.3819147199811097, 0.3826195713282629, 0.3826353441758983, 0.3801790486198649, 0.3829474402544367, 0.3811899866278996, 0.38078556517658085, 0.3804552680327764, 0.38199248646151784, 0.38223099550934453, 0.3802927642233144, 0.38131280701815334, 0.3816022289972377, 0.3805140860949954, 0.3812344607841246, 0.38163871271242383, 0.38147256507541344, 0.37970105226962314, 0.3799983097460787, 0.3807060932450128, 0.3797923813988819, 0.3793469592003418, 0.38029619101087164, 0.38119037854679916, 0.3802905904978972, 0.37860130429074373, 0.38034896212542296, 0.38098975018243625, 0.3798238752928534, 0.3800517486575771, 0.3799635352576655, 0.3796906279198287, 0.37896636868374134, 0.3784899456092211, 0.3796350249101295, 0.3783963041947064, 0.3790847559041082, 0.37928807454552516, 0.37844668720762153, 0.3794186717159321, 0.3810127056966581, 0.3797130326024651, 0.37970434364468025, 0.3777986299748311, 0.3773088994258671, 0.3790125098837054, 0.37970167824093665, 0.3785978961951986, 0.37929922366532026, 0.3773523477103662, 0.3776330135091953, 0.37711525391577233, 0.37894214473661086, 0.37826162933180574, 0.3777307002835216, 0.3783611347851888, 0.3764093151688512, 0.37760511938066965, 0.37662740144868634, 0.3772460398472213, 0.3756574858752702, 0.37651014141353467, 0.37632456805743036, 0.3767039029016115, 0.3750273712502436, 0.3773001323758063, 0.3777941394507276, 0.3775804515609604, 0.3761971626571648, 0.3760122624119122, 0.37759038852229704, 0.3763682251429602, 0.3769863112920301, 0.3770508367122117, 0.3759623901979176, 0.3758564375477921, 0.3770587261313078, 0.3748651154684619, 0.375437740910216, 0.3757290594889659, 0.3761589188539736, 0.37578116136844436, 0.3777547413981494, 0.3760892219790811, 0.3745776569518755, 0.3760811784847765, 0.3751207932367709, 0.3757258011522273, 0.37778096903512687, 0.3761438693232948, 0.37534755591444646, 0.37426466065412195, 0.3742092610055956, 0.37521358997658866, 0.3763467040432709, 0.3750828690440349, 0.37481889353589287, 0.3751040169611654, 0.37485029512618623, 0.37396962711089343, 0.3728059523655758, 0.3745381547920334, 0.37577041086715196, 0.37502197233126083, 0.37527655286266337, 0.3747551473629311, 0.37518339031909975, 0.37358073286944415, 0.3758858661298891, 0.3736692514595524, 0.3727101510928591, 0.37521660239871996, 0.3737798026217259, 0.3734853297724759, 0.3745546130551486, 0.37166867412768523, 0.37274731794336674, 0.37166948486939083, 0.37184223071977746, 0.37198432409954885, 0.3735700235533634, 0.37418043728688494, 0.373043857398229, 0.37288477911743134, 0.37408009349163057, 0.37214939098119665, 0.3728891491965824, 0.37529764618855627, 0.37161795180403756, 0.37182728821822153, 0.37237352845210825, 0.37168534573616363, 0.37296558152953374, 0.3730539843950582, 0.3719875075020061, 0.371372011742692, 0.3741748681083441, 0.3729710881120941, 0.37226796071801105, 0.3719463327338926, 0.3735341730506288, 0.37119493526208686, 0.3728444562393655, 0.37237990333060283, 0.37222051041823184, 0.3704529000818399, 0.3729379465961145, 0.37103806567119274, 0.37234321651829805, 0.37232430029522284, 0.37081408910861174, 0.37133861007363694, 0.3700906117246955, 0.3704859419867233, 0.3708300524556994, 0.3701377568140318, 0.37111668906656403, 0.3701894991908354, 0.37091089373406755, 0.37130887113662187, 0.37203591987873735, 0.37046207958117544, 0.3709294941341286, 0.3699811005284347, 0.37218048785377783, 0.3715697244664413, 0.370909303294822, 0.3697927253062633, 0.37017545479286407, 0.3695708321452951, 0.37020635029352345, 0.37014843949303095, 0.3690447605462917, 0.3686182523647274, 0.3688024398078797, 0.3695209949759196, 0.36972966021245274, 0.3700251534830214, 0.36858719895304054, 0.37036535413255733, 0.37019342135816674, 0.36819042314890726, 0.3696144039146735, 0.3689407592710975, 0.37105133492980946, 0.37008316020829385, 0.36925600356915994, 0.3684827597265608, 0.3700190943332358, 0.367585719296462, 0.36845275357222074, 0.3675608240949578, 0.3686491203545179, 0.3693252013043296, 0.3703596203267625, 0.3684630367736351, 0.3687990751210148, 0.37051525177489936, 0.36895590622243724, 0.3687969058736502, 0.3685900842598135, 0.3680560701214223, 0.36846755796063485, 0.3691589988581675, 0.3680183872543126, 0.3673182347469156, 0.36815029846111247, 0.36792141512247417, 0.3687629684605432, 0.3676101345277482, 0.3692183734978685, 0.36766994136239545, 0.36947242195704316, 0.3684659439932849, 0.3695631133013861, 0.36850165024185894, 0.3676244527633674, 0.36711626375936046, 0.3690958110420168, 0.3679341395464557, 0.3670271767259538, 0.3685162195344294, 0.36687900522860895, 0.36817727111246024, 0.36767471057835427, 0.3680054499492471, 0.3680236576893945, 0.3676708767387564, 0.3660133079978704, 0.36647274354680615, 0.3656134206001738, 0.3687634323541431, 0.36773903376902384, 0.3655103171817726, 0.36614997167556385, 0.3690404985635625, 0.3664632503557512, 0.3654939811205615, 0.36788008673064443, 0.3661476314549063, 0.36653500298371294, 0.36586718979143307, 0.3667279587739672, 0.3669953940440493, 0.3681887987210464, 0.36594694261807875, 0.3677273001791821, 0.3667559814670591, 0.36785936181600615, 0.3674575303267138, 0.36719671337563725, 0.3672531602866252, 0.36723743099727946, 0.3661052855756581, 0.36619508428866826, 0.36595132659129803, 0.3660631632569843, 0.36443044410889675, 0.3673034845923389, 0.3666696443091708, 0.36619261462177183, 0.36828512055437795, 0.36599734456063354, 0.36722489083433607, 0.3658024172949335, 0.3657105304904178, 0.3664129358912252, 0.36661702916924943, 0.36638259168334053, 0.3665059618705946, 0.3669229360486372, 0.36632740990746054, 0.36592077709351517, 0.36637691470823597, 0.3647410739791979, 0.36511693648103505, 0.36637765841831915, 0.3651434904485303, 0.3656890577618804, 0.36512677445827113, 0.36446764753421657, 0.36429228755434273, 0.364319480411242, 0.3629359952498434, 0.36618510644911767, 0.364346523420038, 0.36608812440938543, 0.3647008523410954, 0.3659509089046284, 0.36492782947384395, 0.36590696856181204, 0.36491517673919666, 0.36651565418879084, 0.362737991379362, 0.3650527928303956, 0.36391280981271545, 0.3640502060296561, 0.36532238908011083, 0.36587509284778924, 0.36457428626453947, 0.3655965441990034, 0.36496719963811985, 0.36540101692987853, 0.36399875051056846, 0.3646608599205932, 0.3663084944919991, 0.3646324827881033, 0.36393138532817093, 0.36518845582849924, 0.3642147514924595, 0.3630753079064263, 0.3647660598525294, 0.3643609412034571, 0.3622933832754194, 0.36356266068436915, 0.36315915902072887, 0.3669188256860943, 0.36357260541825565, 0.364097077018569, 0.363162328265703, 0.36408274021784987, 0.3627932204460946, 0.3616045254032152, 0.36448869038334364, 0.36494600118476334, 0.3645012580812383, 0.3637590419680166, 0.3629012832167523, 0.3632007869747135, 0.36285498480447076, 0.36182402715174633, 0.3634411559059892, 0.36227355210725803, 0.3631643391836878, 0.363952828295731, 0.3632882372210728, 0.3637490574854459, 0.36351811851777355, 0.362407378071873, 0.3640039186014119, 0.36341357285698556, 0.3614911477667841, 0.3613708986018961, 0.3633875497752857, 0.3633150401104949, 0.3622175394414194, 0.36373341178130053, 0.3616725854610106, 0.36282911994687006, 0.36183761888747945, 0.3620106244679008, 0.3629370558379854, 0.3649177936483926, 0.36034283535110984, 0.3632526465195545, 0.3633158152212916, 0.36343793730813134, 0.36327654169957985, 0.3625350840276403, 0.361282482914078, 0.3625037784588828, 0.3628238855022285, 0.3627028509927913, 0.3618323459076523, 0.3628803857103967, 0.3634798825017308, 0.36305092774938263, 0.3608140127870292, 0.36040614163383106, 0.3596391482874039, 0.36259805495745856, 0.36085226628861844, 0.36379353139338744, 0.3623164221842069, 0.3628445266914342, 0.3621323751398958, 0.36137941827983006, 0.3613340673199676, 0.36105372186727985, 0.36266811495143914, 0.36296019289129194, 0.3643505651355178, 0.36177811834549245, 0.3612281959301293, 0.3612410127711682, 0.3618625903848811, 0.3615483338970155, 0.36103923693779344, 0.3612989887587398]}, {\"mode\": \"lines\", \"name\": \"val_loss\", \"type\": \"scatter\", \"y\": [0.7409208337951264, 0.6067832257954876, 0.5480226353692284, 0.5046100655590797, 0.5035215351406174, 0.6367769081776632, 0.47973332666648216, 0.8203115016751601, 1.6065660721169932, 1.1086576205188978, 1.2568713099043392, 0.6557084135655871, 0.6589381086355105, 0.455304835443532, 0.8856425796232048, 0.8844733585667823, 0.4890442505212567, 0.6868335904545732, 0.737500977344912, 0.44919108176278727, 0.6328370044818241, 0.5422961272016961, 0.49706222916743026, 1.1436016188920428, 0.6567888370392644, 1.1970458151678292, 0.4433965649168546, 0.47492512449416036, 0.425656706120103, 0.5280407330448641, 0.4644038869676787, 0.500085035332813, 0.4290333811723118, 0.5135239027074427, 0.4545476079997589, 0.44772960146228424, 0.40978723774315373, 0.5333320262463686, 0.5059376968578181, 0.4243982673408419, 0.487251971835271, 0.8218844745537717, 1.2101666713210066, 0.6375855472735673, 0.4526413022528, 0.43427068994350027, 0.414097154325559, 0.46639412059561713, 0.6691856930978971, 0.42489106018039086, 0.5066871122362433, 0.41710363549322566, 0.4496941151519263, 0.7395697170350881, 0.7403211562354164, 0.8472080355161493, 0.9529636197096832, 0.4805749282135196, 0.5733496537366651, 0.43105164328996093, 0.509081107768667, 0.8964309514974184, 0.7263986664297059, 0.40137781168207487, 0.5024425406602273, 0.46936916259367817, 0.42345870839111543, 0.555706371090417, 0.5651114428511402, 0.4589443362648715, 0.48143620212134863, 0.45527047989556646, 1.3483844489588683, 0.4149746125429186, 0.4497310181477688, 0.3923121449694979, 0.7076696455364294, 1.0387070084423355, 0.506448138658444, 0.4719896303628949, 0.38647563075709385, 0.4497829541210672, 0.4708179109766578, 0.48199047314691246, 0.43841081420475125, 0.5644650866410429, 0.7089764048193857, 0.42160777540738875, 0.4333078976246853, 0.6027776879623471, 0.8373540476969294, 0.47578547259111137, 0.7480616000972027, 0.39904435669704896, 0.5595742668605627, 0.44777014308692564, 0.5646213189761242, 0.6716615440497157, 0.39673164747955625, 0.39724398469117744, 0.38754865350072587, 0.5781912330833728, 0.8346913285366107, 0.4855031430098692, 0.4587776668840816, 0.46360909308016074, 0.3964067351226126, 0.3952716797711094, 0.43404600866412063, 0.4688481742459004, 0.4740270591307688, 0.45712941513876504, 1.1465156884643835, 0.5770041793572391, 0.5520322869084618, 0.38598391967506324, 0.4000351205106409, 0.4016315121905381, 0.4257781317753157, 0.38856976097271106, 0.7469788117201567, 0.5272585566971256, 0.397177446404892, 0.4059436795581469, 0.5291405511947482, 0.6995336506936252, 0.6825812958178791, 0.4370457097783316, 0.44231569851485697, 0.44205586167683586, 0.41787570186742673, 0.4296871372422193, 0.4234423202600753, 0.37495712005543674, 0.3890125520997414, 0.4720642740285366, 0.7096860918074419, 0.4413966445440612, 0.46657145596955246, 0.934691209037309, 0.40385143488108, 0.606012106222734, 0.4380824707263371, 0.41303569095452314, 0.4365423077670213, 0.4442775085061454, 0.3852137732002753, 0.42226648225414887, 0.43421164277137697, 0.5603077307467056, 0.5032959882865466, 0.46312138407144965, 0.4293417518270684, 0.5423983198246476, 0.4074696317232802, 0.43664190448789886, 0.7111695960222003, 0.4454812094571941, 0.43404840145081885, 0.4366731916676991, 0.3645043839051713, 0.5370551892579327, 0.3870016047920784, 0.4367121719790492, 0.37941411189247976, 0.3926230760709584, 0.4168623514584455, 0.3759624873759783, 0.40313268194112123, 0.3868238767446608, 0.3843719638689259, 0.6464358131721347, 0.45844082833102234, 0.4241699883655422, 0.4008338598400542, 0.3843680714203744, 0.44611988547240905, 0.39666051276424613, 0.5088042629067252, 0.40789666250493545, 0.5607722069860446, 0.42502474516868366, 0.6235044850877989, 0.5246988756852256, 0.3925964104336781, 0.3876981583450532, 0.4000601323818397, 0.3807053692670327, 0.37929913454812364, 0.49332364186547834, 1.410539917711863, 0.38060753432334, 0.5696371065096552, 0.40654288364378477, 0.42155354705761283, 0.40485606710203587, 0.37161379533259903, 0.38217606513822566, 0.3805088108088674, 0.37834140013260836, 0.3971440829389479, 0.3630555526852514, 0.45479611414309623, 0.39745389942977183, 0.3845093872776255, 0.4367371325600788, 0.530801518700056, 0.38672041581113087, 0.3822881398121663, 0.506519583193886, 0.3630651121878003, 0.3982355271683278, 0.4249611315936329, 0.4241762487155469, 0.40241143907135507, 0.37720970803865317, 0.3964969867733526, 0.6054029014128826, 0.5597898753828007, 0.3708211962100142, 0.3982709996865104, 0.49991929120445866, 0.45538760676754503, 0.5470600195818451, 0.3736478188006206, 0.3811791420387694, 0.3698868965509249, 0.3851919733442268, 0.5412929720915678, 0.44732515289351404, 0.4435559649203991, 0.4040979207913642, 0.38039258249100666, 0.3751284595418475, 0.4009926886306791, 0.4808827742870327, 0.3704677254259432, 0.43724320634255465, 0.3974001235092952, 0.41734988960120445, 0.44500908692236235, 0.4030611412193314, 0.4646461645330489, 0.3901722714635862, 0.4125304832604258, 0.558819093480608, 0.3909983909888345, 0.3946839076198344, 0.4006467730230083, 0.37315322201676576, 0.5494040565987324, 0.36204327785412427, 0.4382990319248561, 0.5557434869154488, 0.36913663262308943, 0.3665969621657577, 0.37870571741300985, 1.837972320430388, 0.3859711492265101, 0.3658363560572958, 0.3790387990171123, 0.39233224602255695, 0.3974743134263611, 0.37746414136370227, 0.37555419946836327, 0.405885757040666, 0.4924476660932394, 0.4065221079680092, 0.3793463790105024, 0.5296084002791404, 0.3891277481675142, 0.3773635726920778, 0.4226411295199497, 0.39398446363642614, 0.4669852868599957, 0.38305426518929936, 0.3638071973918645, 0.3757065171445023, 0.5038042512659423, 0.39939555084794265, 0.5497568691642684, 0.5618362992699096, 0.38131417005702717, 0.38241119765759557, 0.4189931071842314, 0.3835426299117599, 0.3633377348372576, 0.3761587336957052, 0.3881079245027581, 0.3629679221758919, 0.385565066904581, 0.36956498474695726, 0.38936883322177873, 0.5050663182013436, 0.3778541964008382, 0.360224770569427, 0.41109611109189775, 0.3914698392301472, 0.7230350097018478, 0.37683264402136923, 0.3842591206306304, 0.36621222005359316, 0.39077307962288804, 0.37748704975614583, 0.39993819207004266, 0.42721171142614134, 0.3770522032332694, 0.36942332256196553, 0.3715848101277216, 0.3990352563037246, 0.3687427332803036, 0.36395513072324714, 0.36677286057206804, 0.38157539856071654, 0.380009971506212, 0.4013914568751115, 0.39608935245859955, 0.37935317071963937, 0.3691300915814646, 0.37243662053137877, 0.42370406150732337, 0.3847410326661946, 0.40223332750881013, 0.38440296818748537, 0.414918196327434, 0.41914452502825017, 0.39061262190567714, 0.38858987537368583, 0.37802537886400334, 0.3873056317341047, 0.4083515451508842, 0.3800309769777793, 0.3702593055201429, 0.39391982653701113, 0.36505016968825565, 0.36762275270439776, 0.36956179215744506, 0.3966551138809252, 0.3798669489402578, 0.40028209624398114, 0.49149694437239194, 0.3657843895919514, 0.3878945956983081, 0.4895344182417045, 0.37156227355892013, 0.3848916079952625, 0.3822865521421867, 0.37003578700822526, 0.37321589253287746, 0.3915148467644501, 0.40391796751133413, 0.3724571387612562, 0.35942494121376933, 0.36906062015061963, 0.39681493638911647, 0.4309470759284914, 0.3636746879485724, 0.4119232357705971, 0.4621273932373666, 0.4003011293543809, 0.366237716242989, 0.3875722529195704, 0.39179524068859767, 0.39016278863273435, 0.3706235048961103, 0.46626381099893427, 0.45163477021696147, 0.558190020103759, 0.3620826282764937, 0.37474437113940506, 0.3855179747651833, 0.3839429665924827, 0.4047365287009799, 0.37206038438820915, 0.3806246416550178, 0.3719088600025413, 0.36896260452273294, 0.3914847083090025, 0.3829077828776021, 0.3672899472637089, 0.3721859726865683, 0.3604669527475739, 0.38158699314451966, 0.3909226465353716, 0.38745449695408773, 0.4287743493644831, 0.38599976725430396, 0.40140241456860065, 0.37297811893628247, 0.3629495509613923, 0.36518043255629334, 0.3756873866652295, 0.36179739770161506, 0.39342888683840016, 0.36887517319180535, 0.43095963842912843, 0.39969813767855716, 0.4233836097491203, 0.37598512610641094, 0.3729592056423478, 0.3817423914820147, 0.368793733324624, 0.36680845948818, 0.3753021008554897, 0.37346269409486377, 0.40935304970435826, 0.3720966327200544, 0.3661676846164018, 0.5854388898770098, 0.3656350002417553, 0.37910870403790825, 0.3840614199490178, 0.36207132812059994, 0.36852664027377796, 0.36065523532443766, 0.36361074242554703, 0.4083382848797722, 0.3669375338740523, 0.3762468041586726, 0.36773675164235387, 0.42069450664565217, 0.4018315566646086, 0.36472360301623646, 0.3936307545317397, 0.3740854792881063, 0.37667883227525945, 0.3756913770117571, 0.36693610474500843, 0.4310207607968666, 0.37726311308081173, 0.35845482415682806, 0.384660396590488, 0.3679217106951158, 0.39949716798089313, 0.3769538221871687, 0.38986037194702, 0.3635959063320857, 0.36149361567957056, 0.41315374861562215, 0.3758074661173512, 0.3766894969501229, 0.3998195298525905, 0.37014596451578186, 0.36260721257524564, 0.376443215811645, 0.3698482340554274, 0.4000987265434877, 0.4020628496989342, 0.3551269978017798, 0.3550747694085774, 0.3999843162324359, 0.41142933013945165, 0.3754913160594106, 0.3827418556169579, 0.3821098278603194, 0.38865664773582825, 0.3826961093285789, 0.36701692674074116, 0.3657280908114712, 0.3630260832119047, 0.362687004608863, 0.3781087440713081, 0.37857101768574986, 0.35758903550422605, 0.3577739377341121, 0.42263751457845494, 0.3727812553935565, 0.3663770535325553, 0.39491336576279956, 0.3683220240425959, 0.37095991044749754, 0.35223165132328255, 0.37704204370555755, 0.37284635473205896, 0.38466032218886165, 0.3885657865156832, 0.3765431242572263, 0.35500341915590594, 0.37164062398084025, 0.36589315684362733, 0.38548730845740253, 0.36042116690228215, 0.3874411701383298, 0.3774215439064273, 0.3665384349954518, 0.37432166212961365, 0.372218542499526, 0.37203049191890575, 0.3815176399199561, 0.38587474198119465, 0.3610063070939103, 0.36686856476731605, 0.37331003657299294, 0.3578106604749108, 0.37724708562197157, 0.39068463283542226, 0.3768266323313685, 0.36194284422758316, 0.47483593036563504, 0.37715625030698713, 0.3920828548286653, 0.37018475755103086, 0.37720401845998586, 0.3634644697579785, 0.36038883521799087, 0.3661706842349939, 0.3912664156204664, 0.40656500496818726, 0.3663184780443061, 0.35610444062720575, 0.3716545415445569, 0.37123094198134127, 0.38170832365070495, 0.3481288801181446, 0.3733844942266123, 0.36427405060199897, 0.36493806057140143, 0.37145680131448533, 0.38774216160359937, 0.38041782819787756, 0.3598320630326077, 0.3701431011188311, 0.37075128647353817, 0.3731592210565308, 0.39446367080254885, 0.373902600621539, 0.3684277319377647, 0.39049436826164974, 0.46191150008159176, 0.378772648342941, 0.35682932934524186, 0.3879848854370039, 0.3689472349810777, 0.36211066510305734, 0.36809526471074366, 0.3746574915549822, 0.3615220940937951, 0.35790240740997253, 0.37320307930406044, 0.38534923054532627, 0.36537365963884644, 0.364819017597716, 0.3769124661054503, 0.36957733629115086, 0.4081667263770485, 0.3725607564863005, 0.3703456780438914, 0.3589384489638995, 0.3628630893136274, 0.38629002649556415, 0.35163367113937627, 0.360614972064159, 0.376169172646483, 0.35201825073686266, 0.3556839454216012, 0.3693799585587839, 0.35893582684885017, 0.38275279681029084, 0.3582379395704649, 0.3812352369659144, 0.356508159548538, 0.3631259387312745, 0.37842069747084717, 0.35383191117217, 0.3612319873112727, 0.36282474115055546, 0.3617479240204495, 0.37349869129623176, 0.3769778156877847, 0.3713380648097805, 0.3570067113389186, 0.38153654292025185, 0.3726211665491445, 0.3772881915498652, 0.36057228515416734, 0.36797884118272334, 0.3784926987379982, 0.3642699930245828, 0.415015381764889, 0.3636421646384959, 0.355351754275943, 0.3625740499436667, 0.38310850016081904, 0.36020614654415034, 0.35967885059060883, 0.3751504632591877, 0.36783263375643716, 0.38352724880393324, 0.3763940062115479, 0.3952423877277744, 0.37348295373112705, 0.3828983668191491, 0.3532916537504711, 0.37656921494554313, 0.3547252016675496, 0.3809096087535171, 0.3573415887797188, 0.35917135318693183, 0.36136545478851084, 0.3536341435983147, 0.3714111237662313, 0.371160926025949, 0.36617104418266083, 0.3537280247030885, 0.3651389559151777, 0.3725087358913338, 0.37349946107145676, 0.37127463065733135, 0.36178302273334023, 0.36991227725165954, 0.35468036307075773, 0.3633157741587654, 0.35847911328329435, 0.3578419834914927, 0.3675162742353767, 0.35501346607021356, 0.3759273176881986, 0.3628054813806916, 0.38899150195129484, 0.3742841623593096, 0.3751722463326265, 0.36536679579218634, 0.36699952934525903, 0.3630524851917968]}, {\"mode\": \"lines\", \"name\": \"val_acc\", \"type\": \"scatter\", \"y\": [0.7770435986702097, 0.7998197915622433, 0.816872736894335, 0.8255660663107602, 0.8283359183499887, 0.7831339360912527, 0.8331748191909051, 0.6940481565960201, 0.5998731881304993, 0.6849209929361525, 0.6704376688225286, 0.765446929485205, 0.7659475055828312, 0.8447548029451841, 0.6794146579488398, 0.7131868309570165, 0.8281356891016188, 0.7442225233055788, 0.7591063053898232, 0.8437870232494142, 0.7841517727385892, 0.8008710008532725, 0.8276684853672212, 0.71195208022135, 0.754684555048388, 0.6573559589176414, 0.8457893266443699, 0.841100600138099, 0.8514458310044957, 0.8322904679078692, 0.838030403225794, 0.8230798749521031, 0.8511955443361242, 0.8222956395016359, 0.8366788485077213, 0.8354941529970747, 0.8550166043744556, 0.8058600702415217, 0.8152375225946739, 0.8467070478738669, 0.8237306228313535, 0.7712702927603579, 0.7152058206002216, 0.7831339379928409, 0.8364786153795944, 0.846356645086495, 0.8550499753174603, 0.8379970304538036, 0.7771770864622176, 0.8493601009681075, 0.8322237248771276, 0.8556006075928896, 0.8413008301413357, 0.7441557804737482, 0.7660476204258181, 0.704059666185237, 0.7618261008663559, 0.8249987480028999, 0.7868548843518142, 0.8456892107411879, 0.8183911494513268, 0.6828686339839958, 0.7701857133110275, 0.8596552722284718, 0.8155879263875402, 0.8271679097330573, 0.8507783961609168, 0.8004204843994717, 0.8000367089495105, 0.84143431712676, 0.8212944875222018, 0.8364452463162978, 0.6217984016342902, 0.8556840388967935, 0.8368290212978238, 0.8618911777611452, 0.7362133128039023, 0.690160350712358, 0.8268675658973011, 0.8383474333396362, 0.8656288074980836, 0.8429861021285338, 0.8363117608048032, 0.8247651451192664, 0.8377467440549564, 0.7847524638731403, 0.7892242745476271, 0.8486259225398202, 0.8507617114442813, 0.7842352039848088, 0.7667817992131397, 0.8294705590752085, 0.7453571596875792, 0.8607231662122672, 0.8075620301060494, 0.8461897881436695, 0.8053928681988612, 0.7763928520063049, 0.8625419256016079, 0.8610735689419549, 0.8635764477781307, 0.8206604264879336, 0.758455556456345, 0.8296207307941756, 0.8305718252770274, 0.8404832221864132, 0.8623750664220293, 0.8635097048886159, 0.8465068187836311, 0.8303382224182577, 0.8320068082089231, 0.8401495050992913, 0.7558525625832441, 0.7894411890874848, 0.8166725063053057, 0.8662962414754055, 0.861423972266386, 0.8608399673880407, 0.8518462923625686, 0.8646610279713879, 0.7769601701808949, 0.8269843661471443, 0.8634095885577755, 0.8582870311616998, 0.8103151955509235, 0.8061103621114132, 0.7852196689700777, 0.8533813899166602, 0.8484757490306548, 0.8435200501855993, 0.8538652805149365, 0.8451719490497291, 0.855967697811036, 0.8691995809277168, 0.8665465295938375, 0.8274682551541335, 0.7492783359045841, 0.8438370792472029, 0.8354440951106271, 0.7420033042200658, 0.8562012993649502, 0.801688606053279, 0.8447381160594253, 0.856484959461718, 0.8463065870309731, 0.8499774752986204, 0.8647110845937568, 0.8583537746887241, 0.8490263832136395, 0.7998031067471468, 0.8285862072939008, 0.8443376562220262, 0.8509285694821113, 0.7967495935330535, 0.8575695390691825, 0.8483422617757063, 0.7770269133807108, 0.8396823037219878, 0.8476748270325772, 0.8499107317636397, 0.8730373273913282, 0.8154711241296915, 0.8649446886350518, 0.8490430679004384, 0.8683486012530425, 0.8642438821940512, 0.8510453702600629, 0.8720862331481641, 0.8613906007753819, 0.86683019142113, 0.8676644810493513, 0.7909762882089943, 0.8394487007756973, 0.8512289145819463, 0.8599723030673443, 0.8657956659914194, 0.846306586720672, 0.8623750655448322, 0.8169895367354164, 0.8545660859723226, 0.820910714625262, 0.8537484781456977, 0.7692846739487674, 0.8167392497507766, 0.8634930173464511, 0.8670304185113167, 0.8618911765269031, 0.8692496380483574, 0.8660960125950209, 0.8237139358988506, 0.6532512394140843, 0.8683319154841683, 0.8151207216993648, 0.8585039476419334, 0.853498192741405, 0.8631759862380544, 0.8723198359363205, 0.8697168414535575, 0.8683152304403244, 0.869683470202241, 0.8606063669460384, 0.8737548174539597, 0.8390315560824251, 0.8615074011067785, 0.8668135036522069, 0.8442208578499018, 0.8221287811067608, 0.8673474504561337, 0.8665799022673669, 0.8335252226863996, 0.8745390553321345, 0.8634596460762379, 0.848342262173528, 0.8510620572930158, 0.8605062507564247, 0.8674809378393799, 0.8616742602863571, 0.7857035588711713, 0.8219952945708752, 0.8725868072676214, 0.8589711525697965, 0.8246650330441246, 0.8449717187769682, 0.815053979513, 0.8714521715042339, 0.8656454929397492, 0.8736046476644281, 0.8682985434073716, 0.8278019715271653, 0.8507617113159837, 0.8415344321805924, 0.8609734534365947, 0.869950443266056, 0.8704343351671986, 0.8603560789370075, 0.8266172769016722, 0.8707013054164243, 0.8457559532328809, 0.8602893340176069, 0.8559009550498187, 0.8521633244187758, 0.8605229362388672, 0.8450217749736678, 0.8647611435453724, 0.857869884038731, 0.8221955250017703, 0.8637433074072479, 0.8622082073080913, 0.8607899101261732, 0.8702007292372447, 0.8036575394997845, 0.8746057967009755, 0.8485925499070673, 0.831873321334889, 0.8719694322011382, 0.8744723098846254, 0.8683819729727943, 0.6908444710085427, 0.8683819735993635, 0.8732542426482598, 0.8718359449183422, 0.8654619488038476, 0.8629257002778057, 0.8671805924889171, 0.870367589223407, 0.8580701170554678, 0.8250488077909357, 0.8572358209855171, 0.8670637891957372, 0.8329412142664457, 0.8647778294256366, 0.8699504443013871, 0.8588543519907558, 0.8639769071003507, 0.8246483461693059, 0.8664464161183629, 0.8724533207207956, 0.8703509047056823, 0.8180908049134151, 0.8620580344364355, 0.8312392592354528, 0.8166558203653683, 0.8684654037207422, 0.8638601084825713, 0.8525137272469243, 0.8687991191887294, 0.8756736921477606, 0.8709515954364444, 0.8656621792755195, 0.8735045300008848, 0.8676144238879339, 0.8701339874407452, 0.8666967007568487, 0.8438871373325615, 0.8697502118107697, 0.8741219066884918, 0.8581034868457837, 0.8628756398632005, 0.7999866522565282, 0.8693497514233819, 0.8665632154223849, 0.8744723107101057, 0.866346299192779, 0.8697669002659355, 0.8574360535636554, 0.846640303341348, 0.8686489463936542, 0.8712519404766061, 0.8709349093572692, 0.8627755268969379, 0.8740051072452323, 0.8764912981135741, 0.8739383622959951, 0.8663963566814048, 0.8686656343614884, 0.8600557310007031, 0.8643606806427563, 0.8684820882086302, 0.8735045318915329, 0.8717191434153603, 0.8481587160266372, 0.8671138482478027, 0.8613238552701887, 0.8664297286875883, 0.8558508961091432, 0.8572024511673535, 0.8624418101668611, 0.8664130428888775, 0.8708514792358907, 0.8681650578551002, 0.8578365134547604, 0.8700839295950743, 0.8726702384243313, 0.863626504770474, 0.875773807255299, 0.873054012533633, 0.8719861164493385, 0.8627087838960329, 0.8681150000671135, 0.8603060196581835, 0.8398992173896214, 0.8758739209983086, 0.8689326074362433, 0.8340424816209533, 0.871819260482171, 0.8672473358468672, 0.8661794413240232, 0.8729872690473854, 0.8714187967839113, 0.8642605665705492, 0.86145734302142, 0.8690827786589279, 0.8771754184972796, 0.8721029203392512, 0.8603060214076049, 0.8420350093075826, 0.8744389392708183, 0.8545160278571274, 0.8463733305987741, 0.8601057898538578, 0.8739550482637801, 0.865161604120731, 0.8631092441034063, 0.862541923512049, 0.8716857711804293, 0.8467404200322171, 0.8457893263857856, 0.8295039288466279, 0.8739383626232035, 0.8716023429477096, 0.8676311105529015, 0.8671472208099421, 0.8595718414158778, 0.8715856572663563, 0.8706178775815264, 0.8701173020289161, 0.8745724253193723, 0.8645442285281284, 0.8674141938140838, 0.8726535515902893, 0.8719861180814025, 0.8755568913827381, 0.8682484862867308, 0.8653284606955712, 0.8633595323332284, 0.8599389316578936, 0.8677479124944819, 0.8580868014259982, 0.8723365206698633, 0.8752565455340036, 0.8727202953460611, 0.8711851963826858, 0.875189801181499, 0.866496470296117, 0.8716190283893753, 0.8523969260433034, 0.862058035997886, 0.8542824256060305, 0.8721196051652876, 0.87013398927172, 0.8673808231893365, 0.8710350233698032, 0.8746892250321561, 0.8702674737996002, 0.8742053357576318, 0.8580867997939343, 0.8706011913442172, 0.8747392841419057, 0.8334751645304277, 0.8748560847318866, 0.8700005021172215, 0.8689159196673202, 0.8749061425069442, 0.8742887674702976, 0.8752899166759192, 0.8748727716236128, 0.8632761012859195, 0.8741886501578319, 0.8685321459150634, 0.8721696631114086, 0.8601224768161972, 0.8645775989838014, 0.874922827850149, 0.8615074010550616, 0.8725701232183319, 0.8693831253609902, 0.8715689721240515, 0.871869318327842, 0.8500609034418302, 0.8683819743950072, 0.8760908369116461, 0.8635764481461159, 0.8736046462611118, 0.8631259297250864, 0.8686322605243301, 0.865111544285951, 0.8752565446100624, 0.8742053357685718, 0.856001067699813, 0.8712185690562153, 0.8678480257113723, 0.860756537166212, 0.8720028042480984, 0.8746558542602147, 0.8693998097782648, 0.8721029197534585, 0.8600390478067306, 0.8648445732410817, 0.8785102866916112, 0.8766915295499638, 0.8649947464916629, 0.8576362851114352, 0.8711017663707081, 0.8683819733407794, 0.8667467599073752, 0.866246182932552, 0.8690827806182002, 0.8739717365608117, 0.8740384795507766, 0.8752231742528503, 0.8751230596734204, 0.8666132728642667, 0.8715856575358806, 0.8761575821304076, 0.8761742673731624, 0.8539320226197479, 0.8710517113396264, 0.8735545888540394, 0.8627922126956487, 0.8721863488802827, 0.8717191448783499, 0.8780430829761101, 0.8695666687997091, 0.8724366358758626, 0.8690160366933541, 0.8642271941665439, 0.8702507893117123, 0.8770419317515429, 0.8742387075350677, 0.8719193739168687, 0.8642605686193313, 0.8760240961803145, 0.8649279998526775, 0.8684654040887274, 0.8742887665463565, 0.871085082937048, 0.8725701220656433, 0.8729872682219052, 0.8687490622073263, 0.8671805907693324, 0.8742720800802997, 0.8742220225916738, 0.8719694330375586, 0.875890607704053, 0.8705010771735491, 0.8642271960442628, 0.871802572781872, 0.8760574651342102, 0.8460229281386108, 0.8709682807090359, 0.8626086677064192, 0.8724866947867014, 0.8713854273914171, 0.8749228284468817, 0.8763244397594757, 0.8746725402578364, 0.8609067110324223, 0.8612237422929859, 0.8735379021075182, 0.8783601126732341, 0.8722697795705465, 0.8699170730610106, 0.8691995795353404, 0.8808629924761169, 0.8707346797110777, 0.8741886517083424, 0.8751063726514076, 0.8725534373788445, 0.8647778285892163, 0.8692663232612756, 0.8776259355667095, 0.8726368677806875, 0.8742387074773835, 0.8706846211383874, 0.8641938222180446, 0.8716190291850189, 0.8724700086498421, 0.8664797864457384, 0.8311391434685248, 0.8670971620681776, 0.877325592117835, 0.8699170721649171, 0.8727703529759138, 0.8755402038405733, 0.8723532067788751, 0.8716524005367855, 0.8752064884839762, 0.8788940603921511, 0.8718025745720701, 0.8677979681222964, 0.8743721955448831, 0.8747893408756647, 0.8717024588101149, 0.8737047615078878, 0.8625586107439127, 0.8709182228504357, 0.8709682804802883, 0.8772087905442398, 0.874872771326241, 0.8662294986843516, 0.8795614947076216, 0.8771754193635366, 0.8698670156002323, 0.8783434295200382, 0.8767249005039085, 0.8748060275704691, 0.8759907227409781, 0.8674642512917695, 0.876641471505382, 0.8693831245653466, 0.8773923334866761, 0.8739550483642301, 0.8689826641481222, 0.8783768007007414, 0.8761909529431257, 0.874722599109002, 0.8767582718258385, 0.8727870380088175, 0.8719694323294357, 0.8704176479353348, 0.8781932565668289, 0.8674976234093431, 0.8715189137094953, 0.8699838159097488, 0.8773422759383769, 0.8732375554462327, 0.8688658632607695, 0.8744723098846254, 0.8483088896770292, 0.8756236356238525, 0.876424556088327, 0.8755068313361181, 0.8698670132839149, 0.8750229446772722, 0.8775591928462689, 0.8722530920800986, 0.8729038422368787, 0.8664297295538452, 0.8703008470589223, 0.8682818599249782, 0.8723031476094522, 0.8689826639492113, 0.8779763404247438, 0.8690994656620442, 0.8784268569272776, 0.8689492927386715, 0.879428008618291, 0.8773756486119064, 0.8763244396888623, 0.8786104008622794, 0.8735379031428494, 0.8733877294238331, 0.8739216782059289, 0.8788440044351391, 0.8756069487599739, 0.8719527469693235, 0.8723865786269244, 0.8719193741157797, 0.8755235191647146, 0.8721529770023968, 0.8782433136874696, 0.8749895721320401, 0.8771587328974797, 0.8786270867017668, 0.8728204105818971, 0.8788106328267775, 0.870901538076116, 0.876190954435952, 0.8621748356291163, 0.8689159208607855, 0.8708681655716608, 0.8744889959936373, 0.8749561993302131, 0.8753733467097771]}],\n",
              "                        {\"template\": {\"data\": {\"bar\": [{\"error_x\": {\"color\": \"#2a3f5f\"}, \"error_y\": {\"color\": \"#2a3f5f\"}, \"marker\": {\"line\": {\"color\": \"#E5ECF6\", \"width\": 0.5}}, \"type\": \"bar\"}], \"barpolar\": [{\"marker\": {\"line\": {\"color\": \"#E5ECF6\", \"width\": 0.5}}, \"type\": \"barpolar\"}], \"carpet\": [{\"aaxis\": {\"endlinecolor\": \"#2a3f5f\", \"gridcolor\": \"white\", \"linecolor\": \"white\", \"minorgridcolor\": \"white\", \"startlinecolor\": \"#2a3f5f\"}, \"baxis\": {\"endlinecolor\": \"#2a3f5f\", \"gridcolor\": \"white\", \"linecolor\": \"white\", \"minorgridcolor\": \"white\", \"startlinecolor\": \"#2a3f5f\"}, \"type\": \"carpet\"}], \"choropleth\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"choropleth\"}], \"contour\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"contour\"}], \"contourcarpet\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"contourcarpet\"}], \"heatmap\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"heatmap\"}], \"heatmapgl\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"heatmapgl\"}], \"histogram\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"histogram\"}], \"histogram2d\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"histogram2d\"}], \"histogram2dcontour\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"histogram2dcontour\"}], \"mesh3d\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"mesh3d\"}], \"parcoords\": [{\"line\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"parcoords\"}], \"pie\": [{\"automargin\": true, \"type\": \"pie\"}], \"scatter\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatter\"}], \"scatter3d\": [{\"line\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatter3d\"}], \"scattercarpet\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattercarpet\"}], \"scattergeo\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattergeo\"}], \"scattergl\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattergl\"}], \"scattermapbox\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattermapbox\"}], \"scatterpolar\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterpolar\"}], \"scatterpolargl\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterpolargl\"}], \"scatterternary\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterternary\"}], \"surface\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"surface\"}], \"table\": [{\"cells\": {\"fill\": {\"color\": \"#EBF0F8\"}, \"line\": {\"color\": \"white\"}}, \"header\": {\"fill\": {\"color\": \"#C8D4E3\"}, \"line\": {\"color\": \"white\"}}, \"type\": \"table\"}]}, \"layout\": {\"annotationdefaults\": {\"arrowcolor\": \"#2a3f5f\", \"arrowhead\": 0, \"arrowwidth\": 1}, \"coloraxis\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"colorscale\": {\"diverging\": [[0, \"#8e0152\"], [0.1, \"#c51b7d\"], [0.2, \"#de77ae\"], [0.3, \"#f1b6da\"], [0.4, \"#fde0ef\"], [0.5, \"#f7f7f7\"], [0.6, \"#e6f5d0\"], [0.7, \"#b8e186\"], [0.8, \"#7fbc41\"], [0.9, \"#4d9221\"], [1, \"#276419\"]], \"sequential\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"sequentialminus\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]]}, \"colorway\": [\"#636efa\", \"#EF553B\", \"#00cc96\", \"#ab63fa\", \"#FFA15A\", \"#19d3f3\", \"#FF6692\", \"#B6E880\", \"#FF97FF\", \"#FECB52\"], \"font\": {\"color\": \"#2a3f5f\"}, \"geo\": {\"bgcolor\": \"white\", \"lakecolor\": \"white\", \"landcolor\": \"#E5ECF6\", \"showlakes\": true, \"showland\": true, \"subunitcolor\": \"white\"}, \"hoverlabel\": {\"align\": \"left\"}, \"hovermode\": \"closest\", \"mapbox\": {\"style\": \"light\"}, \"paper_bgcolor\": \"white\", \"plot_bgcolor\": \"#E5ECF6\", \"polar\": {\"angularaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}, \"bgcolor\": \"#E5ECF6\", \"radialaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}}, \"scene\": {\"xaxis\": {\"backgroundcolor\": \"#E5ECF6\", \"gridcolor\": \"white\", \"gridwidth\": 2, \"linecolor\": \"white\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\"}, \"yaxis\": {\"backgroundcolor\": \"#E5ECF6\", \"gridcolor\": \"white\", \"gridwidth\": 2, \"linecolor\": \"white\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\"}, \"zaxis\": {\"backgroundcolor\": \"#E5ECF6\", \"gridcolor\": \"white\", \"gridwidth\": 2, \"linecolor\": \"white\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\"}}, \"shapedefaults\": {\"line\": {\"color\": \"#2a3f5f\"}}, \"ternary\": {\"aaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}, \"baxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}, \"bgcolor\": \"#E5ECF6\", \"caxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}}, \"title\": {\"x\": 0.05}, \"xaxis\": {\"automargin\": true, \"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\", \"title\": {\"standoff\": 15}, \"zerolinecolor\": \"white\", \"zerolinewidth\": 2}, \"yaxis\": {\"automargin\": true, \"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\", \"title\": {\"standoff\": 15}, \"zerolinecolor\": \"white\", \"zerolinewidth\": 2}}}},\n",
              "                        {\"responsive\": true}\n",
              "                    ).then(function(){\n",
              "                            \n",
              "var gd = document.getElementById('7753077e-8867-4cad-834d-ede8909d60d8');\n",
              "var x = new MutationObserver(function (mutations, observer) {{\n",
              "        var display = window.getComputedStyle(gd).display;\n",
              "        if (!display || display === 'none') {{\n",
              "            console.log([gd, 'removed!']);\n",
              "            Plotly.purge(gd);\n",
              "            observer.disconnect();\n",
              "        }}\n",
              "}});\n",
              "\n",
              "// Listen for the removal of the full notebook cells\n",
              "var notebookContainer = gd.closest('#notebook-container');\n",
              "if (notebookContainer) {{\n",
              "    x.observe(notebookContainer, {childList: true});\n",
              "}}\n",
              "\n",
              "// Listen for the clearing of the current output cell\n",
              "var outputEl = gd.closest('.output');\n",
              "if (outputEl) {{\n",
              "    x.observe(outputEl, {childList: true});\n",
              "}}\n",
              "\n",
              "                        })\n",
              "                };\n",
              "                \n",
              "            </script>\n",
              "        </div>\n",
              "</body>\n",
              "</html>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "fbtg6S6AIdJE",
        "colab": {}
      },
      "source": [
        "# fig, loss_ax = plt.subplots()\n",
        "# # acc_ax = loss_ax.twinx()\n",
        "\n",
        "# loss_ax.plot(history.history['loss'], 'y', label='train loss')\n",
        "# loss_ax.plot(history.history['val_loss'], 'r', label='val loss')\n",
        "# loss_ax.set_xlabel('epoch')\n",
        "# loss_ax.set_ylabel('loss')\n",
        "# loss_ax.legend(loc='upper left')\n",
        "\n",
        "# # # acc_ax.plot(history.history['categorical_crossentropy'], 'b', label='train crossentropy')\n",
        "# # # acc_ax.plot(history.history['val_categorical_crossentropy'], 'g', label='val crossentropy')\n",
        "# # # acc_ax.set_ylabel('categorical_crossentropy')\n",
        "# # # acc_ax.legend(loc='upper right')\n",
        "\n",
        "# plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "P1lPPJBiIdJJ",
        "colab": {}
      },
      "source": [
        "real_y_pred = best_model.predict(test_X)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "JwLvngasIdJO",
        "colab": {}
      },
      "source": [
        "submission = pd.DataFrame(data=real_y_pred, columns=sample_submission_df.columns, index=sample_submission_df.index)\n",
        "submission.to_csv('0227_submission_keras_alldata_0.3481(이전꺼랑 배치사이즈300->200으로, elu - 0.2-->0.3).csv', index=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "kUfxKxAUIdJT",
        "colab": {}
      },
      "source": [
        "\n",
        "### 기록 1.레이어 2. 옴티마이저  ==> val_loss\n",
        "#1. 9개,// 2. 0.0003 ==> 0.404\n",
        "#1. 8개(256*2)층 하나 제거 //2. 0.0001 ==> 0.666179819053121\n",
        "#1. 8개 //2. 0.0005 ==> 0.47\n",
        "#1. 7개 //2. 0.0002 ==> 0.38\n",
        "#1. 8개(256*1)층 하나 추가 //2. 0.0002 ==> 0.0.3935\n",
        "#1. 8개(파생변수만 남기고 전부 제거) // 2. 0.0002 ==>0.5719 "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "yA-2NZ7XuSJM",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}